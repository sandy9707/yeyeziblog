[{"title":"Dify 的介绍和部署","url":"/2024/09/15/LLM/Dify/","content":"引言八月份的我：我已经忘了四月份的我为啥要建这个文件了，可能是为了 AI Agent？总之，现在我要建的时候正好发现这文件已经存在了，所以就用起来好了。\nDify 是一款开源的大语言模型 (LLM) 应用开发平台。它融合了后端即服务（Backend as Service）和 LLMOps 的理念，使开发者可以快速搭建生产级的生成式 AI 应用。即使你是非技术人员，也能参与到 AI 应用的定义和数据运营过程中。[1-2]\n我需要的功能是”直观的 Prompt 编排界面、高质量的 RAG 引擎、稳健的 Agent 框架、灵活的流程编排”, 现在开始。\n效果展示过程# git config --global http.proxy &lt;protocol&gt;://&lt;host&gt;:&lt;port&gt;## git clonegit clone https://github.com/langgenius/dify.git## runcd dify/dockercp .env.example .envdocker-compose up -d## check statusdocker compose ps## Resetdocker-compose down\n\n# git config --global http.proxy http://127.0.0.1:7890\n\n问题端口冲突在.env和docker-compose.yaml分别更改冲突端口 (实际上官网只推荐了更改.env, 但是我实际发现更改不可用，不排除是未全部重置的原因)。\n以 80 和 443 端口冲突为例，.env需要更改 4 处，包括：\n\nNGINX_PORT\nNGINX_SSL_PORT\nEXPOSE_NGINX_PORT\nEXPOSE_NGINX_SSL_PORT\n\ndocker-compose.yaml中字段同上。\n需要注意的是，这样会导致分享处理的应用和 api 需要手动额外加上端口号，所以事实上选择 80 和 443 最为友好。但是可以使用转发解决。\n不能登录我的情况是无法注册和登录，会一直转圈圈\n首先是在.env文件中INIT_PASSWORD=填上自己的文件夹，但是这不是关键。真正重要的是改好所有的冲突端口和重置weaviate.\n我怀疑我第一次更改了端口但第二次使用了默认的5001端口导致了问题。\n重置的命令是[3]:\nsudo rm -rf ./volumes/app ./volumes/db ./volumes/redis ./volumes/weaviate\n删除所有创建的不用的 docker 服务。\ndocker system prune -a\n结论试着用了几下示例应用，感觉非常不错，早就该用起来了~\n2025 年 03 月 01 日：我觉得他非要让我用 80 和 443 还是太过分了…但是社区版好像不用安装也能用，我觉得是不是可以直接用在线的也行…\n引用\nDify.AI · The Innovation Engine for Generative AI Applications\n欢迎使用 Dify | 中文 | Dify\nwindows11 环境的 docker 部署方式，设置管理后跳转到登录页，输入登录信息又跳转到设置管理员页面，如此反复，不能登录 · Issue #4614 · langgenius&#x2F;dify · GitHub\n\n","categories":["LLM"],"tags":["LLW"]},{"title":"GOT-OCR2.0","url":"/2024/09/16/LLM/GOT-OCR2.0/","content":"引言看起来不错的 OCR 服务\n效果展示过程## Clone this repository and navigate to the GOT foldergit clone https://github.com/Ucas-HaoranWei/GOT-OCR2.0.git# cd &#x27;the GOT folder&#x27;cd GOT-OCR2.0/GOT-OCR-2.0-master/## Install Packageconda create -n got python=3.10 -yconda activate gotpip install -e .## Install Flash-Attentionpip install ninjapip install flash-attn --no-build-isolation\n\n## test demo# python3 GOT/demo/run_ocr_2.0.py  --model-name  /GOT_weights/  --image-file  /an/image/file.png  --type ocrpython3 GOT/demo/run_ocr_2.0.py  --model-name  /home/tenney/github/GOT-OCR2.0/GOT-OCR-2.0-master/GOT_weights/GOT_weights  --image-file  /home/tenney/github/GOT-OCR2.0/GOT-OCR-2.0-master/an/2024-09-16-16-28-28.png  --type ocrpython3 GOT/demo/run_ocr_2.0_crop.py  --model-name  ./GOT_weights/GOT_weights/ --image-file  /home/tenney/github/GOT-OCR2.0/GOT-OCR-2.0-master/an/病历示例  --multi-page\n\n结论引用\nGitHub - Ucas-HaoranWei&#x2F;GOT-OCR2.0: Official code implementation of General OCR Theory:  Towards OCR-2.0 via a Unified End-to-end Model\nucaslcl&#x2F;GOT-OCR2_0 · Hugging Face\nGOT-OCR2.0 - Google ドライブ\nGOT Online - a Hugging Face Space by stepfun-ai\n\n","categories":["Tech","LLM"],"tags":["OCR"]},{"title":"使用自己的大模型 api 在表格中生成","url":"/2025/05/21/LLM/ai%E8%A1%A8%E6%A0%BC/","content":"引言多维表格大家都听说过吧？比起传统的在线表格这玩意有这样几个优势：\n\n本质上是一个在线数据库，所以数据很多很多的时候也不卡\n可以切换多种视图\n支持有限的自动化\n\n对于大众来说，其实不会太在意背后的技术和用不到的功能，所以可能很多人没有实际体验过，甚至对这玩意需要先规定列的属性相当不适应。自动化功能和精细权限管理太难，多视图模式和数据展示用不上，所以何必折腾呢？我的意见是：他真的有 ai 加成…\n其实表格天然就很适合做生成，比起平常文档形式的”上下”视图，表格的”左右”视图可以直观的看到输入的信息和输出的信息。而序号、标题确保了可以快速定位。\n目前有 ai 加成的多维表格首先是飞书和钉钉，还有 Vika 和 Airtable 等等，我平常就用的钉钉，但是他有个问题：他是免费的。免费当然很好，但是当你薅了大几千次 qwen 之后，他会不断的给你显示”等待中”。那么，花钱行不行呢？问题来了，他是免费的…想花钱也没地方花…\n因此，对我来说，重新整一个本地版的 ai 表格就情有可原了，反正技术原理也不复杂。\n本项目用来解决下面几个痛点：\n\n在线表格无法选择 api 供应商\n在线表格可能会触发大型批量使用限制\n\n效果展示GitHub - sandy9707&#x2F;ai-cellfill-excel\n\n使用方式首先需要完成配置，在.config文件里面输入自己的模型 api 和密钥，然后把需要启用的 api 的 ENABLED 改成 true.\n第二，更新 systemprompt.txt 以设置所需的系统提示。\n第三，在没有prompts.xlsx文件的情况下运行python main, 如果包齐全的话会自动生成一个表格，里面含有使用指南和需要填写的信息。\n\n第一列是自动生成的，包含了获取到的系统提示词文件和调用到的 api 模型名称。\n第二列是需要填写的用户提示词，写入后将依次调用 api 回答。\n第三列是是否需要生成，主要用于对结果不满意需要重新生成的情况，通过填入合适的数字决定是否调用 api 进行生成或重复生成。\n第四列是生成结果。\n最后，在有prompts.xlsx存在的情况下，会读取存在的文件对相应的信息进行处理。\n\n结论总之，给自己造了个轮子，该说不说其实原来我也喜欢用 json 之类的，但是跟公司打交道多了发现关系型数据库用得多，然后二维表格妙不可言…\n如果可以结合 teable 之类的数据库型表格就更完美了，但是使用上的复杂度会再高一层，我觉得不好…\n引用\nGitHub - sandy9707&#x2F;ai-cellfill-excel\n\n","categories":["LLM"],"tags":["LLM"]},{"title":"DeepSeek 开源大模型：技术优势、市场影响与使用实践","url":"/2025/02/01/LLM/deepseek_r1_api_siliconflow/","content":"引言在人工智能的浪潮中，DeepSeek 的 R1 模型以其强大的性能和独特的技术架构，迅速在全球 AI 领域崭露头角，甚至被誉为国产大模型的“技术奇点”。那么，DeepSeek 究竟是如何炼成的？它能做什么？我们又该如何利用它呢？\nDeepSeek 的优势、影响力与市场地位DeepSeek R1 模型在技术领域的表现堪称卓越，尤其是在高难度提示词处理、代码生成和数学推理等复杂任务中，其能力远超同类产品。令人瞩目的是，训练这样一款顶尖模型仅需 2048 块 H800 显卡和 600 万美元的成本，这一数字仅为国际同行的 1&#x2F;18，展现了极高的效率与性价比。\n然而，DeepSeek 的火爆并不仅仅源于其技术实力，其独特之处在于两点：\n\n开源策略\n低算力需求\n\nDeepSeek 的成功可以说是开源精神的胜利。它的工具源于开源社区，最终又回馈于开源社区。开源不仅让开发者能够站在巨人的肩膀上，也为后来者提供了攀登的阶梯。通过开源，更多开发者可以参与到模型的微调与训练中，从而推动技术的不断进步。而低算力需求则让这一技术更易于普及，真正惠及大众。正如电灯的发明改变了人类生活，技术的伟大在于其普世价值。至于 DeepSeek 对市场的冲击，从英伟达股价下跌 17%、市值蒸发约 5900 亿美元的数据中可见一斑。\n关于开源，梁文锋有一段访谈发言让我很受感动[3]:\n\n暗涌：但你们究竟是一个商业组织，而非一个公益科研机构，选择创新，又通过开源分享出去，那要在哪里形成护城河？像 2024 年 5 月这次 MLA 架构的创新，也会很快被其他家 copy 吧？\n梁文锋：在颠覆性的技术面前，闭源形成的护城河是短暂的。即使 OpenAI 闭源，也无法阻止被别人赶超。所以我们把价值沉淀在团队上，我们的同事在这个过程中得到成长，积累很多 know-how, 形成可以创新的组织和文化，就是我们的护城河。\n\n此外，DeepSeek 还有一个不可忽视的亮点：它是国产 AI 的杰出代表。它打破了美国在 AI 领域的绝对领先地位，并对 GPT、Claude、Gemini 等严格封锁政策进行了有力回击（尽管部分原因是服务器宕机，但至少让美国也体验了一把被“封锁”的感觉，笑）。\nDeepSeek 和幻方，和老板，和员工构成DeepSeek 能够在当下这个时间点崛起，与其历史背景密不可分。\nDeepSeek 由梁文锋创立，而梁文锋此前也是幻方量化的创始人。幻方量化成立于 2015 年，最初是一家专注于利用 AI 进行投资的对冲基金。\n2023 年，DeepSeek 作为一家独立公司成立，专注于大模型技术的开发，而梁文锋持有约 83.37% 的股份，是公司的主要控制者。\nDeepSeek 与其他公司最大的不同就是员工构成方面：\n员工人数不足 140 人，与 OpenAI 等大型竞争对手相比，规模仅为后者的 10%。主要招聘来自中国顶尖高校（如北大、清华等）的应届毕业生和博士生，注重培养本土人才，而非依赖海外专家。不看业绩，没有任务，没有 kpi, 只有向最难的问题创新。\n\n暗涌：但你们不参与融资，很少对外发声，社会声量上肯定不如那些融资活跃的公司，怎么确保 DeepSeek 就是做大模型的人的首选？\n梁文锋：因为我们在做最难的事。对顶级人才吸引最大的，肯定是去解决世界上最难的问题。其实，顶尖人才在中国是被低估的。因为整个社会层面的硬核创新太少了，使得他们没有机会被识别出来。我们在做最难的事，对他们就是有吸引力的。\n\n\n暗涌：这种发散性灵感的诞生和你们完全创新型组织的架构很有关系。幻方时代，你们就很少自上而下地指派目标或任务。但 AGI 这种充满不确定性的前沿探索，是否多了管理动作？\n梁文锋：DeepSeek 也全是自下而上。而且我们一般不前置分工，而是自然分工。每个人有自己独特的成长经历，都是自带想法的，不需要 push 他。探索过程中，他遇到问题，自己就会拉人讨论。不过当一个 idea 显示出潜力，我们也会自上而下地去调配资源。\n\n待遇方面，DeepSeek 对员工的薪酬相对优厚，采取“一年 14 薪”的模式。核心岗位的薪资可达月薪 11 万元人民币，年薪超过百万。此外，公司还提供实习机会，日薪为 500 元，并有转正名额。\nDeepSeek 的使用方法网页使用接下来介绍 DeepSeek 最核心的功能：\n“深度思考”和联网搜索。\n\n深度思考：用户只需选中输入框下的按钮，就能使模型获得思考能力并在思考后作答。这一功能可以让 ai 理解复杂内容，特别适合学术研究、新闻阅读或技术文档分析等场景，并极大增强了回答准确性和可用性。\n联网搜索：DeepSeek V2.5 版本新增了联网搜索功能，能够从网络信息中提取数据并进行分析，提供更全面、个性化的答案。\n\n这两项功能在用户体验上表现非常出色，既准确又高效。然而，最近 DeepSeek 的深度思考和联网搜索功能都出现了无法使用的情况。用户在尝试时会收到“由于技术原因，联网搜索暂不可用”或“服务器繁忙，请稍后再试”的提示。\n总的来说，尽管 DeepSeek 提供了强大的工具和功能，但目前的技术问题确实影响了用户体验。希望未来能尽快解决这些问题，恢复其高效的服务。\nAPI简单来说，API 是一种接口。你传入一些内容，它就会返回相应的结果。通过这项技术，开发者可以轻松在自己的应用中集成自然语言处理（NLP）、自然语言理解（NLU）和自然语言生成（NLG）等功能，而不需要深入了解模型背后的复杂结构或训练过程。\n如果你关注过 LLM 领域，可能还记得 DeepSeek 上一次火爆的原因——它便宜。没错，它真的很便宜。据梁文锋透露，他们只是定了一个能回本的价格，结果却引发了大模型行业的价格战。这无疑是一件值得高兴的事。\n然而，目前官方的 API 几乎处于不可用的状态。\n硅基流动 (SiliconFlow)市面上有不少可用的 API 供应商，比如 Azure、Groq，甚至英伟达。而硅基流动不仅稳定高效，还基于国产卡部署[1]，尤其适合国内用户。\n那么，硅基流动的 DeepSeek API 有什么特别之处呢？以下几个理由可能会让你觉得它是个不错的选择：\n\n免费额度\n\n如果你是第一次接触 DeepSeek R1 API，完全不用担心费用问题。硅基流动为新用户提供了免费的 API 使用额度，让你可以零风险地体验，看看它是否适合你的项目。\n\n部署在国产卡上，稳定又安全\n\n硅基流动的 DeepSeek R1 API 部署在国产卡上，这意味着它能为国内用户提供更低的延迟和更高的稳定性，避免了跨境数据传输带来的额外延迟。同时，国产卡的部署也确保了数据安全，完全符合国内的合规要求。\n\n支持 DeepSeek R1 和 V3 版本\n\n不同版本的 API 提供了不同的功能和优化。硅基流动同时支持 R1 和 V3 版本，无论是新手还是经验丰富的开发者，都能找到适合自己的接口来解决需求。\n事实上，SiliconFlow 也确实是官方以外价格最低的供应商了。\n想要体验 DeepSeek R1 API？其实非常简单：\n\n点击下方的链接，注册账号。\n获取你的 API 密钥。\n按照文档集成 API，开始使用！\n\n立即注册并获得免费额度\n我的邀请码是jtaKtZMM\n\n基于 SiliconCloud 活动，使用邀请码作为新用户完成 SiliconCloud 账号注册，可立刻获得 2000 万 Tokens。\n结论不得不说失去 r1+ 搜索的组合让我非常不适应，很多原来可以”提问”的内容现在必须自己去搜索。我可以很负责任的说，chatgpt 和 perplexiai 的联网搜索不如 deepseek 远矣，希望大家之后尽量去用一用。\n最后，祝大家新年快乐，恭喜发财~\n篇外api 使用方法[1]如果你想直接在客户端应用里体验 DeepSeek-R1 &amp; V3 模型，可在本地安装以下产品，接入 SiliconCloud 的 API 后（可自定义添加这两款模型），即可体验 DeepSeek-R1 &amp; V3。\n大模型客户端应用：ChatBox、Cherry Studio、OneAPI、LobeChat、NextChat\n代码生成应用：Cursor、Windsurf、Cline\n大模型应用开发平台：Dify\nAI 知识库：Obsidian AI、FastGPT\n翻译插件：沉浸式翻译、欧路词典\n更多场景与应用案例接入教程可参考：https://docs.siliconflow.cn/usercases/awesome-user-cases\nToken 工厂 SiliconCloud Qwen2.5（7B）等 20+ 模型免费用[1]作为一站式大模型云服务平台，SiliconCloud 致力于为开发者提供极速响应、价格亲民、品类齐全、体验丝滑的模型 API。\n除了 DeepSeek-R1、DeepSeek-V3，SiliconCloud 已上架包括 Janus-Pro-7B、CosyVoice2、QVQ-72B-Preview、DeepSeek-VL2、DeepSeek-V2.5-1210、Llama-3.3-70B-Instruct、HunyuanVideo、fish-speech-1.5、Qwen2.5-7B&#x2F;14B&#x2F;32B&#x2F;72B、FLUX.1、InternLM2.5-20B-Chat、BCE、BGE、SenseVoice-Small、GLM-4-9B-Chat 在内的数十种开源大语言模型、图片&#x2F;视频生成模型、语音模型、代码&#x2F;数学模型以及向量与重排序模型。平台支持开发者自由对比、组合各种模态的大模型，为你的生成式 AI 应用选择最佳实践。\n引用\n首发！硅基流动 x 华为云联合推出基于昇腾云的 DeepSeek R1 &amp; V3 推理服务！\nDeepSeek-R1 发布是 AI 发展的一个重大转折\nDeepSeek 创始人专访：中国的 AI 不可能永远跟随，需要有人站到技术的前沿\n\n","categories":["LLM"],"tags":["deepseek"]},{"title":"OPENAI 官网的内容","url":"/2024/01/21/LLM/OPENAI%E5%AE%98%E7%BD%91%E7%9A%84%E5%86%85%E5%AE%B9/","content":"引言在刷 twitter 的时候看到了一个推：\n\n我可不可以说：一个 AI 产品经理没有把 OpenAI 官网所有东西看一遍是不合格的？\n\n所以我觉得我可以仔细看看。\n内容标语Creating safe AGI that benefits all of humanity\nLatest updates保持着 5 天 2 更的速度，恐怖如斯。\nDemocratic inputs to AI grant program: lessons learned and implementation plans更新于 20240116:\n人工智能赠款计划的民主投入：经验教训和实施计划\nWe then awarded $100,000 to 10 teams out of nearly 1000 applicants to design, build, and test ideas that use democratic methods to decide the rules that govern AI systems.\nWe received nearly 1,000 applications across 113 countries. There were far more than 10 qualified teams, but a joint committee of OpenAI employees and external experts in democratic governance selected the final 10 teams to span a set of diverse backgrounds and approaches: the chosen teams have members from 12 different countries and their expertise spans various fields, including law, journalism, peace-building, machine learning, and social science research.\nThe projects spanned different aspects of participatory engagement, such as novel video deliberation interfaces, platforms for crowdsourced audits of AI models, mathematical formulations of representation guarantees, and approaches to map beliefs to dimensions that can be used to fine-tune model behavior.\nHow OpenAI is approaching 2024 worldwide elections更新于 20240115:\nHow OpenAI is approaching 2024 worldwide elections\nOur tools empower people to improve their daily lives and solve complex problems—from using AI to enhance state services to simplifying medical forms for patients.\nPreventing abuseWe expect and aim for people to use our tools safely and responsibly, and elections are no different. We work to anticipate and prevent relevant abuse—such as misleading “deepfakes”, scaled influence operations, or chatbots impersonating candidates. Prior to releasing new systems, we red team them, engage users and external partners for feedback, and build safety mitigations to reduce the potential for harm. For years, we’ve been iterating on tools to improve factual accuracy, reduce bias, and decline certain requests. These tools provide a strong foundation for our work around election integrity. For instance, DALL·E has guardrails to decline requests that ask for image generation of real people, including candidates.\n我们期望并致力于让人们安全、负责任地使用我们的工具，选举也不例外。我们致力于预测和防止相关滥用，如误导性的“深度伪造”、大规模影响力操作或冒充候选人的聊天机器人。在发布新系统之前，我们对其进行红色团队，让用户和外部合作伙伴参与反馈，并制定安全缓解措施，以减少潜在的危害。多年来，我们一直在迭代各种工具，以提高事实的准确性，减少偏见，并拒绝某些请求。这些工具为我们围绕选举诚信开展工作奠定了坚实的基础。例如，DALL·E 有护栏来拒绝要求生成真实人物（包括候选人）图像的请求。\nTransparency around AI-generated contentBetter transparency around image provenance—including the ability to detect which tools were used to produce an image—can empower voters to assess an image with trust and confidence in how it was made. We’re working on several provenance efforts. Early this year, we will implement the Coalition for Content Provenance and Authenticity’s digital credentials—an approach that encodes details about the content’s provenance using cryptography—for images generated by DALL·E 3.\nWe are also experimenting with a provenance classifier, a new tool for detecting images generated by DALL·E. Our internal testing has shown promising early results, even where images have been subject to common types of modifications. We plan to soon make it available to our first group of testers—including journalists, platforms, and researchers—for feedback.\nImproving access to authoritative voting informationIn the United States, we are working with the National Association of Secretaries of State (NASS), the nation’s oldest nonpartisan professional organization for public officials. ChatGPT will direct users to CanIVote.org, the authoritative website on US voting information, when asked certain procedural election related questions—for example, where to vote. Lessons from this work will inform our approach in other countries and regions.We’ll have more to share in the coming months. We look forward to continuing to work with and learn from partners to anticipate and prevent potential abuse of our tools in the lead up to this year’s global elections.\nSafety &amp; responsibilityOur work to create safe and beneficial AI requires a deep understanding of the potential risks and benefits, as well as careful consideration of the impact.\nResearchWe research generative models and how to align them with human values\nProductsOur API platform offers our latest models and guides for safety best practices.\nDALL·E 3DALL·E 3 understands significantly more nuance and detail than our previous systems, allowing you to easily translate your ideas into exceptionally accurate images.\nCareers at OpenAIDeveloping safe and beneficial AI requires people from a wide range of disciplines and backgrounds.\n结论引用\n\n\n","categories":["AI大模型"]},{"title":"一键搭建谷歌 Gemini","url":"/2023/12/21/LLM/%E4%B8%80%E9%94%AE%E6%90%AD%E5%BB%BA%E8%B0%B7%E6%AD%8C%20Gemini/","content":"引言效果展示过程","categories":["Tech","LLM"]},{"title":"使用 Qwen-Agent 结合浏览器插件","url":"/2024/12/05/LLM/%E4%BD%BF%E7%94%A8Qwen-Agent%E7%BB%93%E5%90%88%E6%B5%8F%E8%A7%88%E5%99%A8%E6%8F%92%E4%BB%B6/","content":"引言想找一个可以在浏览器里面直接看 pdf 内容的插件，刚好看到了这个：\n基于 Qwen-Agent 的一个 Chrome 浏览器扩展，一个智能浏览器助手：BrowserQwen。\n效果展示\n\n过程因为没有本地搭建，而是使用 api, 所以用不使用 DashScope 的方案。\ngit clone https://github.com/QwenLM/Qwen-Agent.gitcd Qwen-Agentpip install -e ./&quot;[gui,rag,code_interpreter,python_executor]&quot;# Or `pip install -e ./` for minimal requirements.# 指定模型服务，并启动数据库服务。# 示例: 假设Qwen1.5-72B-Chat已经通过vLLM部署于http://localhost:8000/v1，则可用以下参数指定模型服务：#   --llm Qwen1.5-72B-Chat --model_server http://localhost:8000/v1 --api_key EMPTYpython run_server.py --llm &#123;MODEL&#125; --model_server &#123;API_BASE&#125; --workstation_port 7864 --api_key &#123;API_KEY&#125;\n\n如果需要局域网访问，可以指定server_host为0.0.0.0, 代码就是在命令后加--server_host 0.0.0.0。\n顺便说一下，魔搭社区提供了每天 1000 次的 Qwen&#x2F;Qwen2.5-72B-Instruct 等模型的免费额度，可以用来测试。\n创建守护进程在实际的运行中，为了避免每次启动服务，可以创建守护进程。\n使用 cat &lt;&lt; &#39;EOF&#39; &gt; qwen-server.service 创建服务文件。\ncat &lt;&lt; &#x27;EOF&#x27; &gt; qwen-server.service[Unit]Description=Qwen Server ServiceAfter=network.target[Service]Type=simpleUser=$USERWorkingDirectory=$Qwen-Agent-pathExecStart=$python3-path run_server.py --llm model --model_server api_server_url --workstation_port 7864 --api_key api_key --server_host 0.0.0.0Restart=alwaysRestartSec=3[Install]WantedBy=multi-user.targetEOF\n\n替换 model、api_server_url、api_key为实际的值，Qwen-Agent-path 和 python3-path 为实际路径。\n之后把文件复制到 /etc/systemd/system/ 目录下，并设置权限。\n## 复制文件并设置权限sudo cp qwen-server.service /etc/systemd/system/sudo chmod 644 /etc/systemd/system/qwen-server.servicesudo systemctl daemon-reloadsudo systemctl enable qwen-serversudo systemctl start qwen-server## 查看状态sudo systemctl status qwen-server\n\n安装浏览器插件Chrome 浏览器插件安装非常简单，直接 git clone 下来，然后打开 chrome 的扩展程序，选择加载已解压的扩展程序，选择下载的文件夹中的BrowserQwen即可。\n火狐的需要改一下文件，可以使用 Cursor 等让他改，很快就能改好，然后保存，在火狐地址栏输入about:debugging，选择加载临时附加，选择下载的文件夹中的manifest.json即可。\n火狐的浏览器插件压缩包地址：\n通过网盘分享的文件：20241221_火狐插件 browser_qwen.zip链接：https://pan.baidu.com/s/1Wq-qKbKQkquctnVgLO5zhQ?pwd=nkjj 提取码：nkjj–来自百度网盘超级会员 v4 的分享\n工作区的访问端口是 7864，本机就是就是http://localhost:7864, 局域网访问就是http://ip:7864。\n结论实际体验相当不错，比如可以在多篇文献的网页添加后直接给出总结，引用也是完全正确，我觉得完全可以当一个合格的助手使用了。\n引用\nQwen-Agent&#x2F;browser_qwen_cn.md at main · QwenLM&#x2F;Qwen-Agent · GitHub\n\n","categories":["LLM"],"tags":["Qwen-Agent","agent"]},{"title":"食物识别大模型能力比较","url":"/2024/11/04/LLM/%E9%A3%9F%E7%89%A9%E8%AF%86%E5%88%AB%E5%A4%A7%E6%A8%A1%E5%9E%8B%E8%83%BD%E5%8A%9B%E6%AF%94%E8%BE%83/","content":"引言工作需要，对食物识别大模型能力进行比较。\n效果展示过程moondream2极差，青椒炒蛋变成肌肉了…\n使用方法倒是挺简单的，详细代码放到后面。\n百度 AI 开放平台菜品识别_识别 5 万多种菜品且支持自建菜品图库 - 百度 AI 开放平台\n提供了试用接口和 api, 注册也简单，但是正确率一般，而且只提供卡路里的返回值。\n美团 T-PAMI\n大规模食品图像识别：T-PAMI 2023 论文解读 - 美团技术团队\nLarge-Scale Food Recognition via Deep Progressive Self-Transformer Network\nGitHub - Liuyuxinict&#x2F;prenet\n\n数据下载需要联系作者，发邮件进行申请。\n\nThis dataset can be obtained by sending a request email to us. Specifically, the researchers interested in it should download and fill up this Agreement Form and send it back to us (&#102;&#111;&#111;&#x64;&#99;&#111;&#x6d;&#112;&#x75;&#x74;&#105;&#x6e;&#x67;&#103;&#114;&#x6f;&#x75;&#x70;&#64;&#x67;&#109;&#97;&#105;&#108;&#46;&#99;&#x6f;&#109;; Email title: Food2K dataset request). We will then send you the download instructions.\n\n复旦发布 FoodLMM复旦发布 FoodLMM，食材辨别&#x2F;菜谱生成&#x2F;营养分析样样行！_51CTO 博客_复旦 营养学\n手把手教你构建食物识别AI手把手教你构建食物识别AI：小白轻易可上手，人气高赞有Demo\nYOLOv5ollama结论引用\n\n\n","categories":["Tech","LLM"],"tags":["大模型","食物识别"]},{"title":"使用 browser-use-webui 进行网页信息填写和录入","url":"/2025/03/11/LLM/%E4%BD%BF%E7%94%A8browser-use-webui%E8%BF%9B%E8%A1%8C%E7%BD%91%E9%A1%B5%E4%BF%A1%E6%81%AF%E5%A1%AB%E5%86%99%E5%92%8C%E5%BD%95%E5%85%A5/","content":"引言在数字化时代，网页信息填写和录入是许多业务流程中的重要环节，例如注册账户、提交在线表单或更新个人信息。这些任务往往耗时且容易出错，而自动化工具的引入可以显著提高效率并减少人为失误。GitHub 上的 browser-use&#x2F;web-ui 项目为这一需求提供了一个创新且实用的解决方案。\n事实上，browser-use 已经提供了一个通用的浏览器自动化工具，但 browser-use&#x2F;web-ui 更进一步，提供了一个基于 Gradio 构建的 Web 用户界面，并支持多种大型语言模型（LLM），包括 Google、OpenAI、Azure OpenAI、Anthropic、DeepSeek 和 Ollama 等。它允许用户在浏览器中运行 AI 代理，自动完成网页交互任务。该工具的独特功能包括支持自定义浏览器（无需重复登录网站）、高清屏幕录制以及持久化浏览器会话，非常适合需要高效处理网页任务的用户。\n本文将详细介绍如何通过本地安装（使用 pip）和 Docker 安装两种方式使用 browser-use&#x2F;web-ui，并提供完整的操作流程。\n效果展示使用过程以下是使用 browser-use&#x2F;web-ui 的两种主要安装和运行方式：本地安装（pip） 和 Docker 安装。请根据您的需求选择适合的方法。\nDocker 安装1. 克隆仓库与本地安装相同，克隆项目仓库：\ngit clone https://github.com/browser-use/web-ui.gitcd web-ui\n\n2. 创建并配置环境文件复制并编辑环境文件：\n\n**Windows (Command Prompt)**：\n\ncopy .env.example .env\n\n\n**macOS&#x2F;Linux&#x2F;Windows (PowerShell)**：\n\ncp .env.example .env\n\n编辑 .env 文件，添加 API 密钥，例如：\nOPENAI_API_KEY=your_openai_keyVNC_PASSWORD=your_vnc_password  # 可选，设置 VNC 密码\n\n3. 运行 Docker根据需求选择运行模式：\n\n默认模式（任务后关闭浏览器）：\n\ndocker compose up --build\n\n\n持久化模式（任务间保持浏览器打开）：\n\nCHROME_PERSISTENT_SESSION=true docker compose up --build\n\n4. 访问应用程序\nWeb 界面：打开浏览器，访问 http://localhost:7788。\nVNC 查看器（观察浏览器交互）：访问 http://localhost:6080/vnc.html，输入 VNC 密码（默认“youvncpassword”，或 .env 中设置的密码）。\n\n5. 容器管理（可选）\n后台运行：\n\ndocker compose up -d\n\n\n查看日志：\n\ndocker compose logs -f\n\n\n停止容器：\n\ndocker compose down\n\n\n本地安装（使用 pip）克隆仓库首先，打开终端并运行以下命令，克隆项目仓库到本地：\ngit clone https://github.com/browser-use/web-ui.gitcd web-ui\n\n设置 Python 环境建议使用 Python 3.11，并通过 uv 工具创建虚拟环境。执行以下命令：\nuv venv --python 3.11\n\n激活虚拟环境：\n\n**Windows (Command Prompt)**：\n\n.venv\\Scripts\\activate\n\n\n**Windows (PowerShell)**：\n\n.\\.venv\\Scripts\\Activate.ps1\n\n\nmacOS&#x2F;Linux：\n\nsource .venv/bin/activate\n\n安装依赖安装项目所需的 Python 包和 Playwright：\nuv pip install -r requirements.txtplaywright install\n\n配置环境复制示例环境文件并编辑，添加您的 API 密钥和其他配置：\n\n**Windows (Command Prompt)**：\n\ncopy .env.example .env\n\n\n**macOS&#x2F;Linux&#x2F;Windows (PowerShell)**：\n\ncp .env.example .env\n\n使用文本编辑器打开 .env 文件，填写必要信息，例如：\nOPENAI_API_KEY=your_openai_keyCHROME_PATH=&quot;C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe&quot;  # Windows 示例CHROME_USER_DATA=&quot;C:\\Users\\YourUsername\\AppData\\Local\\Google\\Chrome\\User Data&quot;  # Windows 示例\n\n运行 Web UI启动应用程序：\npython webui.py --ip 127.0.0.1 --port 7788\n\n访问 Web UI打开浏览器，导航到 http://127.0.0.1:7788，即可使用 Web 界面。\n使用自定义浏览器（可选）如果需要使用自己的浏览器（如已登录账户的 Chrome），在 .env 文件中设置：\n\nWindows：\n\nCHROME_PATH=&quot;C:\\Program Files\\Google\\Chrome\\Application\\chrome.exe&quot;CHROME_USER_DATA=&quot;C:\\Users\\YourUsername\\AppData\\Local\\Google\\Chrome\\User Data&quot;\n\n\nmacOS：\n\nCHROME_PATH=&quot;/Applications/Google Chrome.app/Contents/MacOS/Google Chrome&quot;CHROME_USER_DATA=&quot;/Users/YourUsername/Library/Application Support/Google/Chrome&quot;\n\n关闭所有 Chrome 窗口，在非 Chrome 浏览器（如 Firefox）中打开 Web UI，并在界面中勾选“Use Own Browser”选项。\n保持浏览器打开（可选）若希望在 AI 任务间保持浏览器窗口打开，可在 .env 中设置：\nCHROME_PERSISTENT_SESSION=true\n\n使用 VNC 访问浏览器可以连接 5901 端口，而使用 Web UI 访问浏览器可以连接 6080 端口。\n\n结论browser-use&#x2F;web-ui 是一个功能强大且灵活的工具，能够有效自动化网页信息填写和录入任务。通过支持多种大型语言模型和自定义浏览器配置，它可以无缝集成到现有工作流程中。无论是选择本地安装（pip）还是 Docker 部署，用户都能通过简单的步骤快速上手，显著提升工作效率并减少错误。对于需要频繁处理网页交互的用户来说，这款工具无疑是一个值得尝试的解决方案。\n\n问题解决旧版本 docker compose 升级sudo mkdir -p /etc/apt/keyringscurl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpgecho &quot;deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu $(lsb_release -cs) stable&quot; | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/nullsudo apt updatesudo apt install docker-compose-plugindocker compose version\n\n参考\nbrowser-use&#x2F;web-ui GitHub 仓库\n项目文档\n\n","categories":["LLM"],"tags":["browser-use-webui"]},{"title":"Node 转录组数据库批量下载指南","url":"/2025/03/24/bioinformatics/Node%E8%BD%AC%E5%BD%95%E7%BB%84%E6%95%B0%E6%8D%AE%E5%BA%93%E6%89%B9%E9%87%8F%E4%B8%8B%E8%BD%BD%E6%8C%87%E5%8D%97/","content":"随着转录组研究的深入，研究人员需要从转录组数据库中获取大量的 RNA 测序数据以支持基因表达、选择性剪接等分析。除了我们常用的 GEO（基因表达总库）和 ArrayExpress 数据库，还有一些数据库可以获得 RNA 测序数据比如 Node 转录组数据库 (National Omics Data Encyclopedia, 国家组学数据百科全书：多组学大数据共享平台，Node 数据库)。在本文中，我们将详细介绍 Node 转录组数据库的特点及其批量下载方法，帮助您高效获取所需数据。\n本文用到的软件均可以使用 conda 直接下载安装。\n一、Node 转录组数据库简介Node 数据库是一个多组学数据平台，它为研究人员提供了一个集中的数据存储和访问接口，主要包括这些数据类型：\n\nDNA 数据：如全基因组测序（WGS）、外显子组测序（WES）、靶向测序等。\nRNA 数据：如 RNA-Seq 数据（转录组测序）、单细胞 RNA-Seq、非编码 RNA 等。\n其他数据：蛋白质组、代谢组、表观遗传学数据等。\n\n下面是官网介绍：\n\nNODE 是一个生物大数据收集平台，包括实验样本信息的收集、序列文件的上传以及结果的分析、共享和下载。NODE 平台由六个主要模块组成：项目、样本、实验、运行、数据和分析。项目和样本是独立的，但可以通过运行进行链接，这样可以实现元数据和序列信息的整合。help - Node - National Omics Data Encyclopedia\n\n\n生物医学大数据中心隶属于中国科学院上海营养与健康研究所，致力于 1) 为中国科学院、上海及全国的生物医学研究提供全周期大数据服务，包括数据收集和共享、数据管理和分析；2) 构建数据安全、整合、共享和挖掘的技术框架，加速生物医学数据资源的协作网络；3) 增强国家生物医学大数据系统，促进生命科学数据丰富发现的范式转变，加速生物学、医学、数学和信息技术之间的跨学科融合，提高国家的“融合研究”能力。National Omics Data Encyclopedia\n\nNode 数据库支持多种下载途径，包括 HTTP 和 SFTP。对于小文件，HTTP 可能是默认选择，但对于超过 200MB 的大文件，HTTP 下载可能受限，此时需要使用 SFTP。\n二、在 HTTP 无法下载 200MB 文件时如何使用 SFTP当文件大小超过 200MB 时，Node 数据库可能出于服务器限制或安全考虑，禁止通过 HTTP 下载。此时，SFTP（Secure File Transfer Protocol）成为理想选择。SFTP 通过 SSH 协议加密传输数据，确保安全性和稳定性，非常适合大文件的批量下载。\n1. SFTP 下载工具介绍以下是常用的 SFTP 下载工具：\n\nsftp 命令行工具：Unix-like 系统（如 Linux、macOS）内置的工具，支持交互式文件传输。\nlftp：功能强大的命令行工具，支持 SFTP、FTP 等多种协议，适合自动化和批量下载。\n图形化客户端：如 FileZilla、Cyberduck，提供直观界面，但不适合脚本化操作。\n编程库：如 Python 的 Paramiko 或 Node.js 的 ssh2-sftp-client，适用于开发自定义下载脚本。\n\n对于批量下载，命令行工具（如 sftp 和 lftp）因其灵活性和可脚本化特性更为推荐。\n2. 使用命令行下载使用 sftp 基本下载\nsftp 用户名@主机地址\n\n连接成功后，可使用以下命令：\n\n下载单个文件：get 远程文件 本地文件\n下载多个文件：mget *.txt（支持通配符）\n\n示例：\nsftp&gt; get data.fastq /local/path/data.fastqsftp&gt; mget *.fastq\n\nsftp 适合简单下载，但对于批量任务，操作繁琐，建议使用 lftp。\n三、使用 lftp 的 pget 进行多线程下载lftp 是一个功能强大的文件传输工具，支持 SFTP，并提供多种高级功能。然而，需注意：SFTP 基于 SSH，通常使用单一连接，因此其 pget 命令的多线程下载功能在 SFTP 协议下可能受限。多线程下载（如文件分段并行）更适用于 HTTP 或 FTP（若服务器支持范围请求）。尽管如此，lftp 仍可通过并行连接下载多个文件，从而提升效率。\n基本使用lftp sftp://用户名@主机地址\n\n下载单个文件：\nlftp&gt; get remote_file.txt\n\n使用 pget 下载pget 是 lftp 的一个子命令，通常用于加速下载。对于支持多线程的协议（如 HTTP&#x2F;FTP），可通过-n参数指定线程数：\nlftp -e &quot;pget -n 4 remote_file.txt&quot; sftp://用户名@主机地址\n\n但对于 SFTP，由于协议限制，pget 无法将单个文件分割成多线程下载。因此，若目标是单个大文件，下载仍为单线程。对于支持 ftp 或 http 的服务器，pget 可以显著提高下载速度。\n并行下载多个文件虽然 SFTP 不支持单文件多线程，但 lftp 可以通过设置多个并发连接来同时下载多个文件。配置方法如下：\nlftp -u 用户名,密码 sftp://主机地址 &lt;&lt; EOFset sftp:max-connections 5mirror 远程目录 本地目录byeEOF\n\n\nsftp:max-connections 5：设置最多 5 个并发连接。\nmirror：递归下载整个目录。\n主机地址: Node 数据库的 SFTP 地址。fms.biosino.org:44398\n用户名,密码: Node 数据库的用户名和密码。\n远程目录: 远程服务器上的目录路径。\n本地目录: 本地存储目录。\nEOF：结束 lftp 命令。\nbye：退出 lftp。\n\n这将并行下载多个文件，显著缩短总耗时。\n但是在 node 数据库中，fastq 文件往往不是在同一个文件夹内，所以我们往往无法使用 mirror 命令来下载所有的 fastq 文件，这时我们需要在脚本中使用循环来实现。\n四、使用 Shell 脚本批量下载Shell 脚本结合 lftp 可以实现自动化批量下载，适合处理大量文件或定时任务。\n下载指定文件列表首先我们需要从官网获取目标文件的下载链接。我们可以在官网上下载到一个 experiment_OEX***_data_download_link 的文件，这个文件中包含了我们需要下载的所有文件的链接。\n主要信息有：\n\nproject_id：项目 ID\nexperiment_id：实验 ID\nsample_id：样本 ID\nrun_id：运行 ID\ndata_id：数据 ID\nsecurity：安全性\nfileName：文件名\nurl：下载链接\nftp_file_path：FTP 文件路径\nMD5：文件的 MD5 值\n\n其中，ftp_file_path 是我们需要下载的文件的路径，url 是我们可以直接下载的链接。\n如果文件均小于 200MB，我们可以直接使用 wget 和 axel 命令来下载，这样是最快速便捷的。可惜，单细胞的数据都在 15G 以上，所以我们需要使用 SFTP 来下载。\n下载指定文件以下脚本下载一组指定文件：\n#!/bin/bashUSER=&quot;用户名&quot;PASSWORD=&quot;密码&quot;HOST=&quot;主机地址&quot;REMOTE_DIR=&quot;/path/to/remote/dir&quot;LOCAL_DIR=&quot;/path/to/local/dir&quot;MAX_JOBS=5 # 最大并行任务数files_num=$(wc -l &lt; dw_links.txt)if [ -f &quot;dw_links.txt&quot; ]; then  while IFS= read -r REMOTE_PATH; do    REMOTE_PATH=$(echo $REMOTE_PATH | xargs) # 去除多余的空格    FILENAME=$(basename &quot;$REMOTE_PATH&quot;)      # 提取文件名    echo &quot;Preparing to download $FILENAME from $REMOTE_PATH...&quot;    # 使用 lftp 的 get 命令进行下载    echo &quot;Downloading $FILENAME...&quot;    (      lftp -u $USER,$PASSWORD sftp://$HOST &lt;&lt; EOF      # get $REMOTE_PATH -o $LOCAL_PATH/$FILENAME      pget -n 1 $REMOTE_PATH -o $LOCAL_PATH/$FILENAME      byeEOF    ) &amp; # 将下载任务放入后台    # 限制并行任务数    while [ $(jobs -r | wc -l) -ge $MAX_JOBS ]; do      echo &quot;Current running jobs: $(jobs -r | wc -l)&quot;      sleep 1 # 等待任务完成    done  done &lt;dw_links.txt  # 等待所有后台任务完成  waitelse  echo &quot;dw_links.txt doesn&#x27;t exist!&quot;fi\n\n\n&amp;：将每个下载任务放入后台运行，实现并行。\nwait：等待所有任务完成。\nMAX_JOBS：设置最大并行任务数，避免过多连接导致服务器拒绝服务，如果pget设置了 n 参数比如 4, 这里要相应的乘以 4。\n\n注意，dw_links.txt 文件中包含要下载的文件列表，每行一个文件路径。脚本会读取该文件并逐个下载。如：\n/Public/byRun/OER00/OER0008/OER000883/OER00088390/GBC_C_4_S1_L001_R2_001.fastq.gz/Public/byRun/OER00/OER0008/OER000883/OER00088387/GBC_C_1_S1_L001_R1_001.fastq.gz\n\n此脚本使用 5 个并发连接递归下载远程目录。\n注意事项\n\n服务器限制：并行连接数应根据服务器政策调整，避免超限导致连接失败。\n大文件处理：SFTP 下单个大文件无法多线程，若需加速，可检查数据库是否支持 FTP&#x2F;HTTP 替代协议。\n\n五、总结Node 转录组数据库为研究者提供了丰富的 RNA 测序数据资源。在 HTTP 无法下载超过 200MB 文件的情况下，SFTP 结合 lftp 成为高效解决方案。通过 sftp 进行基础下载，或利用 lftp 的并行连接功能批量获取多个文件，再配合 Shell 脚本自动化操作，您可以轻松管理大规模数据下载任务。尽管 SFTP 不支持单文件多线程下载，但通过优化多文件并行策略，仍可显著提升效率。希望本文能助您顺利开展转录组研究！\n六、篇外sftp 的 get 命令有一个问题是如果检测到本地文件已经存在就不会下载了，而这个本地文件不一定是完整的。我们可以使用 -a 参数来强制覆盖本地文件，但是我们需要先效验文件的完整性，而我们从官网下载到的 experiment_OEX***_data_download_link 文件中是有文件的 md5 值。我们可以使用 md5sum 命令来计算文件的 md5 值，命令如下：\n# 检查 dw_links.txt 是否存在REMOTE_DIR=&quot;/path/to/remote/dir&quot;LOCAL_DIR=&quot;/path/to/local/dir&quot;LOCAL_MD5_RECORD=&quot;$LOCAL_DIR/local_md5_record.txt&quot;MD5_FILE=&quot;/path/to/md5_file.txt&quot;MAX_JOBS=5 # 最大并行任务数if [ -f dw_links.txt ]; then  # 逐行读取 dw_links.txt 中的路径  while IFS= read -r REMOTE_PATH; do    REMOTE_PATH=$(echo $REMOTE_PATH | xargs) # 去除多余的空格    FILENAME=$(basename &quot;$REMOTE_PATH&quot;)      # 提取文件名    echo &quot;Preparing to download $FILENAME from $REMOTE_PATH...&quot;    # 检查文件是否已存在并校验    if [ -f &quot;$LOCAL_PATH/$FILENAME&quot; ]; then      if grep -q &quot;$FILENAME&quot; &quot;$LOCAL_MD5_RECORD&quot;; then        echo &quot;$FILENAME already verified. Skipping.&quot;        continue      fi      # 计算 MD5 并校验      file_md5=$(md5sum &quot;$LOCAL_PATH/$FILENAME&quot; | awk &#x27;&#123;print $1&#125;&#x27;)      if grep -q &quot;$file_md5&quot; &quot;$MD5_FILE&quot;; then        echo &quot;$FILENAME is valid. Recording MD5 locally.&quot;        echo &quot;$FILENAME $file_md5&quot; &gt;&gt;&quot;$LOCAL_MD5_RECORD&quot;        continue      else        echo &quot;$FILENAME exists but failed verification. Deleting.&quot;        rm -f &quot;$LOCAL_PATH/$FILENAME&quot;      fi    fi    # 使用 lftp 的 get 命令进行下载    echo &quot;Downloading $FILENAME...&quot;    (      # 使用 lftp 的 get 命令进行下载      # lftp -u $USER,$PASSWORD sftp://$HOST &lt;&lt; EOF      # 下载完成后校验 MD5      if [ -f &quot;$LOCAL_PATH/$FILENAME&quot; ]; then        file_md5=$(md5sum &quot;$LOCAL_PATH/$FILENAME&quot; | awk &#x27;&#123;print $1&#125;&#x27;)        if grep -q &quot;$file_md5&quot; &quot;$MD5_FILE&quot;; then          echo &quot;$FILENAME is valid. Recording MD5 locally.&quot;          echo &quot;$FILENAME $file_md5&quot; &gt;&gt;&quot;$LOCAL_MD5_RECORD&quot;        else          echo &quot;$FILENAME downloaded but failed verification. Deleting.&quot;          rm -f &quot;$LOCAL_PATH/$FILENAME&quot;        fi      fi    ) &amp; # 将下载任务放入后台    # 限制并行任务数    while [ $(jobs -r | wc -l) -ge $MAX_JOBS ]; do      echo &quot;Current running jobs: $(jobs -r | wc -l)&quot;      sleep 1 # 等待任务完成    done  done &lt;dw_links.txt  # 等待所有后台任务完成  waitelse  echo &quot;dw_links.txt doesn&#x27;t exist!&quot;fi\n","categories":["生物信息学"],"tags":["生物信息学","bioinformatics"]},{"title":"使用 OpenHands 完成任务","url":"/2024/11/13/LLM/openhands/","content":"引言试用 OpenHands 完成任务。\n过程模型选择openhands 默认的多种模型提供商基本都是国外的，包括 OpenAI、Anthropic、Google 等。但是国内使用非常麻烦，正好 11 月 12 号阿里开源了 qwen2.5-coder, 可以使用看一下效果。\n这里使用 ollama 来启动 qwen2.5-coder:32b。\nollama serverollama run qwen2.5-coder:32b\n\n然后再用 nginx 反向代理 ollama 的 11434 端口到 0.0.0.0:11435。\n测试：\ncurl -X POST http://localhost:11435/v1/chat/completions -H &quot;Content-Type: application/json&quot; -d &#x27;&#123;&quot;messages&quot;: [&#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: &quot;你好&quot;&#125;]&#125;&#x27;\n\n这一步是因为如果用 docker 启动 OpenHands 的话，不使用 network&#x3D;host, 是没有办法将 localhost 或者 127.0.0.1 映射到 docker 容器中的 ip 的，除此之外也考虑到其他软件的使用，所以这一步还是推荐做一下。\n下载和配置 OpenHandsOpenHands 的下载相当简单，直接使用 docker 拉取镜像即可。如果遇到端口冲突可以修改 3000 端口为自定义端口 (前面的是真实端口)。\ndocker pull docker.all-hands.dev/all-hands-ai/runtime:0.13-nikolaikdocker run -it --pull=always \\    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.13-nikolaik \\    -v /var/run/docker.sock:/var/run/docker.sock \\    -p 3000:3000 \\    -e LOG_ALL_EVENTS=true \\    --add-host host.docker.internal:host-gateway \\    --name openhands-app \\    docker.all-hands.dev/all-hands-ai/openhands:0.13\n\n在 web 界面选择 Advanced Options, 配置如下：\n\nCustom Model 选择 ollama/qwen2.5-coder:32b\nBase URL 选择 http://[ip]:11435\nAPI Key 留空\nAgent 选择 CodeActAgent\nSecurity Analyzer (Optional) 选择 None\n\n实际体验中发现他会自动调用网页浏览器来获取信息，所以建议网络设置成 host 而不是 bridge。\ndocker run -it --pull=always \\    --network host \\    -e SANDBOX_RUNTIME_CONTAINER_IMAGE=docker.all-hands.dev/all-hands-ai/runtime:0.13-nikolaik \\    -v /var/run/docker.sock:/var/run/docker.sock \\    -e LOG_ALL_EVENTS=true \\    --add-host host.docker.internal:host-gateway \\    --name openhands-app \\    docker.all-hands.dev/all-hands-ai/openhands:0.13\n\n结论成功是成功了，但是效果只能说一般，首先是运行太慢，其次是生成代码的效果一般。\n我先后使用了 7b 和 32b，7b 是直接无法做到对于工作区的操作，32b 的效果要好一些，但是依然效果非常有限。\n所以最终还是选择了 openrouter.ai 的 claude-3-5-sonnet-20241022 api 来完成任务。\n后续 (20241206), 非常非常贵!!! 上次一次构建花了我 40 块钱的样子，完成度也就和 blot.new 差不多，但是那个免费啊…\n引用\nGitHub - All-Hands-AI&#x2F;OpenHands: 🙌 OpenHands: Code Less, Make More\n🤖 LLM 后端 | OpenHands\nollama\nYouTube\n\n","categories":["Tech","LLM"],"tags":["OpenHands"]},{"title":"魔搭 ModelScope (二)","url":"/2024/11/06/LLM/modelscope2/","content":"引言效果展示过程模型训练和评估如果你想进一步使用自己的数据集进行模型训练，ModelScope 提供了丰富的预训练模型，并提供了简单易用的调用接口和统一的配置文件设计，允许用户仅用十几行 Python 代码就可以启动微调任务。以下以一个简单的文本分类任务为例，演示如何使用十几行代码启动端到端的微调任务。总体流程包括以下步骤：\n\nDataset Loaading\nData Preprocessing\nTraining\nEvaluation\n\nDataset LoaadingModelScope 提供了标准的 MsDataset 接口，供用户基于 ModelScope 生态加载数据源。以下是加载 NLP 领域的 afqmc（蚂蚁金融问答匹配语料库）数据集的示例。\nfrom modelscope.msdatasets import MsDataset\n\n# Load training data\n\ntrain_dataset = MsDataset.load(&#39;afqmc_small&#39;, split=&#39;train&#39;)\n\n# Load evaluation data\n\neval_dataset = MsDataset.load(&#39;afqmc_small&#39;, split=&#39;validation&#39;)\n\n关于数据集的详细说明，请参考 [数据集介绍](../dataset/introduction.md)。\n\n#### Data Preprocessing\n\n在 ModelScope 中，数据预处理与模型强相关。因此，在指定模型后，ModelScope 框架会自动从对应的模型卡片中读取配置文件中的预处理器关键字，并自动完成预处理器的实例化。\n\n# text classification ModelHub\n\nmodel_id = &#39;damo/nlp_structbert_sentence-similarity_chinese-tiny&#39;\n\n配置文件\n\n...\n&quot;preprocessor&quot;:&#123;\n    &quot;type&quot;: &quot;sen-cls-tokenizer&quot;,\n  &#125;,\n...\n\n当然，对于高级用户，配置文件也支持用户自定义，并从任意本地路径读取。关于配置文件的详细说明，请参考文档：[配置文件解释](../configuration/explanation.md)。\n\n#### Training\n\n我们支持单卡训练和分布式训练。请根据机器配置选择以下方法之一。如果是新手，建议优先选择单卡方法。\n\n#### Single Card\n\n首先，配置训练所需的参数：\n\nfrom modelscope.trainers import build_trainer\n\n# specify the work directory\n\ntmp_dir = &quot;/tmp&quot;\n\n# parameters config\n\nkwargs = dict(\n        model=model_id,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        work_dir=tmp_dir)\n\n其次，根据参数实例化训练器对象\n\n```python\ntrainer = build_trainer(default_args=kwargs)\n\n最后，调用训练器对象的训练接口\n\n```python\ntrainer.train()\n\nCongratulations, you have completed a model training!😀\n\n#### Distributed\n\n首先，准备训练脚本，并将以下代码保存为 ./train.py 脚本：\n\nimport argparse\nimport os\n\nfrom modelscope.trainers import build_trainer\n\nparser = argparse.ArgumentParser(description=&#39;Train a ModelHub&#39;)\nparser.add_argument(&#39;--local_rank&#39;, type=int, default=0)\nargs = parser.parse_args()\nif &#39;LOCAL_RANK&#39; not in os.environ:\n    os.environ[&#39;LOCAL_RANK&#39;] = str(args.local_rank)\n\n# specify the work directory\n\ntmp_dir = &quot;/tmp&quot;\n\n# parameters config\n\nkwargs = dict(\n        model=model_id,\n        train_dataset=train_dataset,\n        eval_dataset=eval_dataset,\n        work_dir=tmp_dir,\n        launcher=&#39;pytorch&#39;  # Distributed startup\n)\n\n其次，根据参数实例化训练器对象\n\n```python\ntrainer = build_trainer(default_args=kwargs)\n\n最后，调用训练器对象的训练接口\n\n```python\ntrainer.train()\n\n然后，启动分布式训练：\n\nPyTorch:\n\nSingle node with multiple GPU cards:\n\n$ python -m torch.distributed.launch --nproc_per_node=$&#123;NUMBER_GPUS&#125; --master_port=$&#123;MASTER_PORT&#125; ./train.py\n\n    nproc_per_node: The number of processes created by the current host (number of GPUs used), for example--nproc_per_node=8。\n    master_port: The port number of the master node, for example--master_port=29527。\n\nMultiple nodes and multiple GPU cards::\n\nTake two nodes as an example.\n\nNode 1:\n\npython -m torch.distributed.launch --nproc_per_node=$&#123;NUMBER_GPUS&#125; --nnodes=2 --node_rank=0 --master_addr=$&#123;YOUR_MASTER_IP_ADDRESS&#125; --master_port=$&#123;MASTER_PORT&#125; ./train.py\n\nNode 2:\n\npython -m torch.distributed.launch --nproc_per_node=$&#123;NUMBER_GPUS&#125; --nnodes=2 --node_rank=1 --master_addr=$&#123;YOUR_MASTER_IP_ADDRESS&#125; --master_port=$&#123;MASTER_PORT&#125; ./train.py\n\n    nproc_per_node: The number of processes created by the current host (number of GPUs used), for example --nproc_per_node=8.\n    nnodes: the number of nodes.\n    node_rank: the index value of the current node.\n    master_addr: the ip address of the master node, for example --master_addr=104.171.200.62.\n    master_port: The port number of the master node, for example --master_port=29527.\n\nCongratulations, you have completed a model distributed training!😀\nEvaluation#\n\nAfter the training is completed, configure the evaluation data set and directly call the evaluate function of the trainer object to complete the evaluation of the model.\n\n# Directly call trainer.evaluate, you can pass in the ckpt generated in the train stage\n\n# You can also directly verify the ModelHub without passing in parameters\n\nmetrics = trainer.evaluate(checkpoint_path=None)\nprint(metrics)\n\nModelScope also supports synchronous cross-validation during training. You need to configure the EvaluationHook of train.hooks in the config file. The specific configuration is as follows:\n\n&#123;\n   ...\n  &quot;train&quot;: &#123;\n     ...\n      &quot;hooks&quot;: [\n          ...\n          , &#123;\n          &quot;type&quot;: &quot;EvaluationHook&quot;,\n          &quot;by_epoch&quot;: false,\n          &quot;interval&quot;: 100\n      &#125;]\n  &#125;,\n\n&#125;\n\nUsers can adjust the configuration file according to their actual situation, or register the corresponding hook by themselves and call it in the configuration file through the type field registration.\nTutorials#\n\ncongratulations! At this point you have successfully learned the complete use of a model. If you want to know more about the platform functions, you can specifically refer to the corresponding function modules. At the same time, the platform provides corresponding tutorials to help you better understand the application of the model! We also welcome you to join our community to contribute your models and ideas, and jointly build a green open source community! For detailed tutorials, please see:\n\n## 结论\n\n## 引用\n\n1.\n\n"},{"title":"魔搭 ModelScope 介绍和使用实录 (一)","url":"/2024/11/05/LLM/modelscope1/","content":"引言本文详细介绍了魔搭（ModelScope）平台的基本概念和使用方法，从环境配置到模型下载、加载和推理的完整流程，并以实际操作为例展示了平台的使用方式。\n其实，我对魔搭 ModelScope 是有一些感情在的，因为我的第一次大模型微调经验就是基于魔搭平台，并且凭此获得了数字中国创新大赛的奖项。\n有趣的是，出于种种机缘巧合，我既缺乏基础知识，也没有接受过完整的培训，甚至没有经历全流程的使用。\n由于当时急于求成，虽然成功完成了训练，却没能深入探索魔搭的强大功能，仅使用了 swift 便捷的训练功能。\n所以，这次我打算从”Quick Start”开始，认真学习魔搭的每一个功能。\n过程Quick Start很奇妙的一点，中英文的教程竟然是不同的，英文版在概念解释上更详细，而中文版在操作流程上更详细。然后，中文版似乎更新更频繁，所以如果是国内用户并以使用优先，建议优先参考中文版，但如果想要更深入的了解模型训练的原理，建议参考英文版。\n\n魔搭社区\n魔搭社区\n\n哦，对了，如果是打算用的话，建议去直接看文档，他写的真的很好，真的可以让你在 5 分钟内学会使用。\n基础概念首先是一些基础概念：\nTask（任务）:特定领域的具体应用，如图像分类、文本生成等，用户可根据输入输出需求选择合适的模型。\n\nTask refers to a specific application in a certain field, used to complete tasks in specific scenarios. For example, image classification, text generation, speech recognition, etc. You can find the task type suitable for your application scenario based on the input and output of the task, and filter the tasks to find the model you need.\n\nModel（模型）:包含网络结构和参数的具体模型实例，提供实际的 AI 能力。\n\nModel refers to a specific model instance, including the model network structure and corresponding parameters. ModelScope provides rich model information for users to experience and use.\n\nModelhub（模型库）:模型库是模型资源的管理和分发平台，提供丰富的模型资源，帮助用户快速找到合适的模型。\n\nModel library (Modelhub) refers to model services that store, version manage and related operations for models. Models uploaded and shared by users will be stored in ModelScope’s model library. Users can also create their own model storage in Model hub. library, and continue to use the model library management function provided by the platform for model management.\n\nDataset（数据集）:用于算法训练、测试的数据集合，支持模型训练和验证。\n\nDataset refers to a set of data used for model training and evaluation. ModelScope provides rich dataset information for users to experience and use.\n\nDatasethub（数据集库）:集中管理数据的平台，便于数据访问、管理和共享。\n\nDatasethub is used to centrally manage data and support model training, prediction, etc., making various types of data easy to access, manage, and share.\n\nModelScope Library（模型库）:ModelScope 的 Python 框架库，提供简单的代码接口实现模型推理、训练等功能。\n\nModelScope Library is a set of Python Library frameworks developed by ModelScope. By calling specific methods, users can write just a few lines of code to complete tasks such as model reasoning, training, and evaluation. On this basis, they can also quickly Carry out secondary development and realize your own innovative ideas.\n\nModel Exploration模型探索：\n访问平台网站 https://www.modelscope.cn/models，可以看到平台上的所有公共模型，通过任务或关键词搜索找到感兴趣的模型。\n\n如果需要找到可以在线体验或支持训练和微调的模型，可以通过搜索框右侧的过滤框进行过滤。可以在线体验和训练的模型将不断丰富和扩展，敬请期待。本文以中文分词模型为例，带你体验使用 ModelScope 的模型。可以通过过滤任务为 “词性标注” 或搜索关键词 “词性标注” 来检索对应的词性标注模型。在模型卡片右侧，会显示模型的基本信息，包括中文和英文名称、任务类型标签和其他模型标签、模型使用的深度学习框架、模型提供者、下载次数、点赞次数、模型描述等信息，帮助你快速理解模型。\n\n\n\n点击模型进入模型详情页，可以查看模型的具体介绍。模型提供者会在这里介绍模型的具体应用场景、功能描述、技术方法、模型训练和使用、效果评估等信息，供你参考。在模型卡片右侧，有一个 “在线体验” 功能。可以切换默认示例查看模型效果，或输入适合模型的测试信息测试模型效果。\n\n\n事实上并非所有模型都支持在线体验，但是依然是非常实用的功能。\n\n在开始在线体验之前，请仔细阅读并理解相关的免责声明，合法合规地使用在线体验模块的功能。除了模型体验，你还可以查看和下载模型的具体文件。（目前支持通过 git 和 Python SDK 下载。更多信息请参见模型下载）如果你对模型效果满意，想要了解更多并进行代码验证，可以点击 “快速使用” 查看具体的代码示例方法。平台提供了两种下载模型的方式：\n\nInstall and download through ModelScope Library\nPull the repository through git这些方法都可以在本地运行模型。但是，你需要先安装 ModelScope Library 才能运行代码。详情请参见步骤 [环境准备] - [本地开发环境安装]。\n\n\n环境准备本地开发环境安装如果你需要运行模型，你需要进行相应的环境安装准备，包括：\n\n安装 python 环境。支持 python3，但不支持 python2。推荐使用 Anaconda 安装。\n安装深度学习框架。ModelScope Library 目前支持两大深度学习框架，Tensorflow 和 Pytorch，用于模型训练和推理。你可以根据模型所需的框架选择合适的框架进行安装。\n安装 ModelScope Library。我们提供了两种安装方法，你可以根据需要选择合适的安装方法。\npip 安装。ModelScope 根据不同领域提供了安装包，你可以根据对应的模型选择所需的安装包。\n从源码安装。\n\n\n\n魔搭社区提供了预安装好的 Notebook 环境来使用魔搭社区模型，并为新用户提供了 100 小时的免费 GPU 算力和不限时长的免费 CPU 算力，并预安装了大部分模型可运行的环境依赖。\nPython 环境安装配置首先，参考文档 安装配置 Anaconda 环境。安装完成后，执行如下命令为 ModelScope library 创建对应的 Python 环境。\nconda create -n modelscope python=3.10conda activate modelscope\n\nModelScope Library 安装ModelScope Library 由核心 hub 支持，框架，以及不同领域模型的对接组件组成。根据您实际使用的场景，可以选择不同的安装选项。\n如果只需要通过 ModelScope SDK，或者 ModelScope 命令行工具来下载模型，可以只最轻量化的安装 ModelScope 的核心 hub 支持：\npip install modelscope\n\n如果需要更完整的使用 ModelScope 平台上的一系列框架能力，包括数据集的加载，外部模型的使用等，则推荐使用”framework”的安装选项，也就是：\npip install modelscope[framework]\n\n以上两种方法，都不涉及 ModelScope 上原生模型的集成。要使用 ModelScope 来实现各种领域模型的使用，包括基于 NLP、CV、语音、多模态，等不同领域的模型，来进行模型推理以及模型训练、微调等能力，则需要根据具体领域，通过安装选项，来安装额外的依赖。同时也涉及对应的 PyTorch,Tensorflow 等机器学习框架的安装。\n同时社区推荐安装 Git 和 Git LFS，这是模型管理包括上传所必须的工具。\n其他以下部分的内容建议参考文档，因为文档写的真的很好。\n\n深度学习框架依赖的安装\n分领域 ModelScope 模型依赖的安装\n安装验证\n\n实际流程因为我这次是为了体验 cv 领域的模型，所以选择了安装modelscope[cv]。\npip install torchpip install &quot;modelscope[cv]&quot; -f https://modelscope.oss-cn-beijing.aliyuncs.com/releases/repo.html\n\n模型下载如果您在高带宽的机器上运行，推荐使用 ModelScope 命令行工具下载模型。该方法支持断点续传和模型高速下载，例如可以通过如下命令，将 Qwen2.5-0.5B-Instruct 模型，下载到当前路径下的”model-dir”目录。\nmodelscope download --model Qwen/Qwen2.5-0.5B-Instruct --local_dir ./model-dir\n\n这里有个插曲是当时我发现文档中代码无法实际使用，然后提了 issue, 然后过来不久开发团队就回复了问题并更新了文档。\n\n谢谢指出。这里主要是 typo，把后面一个引号的位置写错了。事实上对于下载模型，以下 3 种写法都支持\n&gt;modelscope download --model=&quot;Qwen/Qwen2.5-0.5B-Instruct&quot; --local_dir ./model-dir&gt;modelscope download --model &quot;Qwen/Qwen2.5-0.5B-Instruct&quot; --local_dir ./model-dir&gt;modelscope download &quot;Qwen/Qwen2.5-0.5B-Instruct&quot; --local_dir ./model-dir\n\n文档中已经修复引号的位置。\n\n您也可以使用 ModelScope Python SDK 下载模型，该方法支持断点续传和模型高速下载：\nfrom modelscope import snapshot_downloadmodel_dir = snapshot_download(&quot;Qwen/Qwen2.5-0.5B-Instruct&quot;)\n\n由于模型都是通过 Git 存储，所以也可以在安装 Git LFS 后，通过 git clone 的方式在本地下载模型，例如：\ngit lfs installgit clone https://www.modelscope.cn/Qwen/Qwen2.5-0.5B-Instruct.git\n\n关于模型下载的详细说明，可参考模型下载文档。\n同时，如果模型和 ModelScope SDK 绑定，则只需要几行代码即可加载模型，同时 ModelScope 还支持通过 AutoModel 等接口来加载模型。如下是使用 AutoModel 和 pipeline 方式加载模型的示例：\n实际操作我实验的模型是图片生成模型：PAI中文Diffusion模型-美食。\n魔搭社区\n# 命令行下载modelscope download --model PAI/pai-diffusion-food-large-zh --local_dir ./model\n\n模型加载使用 ModelScope pipeline 加载模型如果你准备好了环境，可以基于以下代码推理模型。使用 modelscope pipeline 接口只需要两步，以下以词性标注模型（damo&#x2F;nlp_structbert_word-segmentation_chinese-base）为例进行简要说明：\n首先实例化一个基于任务的 pipeline 对象\nfrom modelscope.pipelines import pipelineword_segmentation = pipeline(&#x27;word-segmentation&#x27;,model=&#x27;damo/nlp_structbert_word-segmentation_chinese-base&#x27;)\n\n输入数据并获取输出\ninput_str = &#x27;今天天气不错，适合出去游玩&#x27;print(word_segmentation(input_str))&#123;&#x27;output&#x27;: &#x27;今天 天气 不错，适合 出去 游玩&#x27;&#125;\n\n使用 AutoModel 加载模型from modelscope import AutoModelForCausalLM, AutoTokenizermodel_name = &quot;Qwen/Qwen2.5-0.5B-Instruct&quot;model = AutoModelForCausalLM.from_pretrained(    model_name,    torch_dtype=&quot;auto&quot;,    device_map=&quot;auto&quot;)tokenizer = AutoTokenizer.from_pretrained(model_name)\n\n模型推理pipeline推理不同模态多种任务，pipeline 是最简单、最快捷的方法。您可以使用开箱即用的 pipeline 执行跨不同模式的多种任务，下面是一个 pipeline 完整的运行示例：\nfrom modelscope.pipelines import pipelinefrom modelscope.utils.constant import Tasksinference_pipeline = pipeline(    task=Tasks.auto_speech_recognition,    model=&#x27;iic/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-pytorch&#x27;,    model_revision=&quot;v2.0.4&quot;)rec_result = inference_pipeline(&#x27;https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/test_audio/asr_vad_punc_example.wav&#x27;)print(rec_result)\n\nAutoModel 和 AutoTokenizerModelScope 兼容了 Transformers 提供的简单而统一的方法来加载预训练实例和 tokenizer。这意味着您可以使用 ModelScope 加载 AutoModel 和 AutoTokenizer 等类。下面是一个大语言模型的完整的运行示例：\nfrom modelscope import AutoModelForCausalLM, AutoTokenizermodel_name = &quot;qwen/Qwen2.5-0.5B-Instruct&quot;model = AutoModelForCausalLM.from_pretrained(    model_name,    torch_dtype=&quot;auto&quot;,    device_map=&quot;auto&quot;)tokenizer = AutoTokenizer.from_pretrained(model_name)prompt = &quot;Give me a short introduction to large language model.&quot;messages = [    &#123;&quot;role&quot;: &quot;system&quot;, &quot;content&quot;: &quot;You are Qwen, created by Alibaba Cloud. You are a helpful assistant.&quot;&#125;,    &#123;&quot;role&quot;: &quot;user&quot;, &quot;content&quot;: prompt&#125;]text = tokenizer.apply_chat_template(    messages,    tokenize=False,    add_generation_prompt=True)model_inputs = tokenizer([text], return_tensors=&quot;pt&quot;).to(model.device)generated_ids = model.generate(    **model_inputs,    max_new_tokens=512)generated_ids = [    output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids)]response = tokenizer.batch_decode[generated_ids, skip_special_tokens=True](0)\n\n其他模型推理对于暂时未与 ModelScope SDK 做原生集成的模型，可以先从 ModelScope 上下载模型，然后通过其他的主流库实现模型推理，以 SDXL-Turbo 模型为例，完整的模型推理运行示例如下：\nfrom diffusers import AutoPipelineForText2Imageimport torchfrom modelscope import snapshot_downloadmodel_dir = snapshot_download(&quot;AI-ModelScope/sdxl-turbo&quot;)pipe = AutoPipelineForText2Image.from_pretrained(model_dir, torch_dtype=torch.float16, variant=&quot;fp16&quot;)pipe.to(&quot;cuda&quot;)prompt = &quot;A cinematic shot of a baby racoon wearing an intricate italian priest robe.&quot;image = pipe(prompt=prompt, num_inference_steps=1, guidance_scale=0.0).images[0]image.save(&quot;image.png&quot;)\n\n模型推理实际操作from modelscope.pipelines import pipelineimport cv2p = pipeline(&#x27;text-to-image-synthesis&#x27;, &#x27;PAI/pai-diffusion-food-large-zh&#x27;, model_revision=&#x27;v1.0.0&#x27;)result = p(&#123;&#x27;text&#x27;: &#x27;红烧狮子头&#x27;&#125;)image = result[&quot;output_imgs&quot;][0]cv2.imwrite(&quot;image.png&quot;, image)\n\n注：可以把模型地址写为刚刚下载的文件夹路径。\n结论受益匪浅，ModelScope 的文档写的真的很好，而且很详细，很适合初学者。\n","categories":["Tech","LLM"],"tags":["LLM"]},{"title":"bam 转 wig 并批量处理的方法","url":"/2024/03/17/bioinformatics/bam%E8%BD%ACwig%E5%B9%B6%E6%89%B9%E9%87%8F%E5%A4%84%E7%90%86%E7%9A%84%E6%96%B9%E6%B3%95/","content":"引言本文将介绍一种 bam 转 wig 并批量处理的方法。需要用到的软件是来自 Augustus 的 bam2wig.\n过程软件安装Augustus 官方 github 地址：\nGitHub - Gaius-Augustus&#x2F;Augustus: Genome annotation with AUGUSTUS\n对于 linux 客户端，官方提供了 apt&#x2F;Docker&#x2F;Singularity&#x2F;Building AUGUSTUS from source 四种安装方式，由于权限及软件问题，建议编译安装，非常不推荐 docker 安装。\n首先需要安装依赖 (samtools 可使用 conda 版本)：\nsudo apt-get install samtools libhts-dev\ngit clone https://github.com/Gaius-Augustus/Augustus.gitcd Augustusmake augustus\n\n如果只需要使用 bam2wig, 可以：\ngit clone https://github.com/Gaius-Augustus/Augustus.gitcd Augustus/auxprogs/bam2wigmake./Augustus/bin/bam2wig\n\n如果顺利的话，会打印出：\nUsage: bam2wig [-r region] [-t trackname] &lt;in.bam&gt;----------------------------------------------------------------- -r   Allows user to specify a target region, e.g. &#x27;chr3L:10-250&#x27;      This option can only be used if an index file exists      See: samtools index -t   A string might be provided as track nameNOTE:File needs to be sorted by Reference ID (i.e. target name)Use &#x27;samtools sort &lt;in.bam&gt;&#x27; to such effect.\n\n软件使用bam2wig 官方提供的使用教程：\nAugustus&#x2F;auxprogs&#x2F;bam2wig&#x2F;README.md at master · Gaius-Augustus&#x2F;Augustus\n由打印可知，在使用 bam2wig 之前需要先进行samtools sort, 因此正确的流程是：\n## checksamtools quickcheck SRR******.bam## sortsamtools sort SRR******.bam -@8 -o SRR******.sorted.bamsamtools stats SRR******.sorted.bam | grep &#x27;is sorted&#x27;## bam2wigbam2wig SRR******.sorted.bam &gt; SRR6131113.wig\n\n批量运行批量的思路是先获取 data 文件夹内的所有文件名，然后对每个文件名依次检查，排序，转换。\n其中，conda activate bulkrna需要设置为含samtools的环境名，Augustus/bin/bam2wig要设置为bam2wig的绝对路径。\n1.get_raw_data.sh\n#!/bin/bashSHELL_FOLDER=$(cd &quot;$(dirname &quot;$0&quot;)&quot;;pwd)echo $SHELL_FOLDER/data# cd $SHELL_FOLDER/datadata_dir=$SHELL_FOLDER/data## get filenamessamplefile=&quot;samplenames.txt&quot;if [ ! -d $samplefile ]; then        filenames=$(ls $data_dir)        for filename in $filenames        do                echo $filename        done &gt; filenames.txt        ### get samplenames        grep -oP &quot;.*?(?=\\.)&quot; filenames.txt | awk &#x27; !x[$0]++&#x27; &gt; samplenames.txtelse        echo &quot;$samplename exists!&quot;fi\n\n2.run.sh\n#!/bin/bash# 检查 env.txt 文件是否存在if [ -f &quot;$&#123;HOME&#125;/env.txt&quot; ]; then  # 如果 env.txt 存在，则运行相应的命令  while IFS=&#x27;=&#x27; read -r key value; do    echo &quot;$key=$value&quot;    export &quot;$key&quot;=&quot;$value&quot;  done &lt; &quot;$&#123;HOME&#125;/env.txt&quot;else  # 运行其他命令  echo &quot;env.txt 文件不存在&quot;fiSHELL_FOLDER=$(cd &quot;$(dirname &quot;$0&quot;)&quot;;pwd)data_dir=$SHELL_FOLDER/dataresults_dir=$SHELL_FOLDER/resultsmkdir -p $data_dirmkdir -p $results_direcho $data_dircd $data_dir# samplefile=$data_dir/samplenames.txtsamplefile=$SHELL_FOLDER&quot;/samplenames.txt&quot;eval &quot;$(conda shell.bash hook)&quot;conda activate bulkrna#Rundata_dir=$SHELL_FOLDER/datadata_dir_process=$SHELL_FOLDER/data_processmkdir -p $data_dir_processnum=$(wc -l &lt; $samplefile)# for i in $(seq 2 2)for i in $(seq 1 $num)do    echo $i    samplename=$(sed -n &quot;$&#123;i&#125;p&quot; $samplefile)#     echo $samplename#     cd $data_dir_process    if [ ! -d $samplename ]; then            echo &quot;$samplename not completed, process in $data_dir&quot;            sample_file=$&#123;data_dir&#125;/$&#123;samplename&#125;.bam            samtools quickcheck $&#123;sample_file&#125;            echo &quot;$samplename is checked&quot;            sort_file=$&#123;data_dir_process&#125;/$&#123;samplename&#125;.sorted.bam            samtools sort $&#123;sample_file&#125; -@8 -o $&#123;sort_file&#125;            samtools stats $&#123;sort_file&#125; | grep &#x27;is sorted&#x27;            Augustus/bin/bam2wig $&#123;sort_file&#125; &gt; $&#123;results_dir&#125;/$&#123;samplename&#125;.wig    else            echo &quot;$samplename exists!&quot;    fidone &gt; run.log\n\n结论这是一份较为通用的处理方法。\n错误解决docker 版本 bam2wig 失败主要遇到的问题是 docker 的存储访问问题，在容器起效之后，容器其实无法访问本机的存储空间。\n所以docker run -i augustus augustus --version和docker run -i augustus bam2wig是可以使用的，但是docker run -i augustus bam2wig SRR******.bam会提示找不到文件。\n引用\n通过 WIG 格式将转录组数据展示到 Gbrowse2 中 | Public Library of Bioinformatics\naugustus 软件安装与 Docker 使用记录_augustus git-CSDN 博客\n如何检测 bam 文件的完整性 - 小鲨鱼 2018 - 博客园\nSAMtools——bam 文件排序 - 简书\n\n","categories":["生物信息学"],"tags":["samtools","bam2wig","shell-script"]},{"title":"RNA-seq 分析流程和代码","url":"/2024/09/15/bioinformatics/RNA-seq%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B%E5%92%8C%E4%BB%A3%E7%A0%81/","content":"引言效果展示过程RNA-seq 分析流程和原理解析[1,2]\nRNA-seq 分析代码[3]\n结论引用\nRNA-seq 分析流程 —— 概述 - 知乎\nRNA-seq 分析：从软件安装到富集分析详细过程 - 简书\n如何完成 RNA-seq 的分析流程？ - 知乎\n\n","categories":["生物信息学"]},{"title":"使用 nbia-data-retriever 在 linux 下载数据","url":"/2025/06/07/bioinformatics/nbia-data-retriever%E4%B8%8B%E8%BD%BD%E6%95%B0%E6%8D%AE/","content":"引言美国癌症医学影像档案中心 (The Cancer Imaging Archive, TCIA) 可以下载癌症病例数据，对于 mac 和 win 来说下载软件使用就可以了，但是在连接 linux 的 terminal 可能会出现两个报错：\n一个是zsh: command not found: nbia-data-retriever, 另一个是java.awt.HeadlessException: No X11 DISPLAY variable was set。\n第一个意味着系统无法在它查找可执行文件的标准路径（即 $PATH 环境变量指定的目录）中找到名为 nbia-data-retriever 的可执行文件。\n第二个表明 nbia-data-retriever 这个程序（它是一个 Java 应用程序）试图执行一个需要图形界面（GUI）的操作，但在您当前运行的环境中没有找到可用的显示设备（X11 DISPLAY）。简单来说，这个程序可能在启动时尝试弹出一个窗口（比如用户协议、进度条或配置界面），但您正在一个没有图形界面的终端会话中运行它（这在服务器上很常见）。\ntenney@sxmu-PowerEdge-R750 $ sudo -S dpkg -i nbia-data-retriever_4.4.3-1_amd64.debSelecting previously unselected package nbia-data-retriever.(Reading database ... 439311 files and directories currently installed.)Preparing to unpack nbia-data-retriever_4.4.3-1_amd64.deb ...Unpacking nbia-data-retriever (4.4.3-1) ...Setting up nbia-data-retriever (4.4.3-1) ...tenney@sxmu-PowerEdge-R750 $ nbia-data-retrieverzsh: command not found: nbia-data-retrievertenney@sxmu-PowerEdge-R750 /data$ /opt/nbia-data-retriever/bin/nbia-data-retriever NSCLC_Radiogenomics-6-1-21-Version-4.tciaWARNING: sun.reflect.Reflection.getCallerClass is not supported. This will impact performance.Exception in thread &quot;main&quot; java.awt.HeadlessException:No X11 DISPLAY variable was set,but this program performed an operation which requires it.        at java.desktop/java.awt.GraphicsEnvironment.checkHeadless(Unknown Source)        at java.desktop/java.awt.Window.&lt;init&gt;(Unknown Source)        at java.desktop/java.awt.Frame.&lt;init&gt;(Unknown Source)        at java.desktop/java.awt.Frame.&lt;init&gt;(Unknown Source)        at java.desktop/javax.swing.JFrame.&lt;init&gt;(Unknown Source)        at gov.nih.nci.nbia.StandaloneDMDispatcher.showUserAgreementTxt(Unknown Source)        at gov.nih.nci.nbia.StandaloneDMDispatcher.launch(Unknown Source)        at gov.nih.nci.nbia.StandaloneDMDispatcher.main(Unknown Source)\n\n本教程所用的平台是 ubuntu 22.04 + macos 15.3.2.\n效果展示\n过程安装 nbia-data-retriever官网提供了安装指南[1].\n对于 ubuntu 使用 deb 安装包安装，相应的 contos 使用 rpm.\nwget https://github.com/CBIIT/NBIA-TCIA/releases/download/DR-4_4_3-TCIA-20240916-1/nbia-data-retriever_4.4.3-1_amd64.debsudo -S dpkg -i nbia-data-retriever_4.4.3-1_amd64.debnbia-data-retriever# zsh: command not found: nbia-data-retriever\n\n但是安装后想使用就会出现引言里面出现的问题，解决方法我使用的是找到路径别然后直接执行，而不是加入 PATH.因为 PATH 里面已经塞了太多没必要的东西了完全没必要…\n另外就是没有 conda 安装方式比较可惜，在 anaconda 官网也没搜到。\ndpkg -L nbia-data-retriever# /opt/nbia-data-retriever/bin/nbia-data-retriever\n\n所以可执行目录就是/opt/nbia-data-retriever/bin/nbia-data-retriever.\n下载数据以https://www.cancerimagingarchive.net/collection/nsclc-radiogenomics/数据为例。\nwget https://www.cancerimagingarchive.net/wp-content/uploads/NSCLC_Radiogenomics-6-1-21-Version-4.tcia/opt/nbia-data-retriever/bin/nbia-data-retriever NSCLC_Radiogenomics-6-1-21-Version-4.tcia# java.awt.HeadlessException: No X11 DISPLAY variable was set\n\n既然没有 X11 屏幕就用本地的好了，以前的教程VScode 使用 remote-ssh 实现服务器上绘图可视化 | Yezi’s Hexo Blog讲过如何配合 vscode 使用 r 绘图。跟那个类似，不过经过常年的锻炼我发现不用按照 r-studio 的思维走…\n其实直接 terminal 里面跑就足足够够的。\n服务端如果是 centOS 可以使用yum install -y xauth xclock.\n如果是 ubuntu 可以使用apt install -y xauth x11-apps.\n本地准备mac:\n首先安装 xquartz 用来展示。\nbrew install xquartz\n\n然后修改本地的./.ssh/config文件内容，加上ForwardX11 yes等三行。\nHost 32_local    HostName 10.9.65.32    User tenney    ForwardX11 yes    ForwardX11Trusted yes    ForwardAgent yes\n\nssh -Y tenney@10.9.65.32echo $DISPLAY# localhost:11.0\n\n-Y参数可以启用X11 Forwarding功能。\n这里面有一个坑，就是 vscode 的remote X11可能是太久没更新已经不支持了，我在 vscode 里面无法调用到 DISPLAY&#x2F;X11, 但是 terminal 可以，所以建议直接用 terminal.\n如果成功输出了类似上面localhost:11.0的东西，就可以重跑刚刚的代码了。\nWindows 听说是用 Xming.\n结论计算机是魔法，这个发明工具远远快于知道工具的速度的年代，就不要对工具刨根问底了，能用就行…\n引用\nDownloading TCIA Images - TCIA Online Help - Cancer Imaging Archive Wiki\nTCIA 数据集下载和 NBIA DATA Retriever 软件下载及安装-CSDN 博客\nVScode 使用 remote-ssh 实现服务器上绘图可视化 | Yezi’s Hexo Blog\n\n","categories":["bioinformatics"],"tags":["radiomics"]},{"title":"受试者工作特性曲线 (ROC) 的原理及绘制方式","url":"/2024/03/24/bioinformatics/roc%E6%9B%B2%E7%BA%BF%E7%9A%84%E7%BB%98%E5%88%B6%E6%96%B9%E5%BC%8F%E5%8F%8A%E5%8E%9F%E7%90%86/","content":"引言受试者工作特性曲线 (Receiver Operating Characteristic, ROC) 曲线是生信分析中一种常用的性能评估方法，那么他背后的原理是什么呢？他为什么会被推荐作为二分类模型的优秀性能指标呢？\n曲线下面积 (Area Under the Curve, AUC) 是什么？约登指数是什么？截断值是怎么来的？AUC 会随截断值变化吗？\n效果展示\n\n原理案例背景在下面的例子里，核酸是一种检测手段，可以是模型、实验方法、巫术，反正就是一种猜答案的方法。有病没病是一种真实存在的情况，可能是疾病、各种特征的有无。\n核酸阳性，也确实有病：这个阳性是真阳性。\n核酸阴性，也确实没病：这个阳性是真阴性。\n核酸阳性，但其实没病：这个阳性是假阳性。\n核酸阴性，但其实有病：这个阳性是假阴性。\n之后，也就自然而然有了计算的方法。\n这里为了便于说明直接取极限：20 个人，10 个有病，检测出来 0 个，没检测出来 20 个。\n\n\n\n真实值\\预测值\n阳性\n阴性\n合计\n\n\n\n病人\n0\n10\n10\n\n\n非病人\n0\n10\n10\n\n\n合计\n0\n20\n20\n\n\n真阳性：0; 预测阳性，同时是真实病人。\n真阴性：10; 预测阴性，同时是真实非病人。\n假阳性：0; 预测阳性，同时是真实非病人。\n假阴性：10; 预测阴性，同时是真实病人。\n有了各类样本量，就可以计算各种分类率了。\n真阳性率 (真阳性&#x2F;真实病人)：0&#x2F;10&#x3D;0%\n真阴性率 (真阴性&#x2F;真实非病人)：10&#x2F;10&#x3D;&#x3D;100%\n假阳性率 (假阳性&#x2F;真实非病人)：0&#x2F;10&#x3D;0%\n假阴性率 (假阴性&#x2F;真实病人)：10&#x2F;10&#x3D;100%\n其实也很好理解，阳性一个没预测出来，那么真假阳性率就都是 0%, 因为真假阳性样本量就是 0 嘛，所以也无所谓真假阳性分子都会是 0。\n这里出现了一个很关键的事情，那就是：真性和假性是之于预测结果来说的，但真率和假率是之于真实样本量来说的!!! 因此真阳性样本量 + 假阳性样本量等于预测样本量，但真阳性率 + 假阳性率不等于 1。\n同理，因为真率和假率是之于真实样本量的，所以真阳性率 + 假阴性率 &#x3D; 1, 假阳性率 + 真阴性率 &#x3D; 1。\n实在搞不懂就死记住率的关系是两个字相反的加起来是 1, 量的关系是第一个字相反加起来等于某值 (不管是啥反正有个值)。\n真阳性 + 假阴性 &#x3D; 全部的阳性样本 &#x3D; 10;\n真阳性率 + 假阴性率 &#x3D; 0% + 100% &#x3D; 100%;\n真阴性 + 假阳性 &#x3D; 全部的阴性样本 &#x3D; 10;\n真阴性率 + 假阳性率 &#x3D; 100% + 0% &#x3D; 100%;\n可以看出，在矩阵的行表示真实值，列表示预测值时，这些率都是按行 (真实值量) 算的，当前行的预测正确的就是真率，预测错误就是假率。\n不太严谨的总结矩阵：\n\n\n\n率\n阳性\n阴性\n合计\n\n\n\n预测正确&#x2F;真\n真阳性率\n假阴性率\n1\n\n\n预测错误&#x2F;假\n假阳性率\n真阴性率\n1\n\n\n\n\n\n率\n阳性\n阴性\n合计\n\n\n\n预测正确&#x2F;真\n0%\n100%\n1\n\n\n预测错误&#x2F;假\n0%\n100%\n1\n\n\n合计\n0%\n200%\n200%\n\n\n在统计学里，我们又把真阳性率叫敏感度，真阴性率叫特异度。真阳性率越高，说明诊断效果越好，真阴性率越高，说明错误率越少。所以敏感度和特异度都是好东西，越多越好。\n\n\n\n率\n阳性\n阴性\n合计\n\n\n\n预测正确&#x2F;真\n敏感度\n1-敏感度\n1\n\n\n预测错误&#x2F;假\n1-特异度\n特异度\n1\n\n\n下面是各指标的计算方法：\n\n\n\n真实值\\预测值\n阳性\n阴性\n合计\n\n\n\n病人\na\nb\na+b\n\n\n非病人\nc\nd\nc+d\n\n\n合计\na+c\nb+d\na+b+c+d\n\n\n$真阳性率&#x3D;敏感度&#x3D;\\frac{a}{a+b}*100%$\n真阳性率（true positive rate，TPR）表示正样本中被预测为正样本的占比\n$真阴性率&#x3D;特异度&#x3D;\\frac{d}{c+d}*100%$\n真阴性率（true negative rate，TNR）表示负样本中被预测为负样本的占比\n$假阳性率&#x3D;1-特异度&#x3D;\\frac{c}{c+d}*100%$\n假阳性率（false positive rate，FPR）表示负样本中被错误地预测为正样本的占比\n$假阴性率&#x3D;1-敏感度&#x3D;\\frac{b}{a+b}*100%$\n假阴性率（false negative rate，FNR）表示正样本中被错误地预测为负样本的占比\n混淆矩阵仅仅使用 roc 的话，有以真实值为底的敏感度和特异度已经足够了，但是为了弄清楚为什么他们可以作为最佳指标以及背后的逻辑，我们需要了解一下混淆矩阵 (仅使用 roc 不想看可以跳过)。\n混淆矩阵是机器学习中总结分类模型预测结果的情形分析表。以矩阵形式将数据集中的记录按照真实的类别与分类模型预测的类别判断两个标准进行汇总。\n其中矩阵的行表示真实值，矩阵的列表示预测值，下面我们先以二分类为例，看下矩阵表现形式：\n\n值得注意的是，混淆矩阵并不规定行和列是否由真实或预测值组成，因此计算时一定要注意矩阵的方向。\n混淆矩阵除了敏感度和特异度值外，可以被用于计算准确率、召回率和 F1 分数。\n这里有一篇文章写的非常好，可以直接看：一文看懂机器学习指标：准确率、精准率、召回率、F1、ROC 曲线、AUC 曲线 - 知乎\n准确率（accuracy，ACC）准确率\nAccuracy\n准确率是总体的，是所有算对的比例。\n准确率 &#x3D;(TP+TN)&#x2F;(TP+TN+FP+FN)\n精确率（percision）精准率&#x2F;查准率&#x2F;精度&#x2F;阳性预测值\nPrecision&#x2F;Positive Predictive Value(PPV)\n只计算预测为阳性样本中的正确率：\n精准率 &#x3D;TP&#x2F;(TP+FP)\n召回率（查全率）- Recall召回率&#x2F;查全率&#x2F;真阳性率&#x2F;敏感度\nSensitivity&#x2F;Recall&#x2F;Hit Rate&#x2F;True Positive Rate(TPR)\n只计算真阳性样本中的正确率：\n召回率&#x3D;TP&#x2F;(TP+FN)\nF1 分数\n计算召回率和精确率时的分子都是 TP，不同在于分母。召回率的分母是 P，而精确率的分母是 P′。这也就是说，召回率是相对真实样本而言的，精确率是相对模型预测为正例的样本而言的。显然，若要提高召回率，则模型会变得「贪婪」，于是犯错的可能性就会变大，也就是精确率下降；若要提高精确率，则模型会变得「保守」，此时模型能够覆盖的正例就少，于是召回率下降。考虑到召回率和精确率之间「跷跷板」的关系，人们发明了 F1 值这个指标，并将其定义为召回率和精确率的调和平均数，从而能够比较容易地在召回率和精确率方面取得平衡。[6]\n\nF1 分数\nF1-score\n比较复杂，总之就是平衡精确率和召回率用的。\nF1&#x3D;(2×Precision×Recall)&#x2F;(Precision+Recall)&#x3D;2TP&#x2F;(P+P’)\n约登指数数学上召回率和精确率存在跷跷板一样的关系，这来源于精确率计算的分母是 P′而非 P。因为当模型发生变化的时候，P′就会发生变化。所以你无法在提升召回率的时候，保证精确率不变；反之亦然。\n\n也就是说，如果不使用 P’作为底而使用 P 或者 N, 就可以解决跷跷板问题。于是统计学家发明了约登指数：\n$J &#x3D; 敏感度 + 特异度 -1 &#x3D; TPR + TNR - 1%$\nROC 曲线\n终于，基于前面的知识，我们得到了下面的定理或推论：\n\n约登指数可以代表模型至少某个角度的最好评估能力\n约登指数 &#x3D; 灵敏度 + 特异度 -1  &#x3D; 敏感度 - (1 - 特异度)\n\n其中，预测方法下文以模型代指。\n模型可以将样本分类为阴性阳性。在我们的预期中，最好的模型可以达到 100% 的预测率，而当模型不能达到 100% 时精确率和召回率是不可能同时有最大值的。\n因此，我们可以尝试以约登指数的组成元素构建一个模型评价指标，也就有了 roc 曲线。\n以(1 - 特异度)为 x 轴，敏感度为 y 轴，一个 roc 空间就完成了。\n\n注：橙色代表真实的值，紫色区域代表模型的预测值；\n横轴代表测试值 (阈值), 纵轴代表概率但可以理解为无意义，只看面积即可。测试值右侧的面积是真值&#x2F;阳性样本，左侧是假值&#x2F;阴性样本。\nROC 曲线也是通过遍历所有阈值来绘制整条曲线的。如果我们不断的遍历所有阈值，预测的正样本和负样本是在不断变化的，相应的在 ROC 曲线图中也会沿着曲线滑动。\n当测试值是最小值的时候，所以样本都是真值，预测全是阳性，所以真阳性率 (敏感度) 是 100%, 而没有假值，所以真阴性率 (特异度) 是 0%, 所以假阳性率 (1-真阴性率&#x2F;1-特异度) 是 100%.\n当测试值是最大值的时候，所以样本都是假值，预测全是阴性，所以真阳性率 (敏感度) 是 0%, 而没有真值，所以真阴性率 (特异度) 是 100%, 所以假阳性率 (1-真阴性率&#x2F;1-特异度) 是 0%.\n所以 ROC 曲线都是从左下角开始到右上角结束。\n现在再回到一开始的示例图片，就可以解答什么是最近阈值，什么是约登指数了。\n\n即：ROC 曲线的本质就是比大小，比如这个图就是原数据里面大于 0.205 的就认为是真，小于就是假，这么比大小比出来的。\n很显然，Cut-off 指在该值时可得到最大的尤登指数。\n这个点是按约登指数计算出来的具有最佳性能的阈值点，也就是尽可能增大灵敏度和特异度的点。\n截断值是在模型生成过程中使用的数值，不是评价模型的数值。\n绘制方式r 代码具体参观公众号”医学和生信笔记”的 “ROC 曲线最佳截点”, 这个公众号有挺多干货的，而且免费。\n## 使用pROC包的aSAH数据，其中outcome列是结果变量，1代表Good，2代表Poorlibrary(pROC)data(aSAH)dim(aSAH)str(aSAH)## 计算AUC及可信区间res &lt;- pROC::roc(aSAH$outcome,aSAH$s100b,ci=T,auc=T)res## 显示最佳截点，比如AUC最大的点plot(res,     legacy.axes = TRUE,     thresholds=&quot;best&quot;, # AUC最大的点     print.thres=&quot;best&quot;)\n\npython 代码auc 计算，来源于 python scikit-learn 包。\nimport numpy as npimport matplotlib.pyplot as pltfrom sklearn import metrics# pip install -U scikit-learn scipy matplotliby = np.array([1, 1, 2, 2])scores = np.array([0.1, 0.4, 0.35, 0.8])fpr, tpr, thresholds = metrics.roc_curve(y, scores, pos_label=2)metrics.auc(fpr, tpr)\n\nimport numpy as npimport matplotlib.pyplot as pltfrom sklearn.datasets import load_irisfrom sklearn.model_selection import train_test_splitfrom sklearn.metrics import RocCurveDisplayfrom sklearn.preprocessing import LabelBinarizerfrom sklearn.linear_model import LogisticRegressioniris = load_iris()target_names = iris.target_namesX, y = iris.data, iris.targety = iris.target_names[y]random_state = np.random.RandomState(0)n_samples, n_features = X.shapen_classes = len(np.unique(y))X = np.concatenate([X, random_state.randn(n_samples, 200 * n_features)], axis=1)(    X_train,    X_test,    y_train,    y_test,) = train_test_split(X, y, test_size=0.5, stratify=y, random_state=0)classifier = LogisticRegression()y_score = classifier.fit(X_train, y_train).predict_proba(X_test)label_binarizer = LabelBinarizer().fit(y_train)y_onehot_test = label_binarizer.transform(y_test)y_onehot_test.shape  # (n_samples, n_classes)label_binarizer.transform([&quot;virginica&quot;])class_of_interest = &quot;virginica&quot;class_id = np.flatnonzero(label_binarizer.classes_ == class_of_interest)[0]class_iddisplay = RocCurveDisplay.from_predictions(    y_onehot_test[:, class_id],    y_score[:, class_id],    name=f&quot;&#123;class_of_interest&#125; vs the rest&quot;,    color=&quot;darkorange&quot;,    plot_chance_level=True,)_ = display.ax_.set(    xlabel=&quot;False Positive Rate&quot;,    ylabel=&quot;True Positive Rate&quot;,    title=&quot;One-vs-Rest ROC curves:\\nVirginica vs (Setosa &amp; Versicolor)&quot;,)display.figure_.savefig(&quot;roc_curve.png&quot;)\n\npython sklearn 也可以绘制多分类 roc, 具体见Multiclass Receiver Operating Characteristic (ROC) - scikit-learn.\n其他ROC 与 PR-Curve 的比较[6]\n\n由于 ROC 的横纵坐标分别表示 FPR 和 TPR，二者的分母完全隔开，从而使得 AUC of ROC 不受正负样本比例的影响（如上图所示）。这看起来是个好事，因为它在倾斜的数据集上依然保持了稳定的物理意义（类似准确率）。但是，另一方面，这说明在负例数量远大于正例数量的极度倾斜的数据集上，AUC of ROC 可能失真。在这种情况下，PR-Curve 能够更好地反映出模型的性能。\n\n这里就要讨论到 roc 至于其他指标的一个优势了，他不受正负样本比例的影响，可以在比例极其不均的样本上得到优秀的表达效果。\n点击率预估模型中的 AUC 与 gAUC（grouped AUC）[6]所谓 grouped AUC 就是多组 roc, 那么 roc 作为一个二分类模型如何应用在多分类问题呢？\n答案就是多次分组计算 AUC, 而后通过权重来计算 gAUC 值。\n不过更多的时候我们不去计算 gAUC 值而是直接通过查看多组的 roc 曲线状态确认模型在多组中的表现情况，如效果展示 1 所示。\n引用\n一文详解 ROC 曲线和 AUC 值 - 知乎\n混淆矩阵 Confusion Matrix - 知乎\n一文看懂机器学习指标：准确率、精准率、召回率、F1、ROC 曲线、AUC 曲线 - 知乎\n我想请教一下 ROC 曲线 cut-off 值如何确定？谢谢！！！? - 知乎\n基于 R 语言的 ROC 曲线绘制及最佳阈值点 (Cutoff) 选择 - 知乎\n二分类的评价指标 | 始终\nMulticlass Receiver Operating Characteristic (ROC) - scikit-learn\nROC 曲线 - 医学和生信笔记\n\n","categories":["生物信息学"],"tags":["ROC"]},{"title":"SRA-Toolkit工具下载SRA数据","url":"/2023/05/23/bioinformatics/SRA-Toolkit%E5%B7%A5%E5%85%B7%E4%B8%8B%E8%BD%BDSRA%E6%95%B0%E6%8D%AE/","content":"引言高通量的原始数据通常情况下会上传到NCBI的SRA（Sequence Read Archive）数据库。\n常见的下载方法有1：\n\naspera 工具下载\nwget, curl命令直接下载\nNCBI官方的 SRA Toolkit 进行下载\n\naspera 工具配置麻烦，直接下载容易出错，所以使用SRA-Toolkit工具下载。(2024年04月27日) SRA-Toolkit工具无断点续传，所以使用srapath获得地址后使用axel下载。\n过程srapath获得地址后使用axel下载 (2024年04月27日)本来其实SRA-Toolkit足够好用了，但是当下载的文件由2G变成20G, 一旦出现网络波动几个小时的工作量就会付之东流…\n所以还是万能的下载链接好使。\n大概意思如下：\nlink=$(srapath $(sed -n &quot;$&#123;i&#125;p&quot; $srr_acc_list_file))axel -o $filename $link -k 32 &amp;\n\n使用 SRA-Toolkit 工具进行下载下载 SRA-Toolkit 工具并安装主要流程来源于官方教程及网络2-3.\n官方教程链接：\n02. Installing SRA Toolkit · ncbi&#x2F;sra-tools Wiki · GitHub\nhttps://github.com/ncbi/sra-tools/wiki/02.-Installing-SRA-Toolkit\n以CentOS为例：\n\n下载sratoolkit.current-centos_linux64.tar.gz, 可以wget, 但推荐本地下载后传入。\n传入目标文件夹，如/dev/sda1/home/tenney/app/sratoolkit/, 并在终端中进入该地址，如cd /dev/sda1/home/tenney/app/sratoolkit/, 对文件解压，tar -vxzf sratoolkit.tar.gz, 注意tar -vxzf后的内容可能产生变化，以实际为准，比如我是tar -vxzf  sratoolkit.current-centos_linux64.tar.gz.\n将二进制文件的路径附加到PATH环境变量中，如：export PATH=$PATH:$PWD/sratoolkit.3.0.5-centos_linux64/bin.\n验证二进制文件是否可由shell找到：which fastq-dump.\n测试工具包是否有效：fastq-dump --stdout -X 2 SRR390728.\n\n永久添加环境变量可以写入~/.bashrc文件。\n完整代码如下：\ncd /dev/sda1/home/tenney/app/sratoolkit/wget --output-document sratoolkit.tar.gz https://ftp-trace.ncbi.nlm.nih.gov/sra/sdk/current/sratoolkit.current-centos_linux64.tar.gztar -vxzf  sratoolkit.current-centos_linux64.tar.gzexport PATH=$PATH:$PWD/sratoolkit.3.0.5-centos_linux64/binwhich fastq-dump# ~/app/sratoolkit/sratoolkit.3.0.5-centos_linux64/bin/fastq-dumpfastq-dump --stdout -X 2 SRR390728\n\nprefetch 工具下载数据提供RUN的SRR&#x2F;DRR&#x2F;ERR检索号即可下载，如prefetch ERR009357.\n也可以提供列表，以\\n分隔。\ncat SRR_Acc_List.txt# ERR003133# ERR003134# ERR003135# ERR003136# ERR003137echo $(&lt;SRR_Acc_List.txt)# SRR12697742 SRR12697743 SRR12697759 SRR12697758 SRR12697757 SRR12697756 SRR12697751 SRR12697750 SRR12697749 SRR12697748 SRR12697741 SRR12697740prefetch -O . $(&lt;SRR_Acc_List.txt)# 可以使用nohup + &amp;  用于放入后台下载，避免关闭终端导致下载中断# nohup prefetch -O . $(&lt;SRR_Acc_List.txt) &amp;\n\n其中，-O .代表下载到当前文件夹，$(&lt;SRR_Acc_List.txt)代表读入的列表。\nAspera的下载和安装如果想获得更快的下载速度，就需要使用ibm-aspera软件。\nAspera——利用SRR号批量高效下载FASTQ或SRA数据 - 知乎\n首先，在linux系统上，最推荐使用conda安装。\nconda install -c hcc aspera-cli\n如果使用全版本安装，可能会出现依赖包不匹配等问题，特别是最新版非常不推荐使用。\n测试运行代码：\nascp  -vQT -l 500m -P33001 -k 1 -i \\~/.aspera/connect/etc/asperaweb_id_dsa.openssh \\era-fasp@fasp.sra.ebi.ac.uk:/vol1/fastq/SRR122/079/SRR12207279/SRR12207279_1.fastq.gz  ./\n\nSRA数据转化为fastq文件使用SRA-Toolkit中的fastq-dump工具将SRA数据转化为fastq文件。\n转换之前需要知道我们拿到的数据是单端还是双端数据4。\n# 如果返回值是4，就是单端SE；如果返回值是8，那么就是双端PE。fastq-dump -X 1 --split-spot -Z SRR5489805.sra | wc -l#SE数据fastq-dump SRR15671203 -O ./#PE数据fastq-dump ERR009357.4 --split-3 -O ./\n\n可以写一个批量脚本，输入文件在/data/input, 输出文件在/data/output.\n#!/bin/bash# 获取当前脚本所在目录，并输出SHELL_FOLDER=$(cd &quot;$(dirname &quot;$0&quot;)&quot;;pwd)echo $SHELL_FOLDER# 将当前脚本所在目录加上&quot;/data/input&quot;作为输入目录Input_Folder=$&#123;SHELL_FOLDER&#125;&quot;/data/input&quot;Output_Folder=$&#123;SHELL_FOLDER&#125;&quot;/data/output&quot;cd $Input_Folderexport PATH=$PATH:/dev/sda1/home/tenney/app/sratoolkit/sratoolkit.3.0.5-centos_linux64/binwhile read linedo  fastq-dump $line -O $Output_Folderdone &lt; SRR_Acc_List.txt\n\n结论值得注意的是，一个GSM编号是可能对应多个Run(SRR) 的，应对的方法可以是分别qc和align，最后quantification的时候考虑合并5。\n\n简单来说，PRJNA相当于是一个project，里面可以有许多experiment（SRX）以及样品（SRS）,每个SRX可以有若干个Run（SRR）。你这3个Run应该分开qc和align，如果都没问题的话，最后quantification的时候可以合并。这样的好处是，如果里面有一个Run的数据不好，你可以知道并随时舍弃，而不会影响你最后的结果。\n\n引用\n下载NCBI SRA数据的最佳方法 - 知乎\n02. Installing SRA Toolkit · ncbi&#x2F;sra-tools Wiki · GitHub\n下载NCBI的SRA数据 详细教程 - 知乎\nSRA数据 (2)——SRA数据处理 - 简书\n为什么GEO数据库里一个样本会对应多个SRR文件？ - 知乎\n\n","categories":["生物信息学"],"tags":["GEO","SRA"]},{"title":"当 SRA 不能 dump 出来有效数据，如何使用 Amazon S3 下载原始数据 (Use Cloud Data Delivery)","url":"/2025/05/29/bioinformatics/s3%E6%95%B0%E6%8D%AE%E4%B8%8B%E8%BD%BD/","content":"引言做上游做多了，总有从 sra 数据 dump 不出来需要的东西的情况，有时候是缺一端的匹配数据，有时候是上传的 bam, 有时候是少 l1 文件，总之总有奇奇怪怪的理由不能用 sra, 这时候就需要使用 Amazon S3 下载原始数据。\nAmazon S3 是一个对象存储服务，提供了高可用性和可扩展性，适合存储和检索大量数据。对于生物信息学领域，S3 是 NCBI 指定的数据交付手段。缺点：要钱。但第一年免费。\n过程注册帐号https://portal.aws.amazon.com/billing/signup#/start/email\n注册一个 AWS 帐号，注意需要绑定信用卡。\n创建 S3 存储桶地区我选的 us-east-1.\n\n登录 AWS 管理控制台。\n在服务列表中选择 S3。\n点击“创建存储桶”。\n输入存储桶名称（必须唯一）和区域。\n配置存储桶设置（如版本控制、加密等）。\n点击“创建存储桶”。\n\nUse Cloud Data Delivery[3]在Deliver Data页面点击Choose data to deliver in Run Selector按钮选取数据集。\n会跳转到https://www.ncbi.nlm.nih.gov/Traces/study/页面。\n在Choose destination bucket中选择刚才创建的 S3 存储桶。\n在Select one or more source file types中选择你需要的数据类型 (也就是除了 SRA Run 和 SRA Lite 以外的类型)。\n发送！\n下载数据我很懒，所以使用了 Use Cloud Data Delivery 之后下载全部就完事了，然后等下载完成后删除，这样下次就还是全新的数据全下就好。\n使用 AWS CLI 下载数据第一，安装 AWS CLI：https://docs.aws.amazon.com/cli/latest/userguide/install-cliv2.html\n第二，配置 AWS CLI：\naws configure\n\n输入你的 AWS Access Key ID、Secret Access Key、默认区域和输出格式。\n第三，使用以下命令下载数据：\naws s3 cp s3://your-bucket-name/path/to/your/file /local/path/to/save\n\naws s3 cp --recursive s3://datsra ./\n\n增强下载工具跳过下载失败文件使用 aws s3 sync 命令：\naws s3 sync 命令会比较本地文件和 S3 上的对象的大小和最后修改时间，仅下载新增或已更改的文件。如果某些文件在之前的下载中失败，sync 命令会尝试重新下载这些文件。\naws s3 sync s3://datsra ./\n\n请注意，sync 命令并不支持断点续传，如果下载过程中断，重新执行命令会从头开始下载整个文件。\n如果不放心他下载什么可以使用--dryrun查看接下来要运行的动作，但并不会实际运行，完整命令是aws s3 sync s3://datsra ./ --dryrun.\n使用支持断点续传的工具我实际没有实验但是看起来还行。\n由于 AWS CLI 不支持断点续传，您可以考虑使用支持该功能的工具，如 s5cmd。s5cmd 是一个高性能的 S3 和本地文件系统之间的文件传输工具，支持并发操作和断点续传，适合处理大量文件的下载任务。\n安装 s5cmd（以 macOS 和 conda 为例）：\nbrew install s5cmdconda install s5cmd\n\n使用 s5cmd 下载 S3 存储桶中的所有文件：\ns5cmd sync s3://datsra/ ./\n\ns5cmd 会自动跳过已成功下载的文件，并重新尝试下载失败的文件，支持断点续传，适合在网络不稳定的环境下使用。\n账单查看网页一天就失效而且那个验证码太难了吧…\n还好命令行也能看。\naws ce get-cost-and-usage \\  --time-period Start=2025-06-01,End=2025-06-02 \\  --granularity DAILY \\  --metrics &quot;BlendedCost&quot;\n\n如果权限不够就是没添加权限策略 (An error occurred (AccessDeniedException) when calling the GetCostAndUsage operation: User: ** is not authorized to perform: ce:GetCostAndUsage on resource: arn:aws:ce:us-east-1:637423541882:&#x2F;GetCostAndUsage because no identity-based policy allows the ce:GetCostAndUsage action)。\n您遇到的错误提示表明，当前 IAM 用户（arn:aws:iam::637423541882:user&#x2F;lev）未被授权执行 ce:GetCostAndUsage 操作。这通常是由于缺少相应的 IAM 策略所致。\n要解决此问题，您需要为该 IAM 用户添加允许执行 ce:GetCostAndUsage 操作的权限。以下是一个示例策略，授予对 AWS Cost Explorer 的完全访问权限[4]：\n&#123;  &quot;Version&quot;: &quot;2012-10-17&quot;,  &quot;Statement&quot;: [    &#123;      &quot;Effect&quot;: &quot;Allow&quot;,      &quot;Action&quot;: &quot;ce:*&quot;,      &quot;Resource&quot;: &quot;*&quot;    &#125;  ]&#125;\n\n您可以通过以下步骤将此策略附加到 IAM 用户：\n\n登录到 AWS 管理控制台。\n导航到 IAM 服务。\n在左侧导航栏中，选择 用户，然后点击您的用户名（例如，lev）。\n选择 权限 标签页。\n点击 添加权限。\n选择 附加现有策略直接。\n点击 创建策略，然后选择 JSON 选项卡。\n粘贴上述策略 JSON。\n点击 下一步：标签，然后点击 下一步：查看。\n为策略命名，例如 CostExplorerFullAccess，然后点击 创建策略。\n返回到 添加权限 页面，刷新策略列表，搜索并选择刚创建的策略。\n点击 下一步：查看，然后点击 添加权限。([Stack Overflow][1])\n\n然后关于资费，我实际测试发送到云 100g 大约是 0.3 美元，也就是 2 人民币，然后下载网上说从美国东部 S3 存储桶下载数据到日本或台湾的互联网用户，属于“数据传出到互联网”，费用通常为每 GB $0.09 美元，也就是 6 毛左右。\n结论这技能做时间长了肯定用得上…\n引用\nAWS S3 下载数据集必学入门教程 - 蓝鹰博客\n新手 AWS S3 下载数据集必学入门教程-CSDN 博客\nCloud Data Delivery Service\nuser is not authorized to perform: ce:GetCostAndUsage - stackoverflow\n\n","categories":["bioinformatics"],"tags":["bioinformatics","amazon-s3"]},{"title":"一种较为通用的GEO数据ID转换的方案","url":"/2023/09/25/bioinformatics/%E4%B8%80%E7%A7%8D%E8%BE%83%E4%B8%BA%E9%80%9A%E7%94%A8%E7%9A%84GEO%E6%95%B0%E6%8D%AEID%E8%BD%AC%E6%8D%A2%E7%9A%84%E6%96%B9%E6%A1%88/","content":"引言在我们使用GEO数据的时候, 经常要把探针名对应上Gene Symbol, 但使用提供的R包转换经常会出现GPL平台不支持的情况, 那有没有一种较为通用的转换方案呢.\n过程Gene类别介绍GPL结构介绍芯片数据 - Array高通量数据 - Highthrou注释文件类别介绍Probe文件提取结论总而言之, 本文介绍了一种较为通用的GEO数据ID转换的方案, 为新手进行生物信息学分析提供了帮助.\n引用\nR包clusterProfiler: 转换ID、GO&#x2F;KEGG富集分析 - 简书\n\n","categories":["生物信息学"],"tags":["R 语言","差异分析"]},{"title":"免疫浸润分析","url":"/2023/07/15/bioinformatics/%E5%85%8D%E7%96%AB%E6%B5%B8%E6%B6%A6%E5%88%86%E6%9E%90%20-%20cibersort/","content":"引言效果展示过程结论引用\n免疫浸润分析 - 知乎\n免疫细胞浸润分析—–单样本GSEA（ssGSEA） - 知乎\n\n","categories":["生物信息学"]},{"title":"去除批次效应输入什么值","url":"/2023/10/30/bioinformatics/%E5%8E%BB%E9%99%A4%E6%89%B9%E6%AC%A1%E6%95%88%E5%BA%94%E8%BE%93%E5%85%A5%E4%BB%80%E4%B9%88%E5%80%BC/","content":"引言首先，这个我怀疑不是 log 数据，而是 tpm, tpm 加一起是 1 百万，所以单个一般就是几，十几二，ComBat 的输入要求是经过归一化操作的表达量数据，归一化的方法可以是 array 等包处理的，也可以用 ComBat-Seq 处理 raw count三，在 sva 包的 sva for sequencing (svaseq) 一节中，作者说In our original work we used the identify function for data measured on an approximately symmetric and continuous scale. For sequencing data, which are often represented as counts, a more suitable model may involve the use of a moderated log function(在我们最初的工作中，我们对在近似对称和连续尺度上测量的数据使用了识别函数。对于通常表示为计数的测序数据，更合适的模型可能涉及使用调节的对数函数),这表示可能确实存在使用 log2 的用法。\n效果展示过程结论引用\nAdjusting batch effects in microarray expression data using empirical Bayes methods | Biostatistics | Oxford Academic\nR 语言-sva 包处理批次效应 | KeepNotes blog\nsva\n\n","categories":["生物信息学"]},{"title":"基因全称和缩写的转换","url":"/2023/08/30/bioinformatics/%E5%9F%BA%E5%9B%A0%E5%85%A8%E7%A7%B0%E5%92%8C%E7%BC%A9%E5%86%99%E7%9A%84%E8%BD%AC%E6%8D%A2/","content":"引言效果展示过程结论引用\n无痛解决基因全称与缩写的转换 - 简书\nUniProt\n网络药理学 | 利用 TCMSP 获取中药成分及靶点预测 - 知乎\n\n","categories":["生物信息学"],"tags":["Gene","GeneSymbol"]},{"title":"服务器通用软件配置","url":"/2024/03/17/bioinformatics/%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%80%9A%E7%94%A8%E8%BD%AF%E4%BB%B6%E9%85%8D%E7%BD%AE/","content":"lintr/home/tenney/.lintr\nlinters: with_defaults(line_length_linter = NULL, seq_linter = NULL)\n\nRoptions(repos = &quot;https://mirrors.pku.edu.cn/CRAN&quot;, BioC_mirror = &quot;https://mirrors.tuna.tsinghua.edu.cn/bioconductor&quot;)if (interactive() &amp;&amp; Sys.getenv(&quot;TERM_PROGRAM&quot;) == &quot;vscode&quot;) &#123;    if (&quot;httpgd&quot; %in% .packages(all.available = TRUE)) &#123;        options(vsc.plot = FALSE)        options(device = function(...) &#123;            httpgd::hgd(silent = TRUE)            .vsc.browser(httpgd::hgd_url(), viewer = &quot;Beside&quot;)        &#125;)    &#125;&#125;\n\nR 装包问题装机大礼包sudo apt-get install libfontconfig1-devsudo apt-get install libharfbuzz-dev libfribidi-devsudo apt-get install libfreetype6-dev libpng-dev libtiff5-dev libjpeg-devsudo apt install libssl-devsudo apt install libcurl4-openssl-dev libssl-dev libxml2-dev libcairo2-dev libgtk-3-dev libhdf5-devsudo apt install libmagick9-dev libcairo2-dev libxt-devsudo apt install libcairo2-dev libxt-devsudo apt-get install  libgmp3-dev# 有些包的装法, conda同样sudo apt-get install r-cran-car r-cran-factoextra# radiansudo apt install python3 python3-pippip install radian\n","categories":["生物信息学"]},{"title":"缺少部分基因长度 counts 还可以转换为 tpm 吗？","url":"/2024/09/19/bioinformatics/%E9%80%82%E7%94%A8%E4%BA%8Egeo%E7%9A%84tpm%E8%BD%AC%E6%8D%A2/","content":"引言在转录组学的机器学习任务中，counts 值（即原始读取数）通常不适合作为输入数据，而每百万缩放因子长度（TPM, Transcripts Per Million）更适合作为特征。\n而我们在实际使用的时候，很多 geo 的数据并不会提供 tpm 数据或原始 fastq 数据，因此，弄清楚 geo 数据集的 counts 转换为 tpm 的方法是有必要的。\n事实上，互联网上有很多人提供了 counts 转换为 tpm 的教程[1-3], 一般的流程是：\n\n通过 GTF 文件或基因长度文件获取外显子长度文件\n构建带有对应基因长度的表达矩阵\n计算 TPM\n目标基因的外显子长度之和除以 1000\n基于 counts 计算每千碱基 reads 长度标准化 (RPK, Reads Per Kilobase)\n基于 RPK 计算 TPM\n\n\n\n但是按照这个流程会出现一个问题，那就是计算 RPK 的过程中需要使用 Ensembl ID, 而 TPM 的过程中需要计算一次单样本所有表达量之和，所以如果按照这个流程就会造成两种可能：\n\n无法计算 (无法 ID 转换或无法获得基因长度)\n数据失真 (只计算部分基因之和或获得了错误的基因长度)\n\n一开始我打算借助 CPM(Counts Per Million) 进行计算，但是发现 tpm 是有本质区别的还是算了。因为 counts 本质是 fragments 或 reads, 所以没办法在不借助基因长度的情况下转换。\n过程从 counts 直接计算 TPM（Transcripts Per Million）需要考虑基因的表达量和基因长度。具体公式如下：\n公式步骤\n计算 RPK（Reads Per Kilobase）：对于每个基因，先计算每个基因的 RPK 值。RPK 是指每千碱基的 reads 数：[\\text{RPK}{i} &#x3D; \\frac{\\text{counts}{i}}{\\text{efflen}_{i} &#x2F; 1000}]其中：\n\n( \\text{counts}_{i} )：基因 ( i ) 的原始 counts 值\n( \\text{efflen}_{i} )：基因 ( i ) 的有效长度，以碱基数为单位\n( 1000 ) 将基因长度转化为千碱基单位\n\n\n计算每个样本中所有基因的 RPK 总和：对于每个样本，计算所有基因的 RPK 总和：[\\text{sum_RPK} &#x3D; \\sum_{i} \\text{RPK}_{i}]\n\n计算每个基因的 TPM：最后，将每个基因的 RPK 除以总 RPK 并乘以 1,000,000，标准化得到 TPM：[\\text{TPM}{i} &#x3D; \\frac{\\text{RPK}{i}}{\\text{sum_RPK}} \\times 10^6]\n\n\n总结的公式[\\text{TPM}{i} &#x3D; \\frac{\\left( \\frac{\\text{counts}{i}}{\\text{efflen}{i} &#x2F; 1000} \\right)}{\\sum{j} \\frac{\\text{counts}{j}}{\\text{efflen}{j} &#x2F; 1000}} \\times 10^6]\nR 代码示例# counts_matrix 是你的表达矩阵，行是基因，列是样本# gene_lengths 是每个基因的有效长度向量，与 counts_matrix 的行对应# 1. 计算 RPKrpk_matrix &lt;- sweep(counts_matrix, 1, gene_lengths / 1000, FUN = &quot;/&quot;)# 2. 计算每个样本的 RPK 总和sum_rpk &lt;- colSums(rpk_matrix)# 3. 计算 TPMtpm_matrix &lt;- sweep(rpk_matrix, 2, sum_rpk, FUN = &quot;/&quot;) * 1e6# 查看结果head(tpm_matrix)\n\n结论篇外转录组学的机器学习任务中选择 tpm 值原因在转录组学的机器学习任务中，counts 值（即原始读取数）通常不适合作为输入数据，而 TPM（Transcripts Per Million） 更适合作为特征，主要有以下几个原因：\n\n测序深度和基因长度的影响：\n\nCounts 值直接反映了测序获得的某个基因的原始读数数量，但这个数量会受到测序深度（即测序的总读取数）和基因长度的影响。即使是同一基因在不同的样本中表达水平相同，测序深度不同的样本中的 counts 值可能会有显著差异。\nTPM 是一种标准化的表达量，考虑了基因长度和测序深度的差异，消除了这些因素对表达量的影响，使得不同样本之间的基因表达量可以更好地进行比较。\n\n\n数据的可比性：\n\n由于 counts 值在不同的样本中没有标准化，直接使用它们会导致样本之间的数据不具有可比性，尤其是当测序深度不同的情况下。\nTPM 标准化了每个样本的基因表达量，将基因表达水平表示为每百万个转录本中某个基因的转录本数量，从而在不同样本之间具有可比性。\n\n\n机器学习模型的输入要求：\n\n机器学习算法通常假设输入数据在不同特征之间是可比的、归一化的，以避免某些特征因为数值范围过大或过小对模型产生不平衡的影响。\nTPM 通过标准化 counts 值，缩小了数值范围，并使数据分布更加符合模型的要求，从而提高模型的稳定性和性能。\n\n\n避免稀疏性和噪声问题：\n\n原始的 counts 值在很多基因上会非常稀疏，尤其是低表达基因的 counts 值可能为零或非常低，这些零值或极小的值会在机器学习模型中引入不必要的噪声。\nTPM 通过标准化表达数据，可以减小这些稀疏性问题，使得表达值更平滑、更连续，有助于模型更好地提取特征。\n\n\n\n因此，TPM 更适合作为转录组学机器学习的输入数据，因为它通过标准化表达量，提升了数据的可比性、模型的性能以及分析的准确性。\n引用\n关于 Count，FPKM，TPM，RPKM 等表达量的计算_计算 fpkm readscount-CSDN 博客\n生信小白教程之 Count 转 TPM，FPKM - 简书\nfeatureCounts 得到的 counts 计算 cpm、tpm、FPKM - 简书\n\n","categories":["生物信息学"],"tags":["生物信息学"]},{"title":"苹果土耳其账号注册","url":"/2023/05/14/Course/%E8%8B%B9%E6%9E%9C%E5%9C%9F%E8%80%B3%E5%85%B6%E8%B4%A6%E5%8F%B7%E6%B3%A8%E5%86%8C/","content":"引言效果展示过程使用 www.oyunfor.com 购买可以用银联 (信用卡的第二个选项).\n支付需要一定时间审查，一般需要 4 min 左右。\n9:23–&gt;9:27\n10 TL &#x3D; 3.63 人民币\n2T 65 TL 一月，所以一月仅 23.595 人民币。现已涨价，130 了。\n\n\n\n容量\n里拉\n人民币\n\n\n\n50G\n25\n9.075\n\n\n200G\n39,99\n14.52\n\n\n2T\n130\n47.19\n\n\n购买后的卡密可以在Products I Bought找到。\n在 appstore 中直接使用即可，无二次密码，如需输入密码是帐号的登录密码。\n结论引用\n苹果土耳其账号注册、购买礼品卡、充值、家庭共享 iCloud 超详细教程 - 知乎\noyunfor\nApple Store Hediye Kartı Kodu - iTunes Hediye Kartı Satış Sitesi\n\n","categories":["Course"],"tags":["苹果","IOS","icloud"]},{"title":"文献和数据集检索记录方法","url":"/2024/11/11/bioinformatics/%E6%96%87%E7%8C%AE%E5%92%8C%E6%95%B0%E6%8D%AE%E9%9B%86%E6%A3%80%E7%B4%A2%E8%AE%B0%E5%BD%95%E6%96%B9%E6%B3%95/","content":"引言在科研初期，有些导师很喜欢让学生写综述，认为这能够系统性地学习某一领域的知识，有助于快速提升学生在单一领域的学术素养和研究能力，同时还能提高文献调研和学术写作能力。然而，实际上学生花费两到三个月的时间，尽管感到十分疲惫，却往往收获甚微。这背后有几个原因：\n\n时间消耗大\n不知道如何着手写作\n容易停留在表面总结\n\n对于缺乏经验的学生来说，他们往往会陷入随机查找文献和粗略总结的状态，既感到疲惫，又缺乏成就感。这种方式不仅效率低下，也很难在过程中获得实质性的学术进展。\n所以，这里介绍一种快速检索文献和记录的方法，能够快速地找到某一领域的文献进行检索并记录。\n使用到的工具：\n\n文献检索工具：XMOL 学术平台\n文献记录工具：Excel\n\n效果展示\n\n过程大方向第一步，如果是还没有开始研究，主要是学习方法，就去除自己要选择的疾病和数据倾向，只选择自己感兴趣的方法，比如要用机器学习关键词就包含机器学习，要使用神经网络关键词就包含神经网络。总之就是留下你需要查询的主干。\n同理，如果你是要专注某一个领域比如糖尿病，那么就留下糖尿病相关的关键词，然后再根据自己的需求增加其他关键词减少文章的数量。事实上理想情况下我们当然是希望可以看完所有的文章，但是这是不可能的，世界上那么多人都在做研究，怎么可能能看完所有文章，掌握所有技巧呢，不可能的。因此，我们只对对自己最有用的知识感兴趣。\n对于我个人来说，第一轮搜索往往是去大量的看方法，所以我除了会记录文献的标题、摘要、年份、影响因子、链接等，还会记录文献中用到的方法和数据量，然后对其对我的价值进行评分，评分分 3 个档次，1 分，2 分，3 分，也就是一般，有用，非常有用，另外还有一个 10 分，也就是非常非常有用 (照着抄就行)。\n具体方向第二步，你已经有了一个大概的文献列表，然后你就可以开始阅读文献，从中确定你自己的研究路径。\n数据集第三步，再检索一次文献，这一次只对自己的目标疾病和数据种类进行检索，比如非小细胞肺癌 + 转录组学，并记录文献中的数据集。值得注意的是，考虑到查全和查准，需要对疾病的名称做多次检索，可以考虑使用 Pubmed 的 Mesh 词系统等。\n对于生信来说，如何获取有效的数据集非常重要。数据集的记录最主要包括数据集的名称，描述，样本量，数据类型，样本类型 (组织&#x2F;细胞系)，数据链接。\n小技巧所谓小技巧，就是没有也能做，但是有了可以显著提高效率的东西。\n首先介绍一下 XMOL 学术平台，这是一个学术资源整合平台，可以检索到很多学术资源，而本次作者主要使用它来检索学术期刊文献。\n高级检索地址：\nhttps://www.x-mol.com/paper/search\n这个平台的好处就是，首先他具有双语搜索，第二他自带了影响因子等评价。\n然后介绍一个复制 xmol 信息的小技巧。我写了一个 javascript 脚本用来复制我认为比较有用的信息，包括标题、摘要、年份、影响因子、链接等，当然你认为有用的信息也可以加到脚本里。\n使用方法：\n\n随便收藏一个网页到收藏夹栏，然后拉到显眼的位置\n鼠标右键点击上一步收藏网页的图标，右键选择编辑\n名称：复制 xmol 信息\n地址：将以下代码粘贴到地址栏 (URL)\n\njavascript:(function()%7Bvar%20allStrongElements%3Ddocument.querySelectorAll(%22strong%22)%3Bvar%20copiedContent%3D%5B%5D%3Bfunction%20copyTextToClipboard(text)%7Bvar%20tempInput%3Ddocument.createElement(%22textarea%22)%3BtempInput.value%3Dtext%3Bdocument.body.appendChild(tempInput)%3BtempInput.select()%3Bdocument.execCommand(%22copy%22)%3Bdocument.body.removeChild(tempInput)%3B%7Dfunction%20collectContent()%7BcopiedContent.push(allStrongElements%5B0%5D.textContent.trim())%3Bvar%20magazineContent%3Ddocument.querySelector(%22.magazine-content%22)%3Bif(magazineContent)%7Bvar%20span%3DmagazineContent.querySelector(%22span%22)%3Bif(span)%7Bvar%20cleanContent%3Dspan.textContent.replace(%2F%5Cs%2B%2Fg%2C&#x27;&#x27;)%3BcopiedContent.push(cleanContent)%3B%7Delse%7BcopiedContent.push(%22%22)%3B%7D%7Delse%7BcopiedContent.push(%22%22)%3B%7Dvar%20numbers%3DallStrongElements%5B1%5D.textContent.match(%2F%5Cd%7B4%7D%2Fg)%3Bif(numbers)%7BcopiedContent.push(numbers.join(%22%22))%3B%7Delse%7BcopiedContent.push(%22%22)%3B%7Dvar%20orangeSpan%3Ddocument.querySelector(%22span%5Bstyle%3D&#x27;color%3Aorange&#x27;%5D%22)%3BcopiedContent.push(orangeSpan%3ForangeSpan.textContent%3A%22%22)%3BcopiedContent.push(window.location.href)%3Bvar%20result%3DcopiedContent%5B0%5D%2B%22%5Ct%22%2BcopiedContent%5B1%5D%2B%22%5Ct%5Ct%5Ct%5Ct%22%2BcopiedContent.slice(2).join(%22%5Ct%22)%3BcopyTextToClipboard(result)%3B%7DcollectContent()%3B%7D)()%3B\n\n\n这是我本人自用的模板链接，可以根据目的自行修改：\nhttps://wwao.lanzoue.com/b00g2qg34j\n密码：\n7nai\n其他网站复制方式Pubmed这是使用 easyScholar 插件获得影响因子的方式，其他插件可以自行更改。\njavascript:(function()%7Bvar%20result%3D%5B%5D%3Bvar%20title%3Ddocument.querySelector(%22h1%22)%3F.innerText.trim()%7C%7C%22%22%3Bresult.push(title)%3Bvar%20abstract%3Ddocument.querySelector(%22%23abstract%22)%3F.innerText.replace(%2F%5Cs%2B%2Fg%2C%27%20%27).trim()%7C%7C%22%22%3Bresult.push(abstract)%3Bresult.push(%22%22)%3Bresult.push(%22%22)%3Bresult.push(%22%22)%3Bvar%20timeText%3Ddocument.querySelector(%22.cit%22)%3F.textContent%7C%7C%22%22%3Bvar%20date%3D%22%22%3Bif(timeText)%7Bvar%20match%3DtimeText.split(%22%3B%22)%5B0%5D%3Bif(match)%7Bdate%3Dmatch.trim()%7D%7Dresult.push(date%7C%7C%22%22)%3Bvar%20sourceDiv%3Ddocument.querySelector(%22div.article-source%22)%3Bvar%20ifValue%3D%22%22%3Bif(sourceDiv)%7Bvar%20ifElements%3DsourceDiv.querySelectorAll(%22span.easyscholar-ranking%22)%3Bfor(var%20i%3D0%3Bi%3CifElements.length%3Bi%2B%2B)%7Bvar%20text%3DifElements%5Bi%5D.innerHTML%3Bif(text.includes(%22IF%22))%7Bvar%20match%3Dtext.match(%2FIF%5Cs*(%5Cd%2B%5C.%3F%5Cd*)%2F)%3Bif(match)%7BifValue%3Dmatch%5B1%5D%3Bbreak%7D%7D%7D%7Dresult.push(ifValue)%3Bvar%20link%3Dwindow.location.href%7C%7C%22%22%3Bresult.push(link)%3Bvar%20finalText%3Dresult.join(%22%5Ct%22)%3Bvar%20tempInput%3Ddocument.createElement(%22textarea%22)%3BtempInput.value%3DfinalText%3Bdocument.body.appendChild(tempInput)%3BtempInput.select()%3Bdocument.execCommand(%22copy%22)%3Bdocument.body.removeChild(tempInput)%3Bconsole.log(%22%E5%B7%B2%E5%A4%8D%E5%88%B6%E5%86%85%E5%AE%B9%3A%22%2CfinalText)%7D)()\n\n其他事实上这个脚本的 URL Decoder 格式是这样的：\n(function () &#123;  var result = [];  // 获取标题  var title = document.querySelector(&quot;h1&quot;)?.innerText.trim() || &quot;&quot;;  result.push(title);  // 获取摘要  var abstract =    document      .querySelector(&quot;#abstract&quot;)      ?.innerText.replace(/\\s+/g, &quot; &quot;)      .trim() || &quot;&quot;;  result.push(abstract);  // 添加 3 个空字符串来产生额外的 tab  result.push(&quot;&quot;);  result.push(&quot;&quot;);  result.push(&quot;&quot;);  // 获取时间  var timeText = document.querySelector(&quot;.cit&quot;)?.textContent || &quot;&quot;;  var date = &quot;&quot;;  if (timeText) &#123;    var match = timeText.split(&quot;;&quot;)[0];    if (match) &#123;      date = match.trim();    &#125;  &#125;  result.push(date || &quot;&quot;);  // 获取 IF 值  var sourceDiv = document.querySelector(&quot;div.article-source&quot;);  var ifValue = &quot;&quot;;  if (sourceDiv) &#123;    var ifElements = sourceDiv.querySelectorAll(&quot;span.easyscholar-ranking&quot;);    for (var i = 0; i &lt; ifElements.length; i++) &#123;      var text = ifElements[i].innerHTML;      if (text.includes(&quot;IF&quot;)) &#123;        var match = text.match(/IF\\s*(\\d+\\.?\\d*)/);        if (match) &#123;          ifValue = match[1];          break;        &#125;      &#125;    &#125;  &#125;  result.push(ifValue);  // 获取链接  var link = window.location.href || &quot;&quot;;  result.push(link);  // 组合所有内容并复制到剪贴板  var finalText = result.join(&quot;\\t&quot;);  var tempInput = document.createElement(&quot;textarea&quot;);  tempInput.value = finalText;  document.body.appendChild(tempInput);  tempInput.select();  document.execCommand(&quot;copy&quot;);  document.body.removeChild(tempInput);  console.log(&quot;已复制内容：&quot;, finalText);&#125;)();\n\n可以看到，这个脚本实际上是获取了标题，摘要，时间，影响因子，链接，然后使用 tab 键分隔，然后复制到剪贴板。\n其中复制影响因子的获取方式是获得 class 为 article-source 的 div 标签，然后获取其 class 为 easyscholar-ranking 的 span 标签，然后获取其 innerHTML, 然后获取其中的数字部分为 IF 值。\n比如按颜色查找:\n// ... existing code ...  // 获取IF值 - 新的获取方式  var ifValue = &quot;&quot;;  var spans = document.querySelectorAll(&quot;span&quot;);  for (var i = 0; i &lt; spans.length; i++) &#123;    var span = spans[i];    if (span.style.background === &quot;rgb(0, 113, 203)&quot; ||        span.style.backgroundColor === &quot;rgb(0, 113, 203)&quot;) &#123;      var text = span.textContent;      if (text.includes(&quot;IF:&quot;)) &#123;        var match = text.match(/IF:\\s*(\\d+\\.?\\d*)/);        if (match) &#123;          ifValue = match[1];          break;        &#125;      &#125;    &#125;  &#125;  result.push(ifValue);// ... existing code ...\n\n结论我们的目标是，少雕花，多做事，把时间花在刀刃上。\n","categories":["bioinformatics"],"tags":["文献检索"]},{"title":"国内生物信息学领域学位论文情况","url":"/2023/05/05/%E5%8C%BB%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%AD%A6/%E5%9B%BD%E5%86%85%E7%94%9F%E7%89%A9%E4%BF%A1%E6%81%AF%E5%AD%A6%E9%A2%86%E5%9F%9F%E5%AD%A6%E4%BD%8D%E8%AE%BA%E6%96%87%E6%83%85%E5%86%B5/","content":"中国科学技术大学基于基因组变异和免疫微环境的胃癌预后分析新冠肺炎患者炎症风暴免疫学特征的单细胞转录组和生物信息学研究\n摘要\nABSTRACT\n第1章 绪论\n1.1 COVID-19患者的免疫学反应\n1.2 研究COVID-19患者炎症风暴的重要性\n1.3 单细胞转录组技术和生物信息学方法在COVID-19患者中的研究现状\n1.4 论文选题目的和研究思路\n\n\n第2章 材料和方法\n第3章 利用单细胞转录组研究COVID-19患者炎症风暴的免疫学特征\n第4章 利用大规模整合分析研究多种感染类疾病炎症风暴的免疫紊乱机制\n第5章 利用相关生物信息学方法研究复发性流产患者蜕膜免疫微环境的紊乱机制\n第6章 总结与讨论\n参考文献\n附录S1 284个人类样本的临床特征\n附录S2 每个样本的质控指标\n致谢\n在读期间发表的学术论文与取得的其他研究成果\n\n引用\n基于基因组变异和免疫微环境的胃癌预后分析-中国知网\n新冠肺炎患者炎症风暴免疫学特征的单细胞转录组和生物信息学研究-中国知网\n\n","categories":["医学信息学"]},{"title":"差异分析分组构建到底谁在前面--关于limma包中model.matrix()的问题","url":"/2023/03/27/bioinformatics/%E5%B7%AE%E5%BC%82%E5%88%86%E6%9E%90%E5%88%86%E7%BB%84%E6%9E%84%E5%BB%BA%E5%88%B0%E5%BA%95%E8%B0%81%E5%9C%A8%E5%89%8D%E9%9D%A2--%E5%85%B3%E4%BA%8Elimma%E5%8C%85%E4%B8%ADmodel.matrix()%E7%9A%84%E9%97%AE%E9%A2%98/","content":"引言在使用limma包进行差异分析的过程中，我们都知道至少需要表达矩阵和分组矩阵两个文件，而在一些例子当中，还出现了一种叫差异比较矩阵的东西，那为什么有些需要有些不需要呢？不需要的会不会得到完全相反的上调下调基因？\n其实差异比较矩阵的差距只在于一行代码，是 design &lt;- model.matrix(~Group) 还是 design &lt;- model.matrix(~ 0 + Group) ，那么这个0究竟代表什么含义呢？\n过程根据官方文档 9.2 , 这一段讨论了一个简单的单通道实验，比较了两组老鼠，一组是野生型（Wt），另一组是突变型（Mu）。该实验的目标是识别两组老鼠之间的差异表达基因。为此，提供了两种不同的设计矩阵构建方法。\n首先是示例输入矩阵:\n\n\n\nFileName\nTarget\n\n\n\nFile1\nWT\n\n\nFile2\nWT\n\n\nFile3\nMu\n\n\nFile4\nMu\n\n\nFile5\nMu\n\n\n可以用R语言进行创建:\n## 创建文件名和目标向量filename &lt;- c(&quot;File1&quot;, &quot;File2&quot;, &quot;File3&quot;, &quot;File4&quot;, &quot;File5&quot;)target &lt;- c(&quot;WT&quot;, &quot;WT&quot;, &quot;Mu&quot;, &quot;Mu&quot;, &quot;Mu&quot;)## 使用cbind函数构建矩阵targets &lt;- data.frame(cbind(filename, target))##   filename target## 1    File1     WT## 2    File2     WT## 3    File3     Mu## 4    File4     Mu## 5    File5     Mu\n\n第一种方法是 实验-对照组比参数化 方法，其中设计矩阵包括突变型和野生型之间差异的系数。设计矩阵是通过为所有样本分配值为1，为突变型组分配值为1，为野生型组分配值为0来创建的。设计矩阵中的第一个系数估计野生型小鼠的平均对数表达，并起到截距的作用，第二个系数估计突变型和野生型之间的差异。\n HIere the first coefficient estimates the mean log-expression for wild type mice and plays the role of an intercept. The second coefficient estimates the difference between mutant and wild type.\nGroup &lt;- factor(targets$Target, levels=c(&quot;WT&quot;,&quot;Mu&quot;))design &lt;- model.matrix(~Group)colnames(design) &lt;- c(&quot;WT&quot;,&quot;MUvsWT&quot;)## r$&gt; design##   WT MUvsWT## 1  1      0## 2  1      0## 3  1      1## 4  1      1## 5  1      1## attr(,&quot;assign&quot;)## [1] 0 1## attr(,&quot;contrasts&quot;)## attr(,&quot;contrasts&quot;)$Group## [1] &quot;contr.treatment&quot;\n\n这种方法可以使用 R 中的 lmFit 函数实现。可以使用 eBayes 函数和 topTable 函数来识别不同表达的基因，将系数设置为**“MUvsWT”**。\nfit &lt;- lmFit(eset, design)fit &lt;- eBayes(fit)topTable(fit, coef = &quot;MUvsWT&quot;, adjust = &quot;BH&quot;)\n\n第二种方法是组均值参数化方法，其中设计矩阵包括分别为野生型和突变型组分配的系数，并将差异提取为对比。设计矩阵是通过为野生型样本分配值为1，为突变型样本分配值为0，并为突变型样本分配值为1，为野生型样本分配值为0来创建的。\ndesign &lt;- model.matrix(~0+Group)colnames(design) &lt;- c(&quot;WT&quot;, &quot;MU&quot;)## r$&gt; design##   WT MU## 1  1  0## 2  1  0## 3  0  1## 4  0  1## 5  0  1## attr(,&quot;assign&quot;)## [1] 1 1## attr(,&quot;contrasts&quot;)## attr(,&quot;contrasts&quot;)$Group## [1] &quot;contr.treatment&quot;\n\n这种方法可以使用 R 中的 makeContrasts 和 contrasts.fit 函数实现。可以使用 eBayes 函数和 topTable 函数来识别不同表达的基因，而不需要指定系数。\nfit &lt;- lmFit(eset, design)cont.matrix &lt;- makeContrasts(MUvsWT=MU-WT, levels=design)fit2 &lt;- contrasts.fit(fit, cont.matrix)fit2 &lt;- eBayes(fit2)topTable(fit2, adjust=&quot;BH&quot;)\n\n总之，这一段提供了两种不同的方法，用于创建一个单通道实验的设计矩阵，比较了两组老鼠，野生型和突变型组。这两种方法是处理-对比参数化和组均值参数化方法。这两种方法都可以使用 R 函数实现，可以用于识别两组老鼠之间的不同表达基因。\n\n结论因此, 结论是:\n仅限两组比较，如已将对照组排在前就可以不要差异比较矩阵，否则将导致结果完全倒转。\n原因是 design &lt;- model.matrix(~Group) 会先对需要比较的组进行比较，从第二列开始以对比组填充，而 model.matrix(~ 0 + Group) 只进行分组，不进行比较，如何进行比较由差异比较矩阵和 makeContrasts 函数结果控制。\n引用\n关于limma包中model.matrix()的问题-QA-生信技能树\n差异分析是否需要比较矩阵 - basic&#x2F;makeContrasts.md at master · bioconductor-china&#x2F;basic · GitHub\nlimma: Linear Models for Microarray and RNA-Seq Data User’s Guide\n\n","categories":["生物信息学"],"tags":["R 语言","差异分析"]},{"title":"学术工具专题","url":"/2023/04/30/%E5%8C%BB%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%AD%A6/%E5%AD%A6%E6%9C%AF%E5%B7%A5%E5%85%B7%E4%B8%93%E9%A2%98/","content":"引言效果展示过程ZoteroZotero 群组文库结论引用\n用好这几个工具，帮助你更高效地完成学术型小组作业 - 少数派\n\n\n","categories":["医学信息学"]},{"url":"/2025/06/09/%E5%8F%B6%E5%AD%90%E7%9A%84%E7%A5%9E%E5%A5%87%E5%B0%8F%E5%B7%A5%E5%85%B7/%E5%9B%BE%E7%89%87%E8%BD%AC%E6%89%AB%E6%8F%8F%E4%BB%B6/","content":"引言效果展示过程\n照片转电子扫描件&#x2F;复印件,在线照片扫描器 - 图改改\nLook Scanned\n\n可以使用 heic 格式的图片。\n电子印章生成器 - vtool工具箱\n"},{"title":"基于Zotero+python的参考文献格式生成方案","url":"/2023/07/31/%E5%8F%B6%E5%AD%90%E7%9A%84%E7%A5%9E%E5%A5%87%E5%B0%8F%E5%B7%A5%E5%85%B7/%E5%9F%BA%E4%BA%8EZotero+python%E7%9A%84%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E6%A0%BC%E5%BC%8F%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88/","content":"引言效果展示过程新建Collection为了获取bib文件, 我们新建一个Collection.\n\nSave to Zotero\n结论引用\n\n\n","categories":["叶子的神奇小工具"],"tags":["参考文献","Zotero","python"]},{"title":"机器学习中的数据归一化","url":"/2023/05/01/%E5%8C%BB%E5%AD%A6%E4%BF%A1%E6%81%AF%E5%AD%A6/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E4%B8%AD%E7%9A%84%E6%95%B0%E6%8D%AE%E5%BD%92%E4%B8%80%E5%8C%96/","content":"引言效果展示过程结论引用\n数据归一化及三种方法（python）\nPython – Sklearn：MinMaxScaler（将数据预处理为(0, 1)上的数）\n【机器学习】数据归一化——MinMaxScaler理解\n\n","categories":["医学信息学"],"tags":["机器学习","归一化"]},{"title":"每日一文献_2024_12_Week2","url":"/2024/12/09/%E6%AF%8F%E6%97%A5%E4%B8%80%E6%96%87%E7%8C%AE/%E6%AF%8F%E6%97%A5%E4%B8%80%E6%96%87%E7%8C%AE_2024_12_Week2/","content":"2024_12_Week2这周想看点数据库建设相关的。\n12_09https://www.x-mol.com/paper/1468698076951126016/t?adv\nLCMD：肺癌代谢组数据库\nEI 检索 SCI 升级版 生物学 2 区 SCI 基础版 生物 2 区\nComputational and Structural Biotechnology Journal ( IF 4.4 )\nPub Date : 2021-12-07 , DOI: 10.1016&#x2F;j.csbj.2021.12.002\n我们构建并介绍了第一个肺癌代谢组数据库（LCMD），一个免费提供的在线数据库，存放了从 65 项基于质谱的肺癌代谢组学研究中鉴定出的 2013 年肺癌相关代谢物。研究人员可以通过两种方式探索 LCMD。首先，通过在“浏览代谢物”模式下应用各种过滤器，用户可以访问满足过滤器规格的肺癌相关代谢物列表。对于每个代谢物，用户可以获得倍数变化的值（癌症&#x2F;正常）、倍数变化的统计显着性（p 值），以及所有基于质谱的肺癌代谢组学研究的比较研究设计，以识别这一点代谢物。其次，通过在“浏览研究”模式下应用各种过滤器，用户可以获得满足过滤器规格的基于质谱的肺癌代谢组学研究列表。对于每项研究，用户可以查看研究标本的类型、质谱 (MS) 方法、MS 数据处理软件和差异分析方法，以及所有已鉴定的肺癌相关代谢物。此外，每项研究的概述都通过图形摘要清楚地说明。LCMD (http://cosbi7.ee.ncku.edu.tw/LCMD/) 是第一个汇集肺癌相关代谢物有意义信息的数据库。\n有趣的点：\n\nClassify the studies by year &#x2F; biospecimens used &#x2F; chromatography used &#x2F; country\n在图片上可进行放大，选择，拖动，鼠标放上去可以显示数量，可以下载。\n标志物详情页\n\n","categories":["每日一文献"],"tags":["文献阅读"]},{"title":"自动规整微信接收文件-python","url":"/2023/03/08/%E5%8F%B6%E5%AD%90%E7%9A%84%E7%A5%9E%E5%A5%87%E5%B0%8F%E5%B7%A5%E5%85%B7/%E8%87%AA%E5%8A%A8%E8%A7%84%E6%95%B4%E5%BE%AE%E4%BF%A1%E6%8E%A5%E6%94%B6%E6%96%87%E4%BB%B6-python/","content":"相信大家都体验过以”小而美”著称的微信，这款神奇而伟大的软件无情的占据了每一个电脑的15g空间以上，而鄙人的电脑总空间…只有256…\n\n于是，本人注定和微信有一场旷日持久的战斗。\n微信与我而言最主要的问题有以下几点：\n\n在微信中下载的文件如果在微信中直接打开会变成只读无法直接编辑\n微信下载文件分散在各个文件夹内，甚至不同人发送的不同文件都会占用同一份内存\n当同名文件发送，微信会默默的在文件名后面加上一个”(1)”\n\n综上所述，写一个自动化脚本将各个文件夹内的接受文件转移到单独文件夹内是非常合理的。\n代码如下 (macOS):\n#!~/opt/anaconda3/bin/python# -\\*- coding: utf-8 -\\*-# Import the necessary modulesimport osimport shutil# Define the file path to the source directoryfilePath=&quot;/Users/sandy/Library/Containers/com.tencent.xinWeChat/Data/Library/Application Support/com.tencent.xinWeChat/2.0b4.0.9/e5935df9a7a640bff14105be4661fcb4/Message/MessageTemp&quot;dst_dir = &quot;/Users/sandy/Library/Mobile Documents/com~apple~CloudDocs/Downloads/wechatDownloadFiles&quot;# Get a list of files in the source directoryget_files_sourceDir = os.listdir(filePath)# Iterate over each file in the source directoryfor file_sourceDir in get_files_sourceDir:    # Define the path to the file within the source directory    file_source = filePath+&quot;/&quot;+file_sourceDir+&quot;/File&quot;    # Check if the file exists    if os.path.exists(file_source):        # Get a list of files in the file_source directory        get_files = os.listdir(file_source)        # Iterate over each file in the file_source directory        for file_ in get_files:            # Define the source and destination file paths            src_file = os.path.join(file_source, file_)            dst_file = os.path.join(dst_dir, file_)            # Check if the destination file exists            if os.path.exists(dst_file):                # Check if the source and destination files are the same                if os.path.samefile(src_file, dst_file):                    # If they are the same, skip this iteration of the loop                    continue                # If they are not the same, remove the destination file                os.remove(dst_file)            # Move the file from the source directory to the destination directory            shutil.move(file_source + &quot;/&quot; + file_, dst_dir)            # Print the name of the file that was moved            print(file_)    else:        # If the file does not exist, print an error message        print(&quot;The file does not exist&quot;)\n\n微信的默认接受文件夹可以在微信中接受文件后右键获取。\n如果是macOS可以使用自带的crontab进行自动化运行，使用方法是在terminal中输入crontab -e, 而后使用cron表达式 + 命令进行自动化部署。\n0 23 \\* \\* \\* /Users/sandy/opt/anaconda3/bin/python &quot;/Users/sandy/Nutstore Files/Nutstore/shell/moveWechatFiles.py&quot;\n\n0 23 \\* \\* \\*是cron表达式，代表每天23点。\npython &quot;moveWechatFiles.py&quot;代表运行命令，注意可以使用绝对路径来避免运行失败。\n另外，可以在之后加上&gt;/dev/null 2&gt;&amp;1以去除运行日志减少空间利用。\n","categories":["叶子的神奇小工具"],"tags":["Python","小工具","Mac OS"]},{"title":"收集 202311","url":"/2023/12/01/%E6%94%B6%E9%9B%86/%E6%94%B6%E9%9B%86%20202311/","content":"2023-12-01奥莉𝗢𝗹𝗹𝗶𝗲@MissOllie2020Subscribe我从来不会用「婚驴」这个词 但我确实对有些已婚女性恨铁不成钢如果一个女人 在婚后自愿做家庭主妇 自愿和社会脱节那几年后发现老公在外面有小三的时候就不要哭与社会脱节将会使你不再和另一半有共同话题同时你没有经济来源 就没有说话的底气男人是需要危机感的“我老婆这么优秀 事业也如此成功”“我老婆人老珠黄 只会在家带孩子”# 高下立判\n\n\nhttps://x.com/MissOllie2020/status/1730505849104154628?s=20\n","categories":["收集"]},{"title":"人生的价值","url":"/2024/09/15/%E6%9D%82%E8%B0%88/%E4%BA%BA%E7%94%9F%E7%9A%84%E4%BB%B7%E5%80%BC/","content":"人是为了向往而活的，是为了追逐感动而活的，为了睹见美而活的。\n人活着是为了追逐感动。\n","categories":["杂谈"]},{"title":"余生皆恋爱--致终身相伴的你","url":"/2023/06/17/%E6%9D%82%E8%B0%88/%E4%BD%99%E7%94%9F%E7%9A%86%E6%81%8B%E7%88%B1--%E8%87%B4%E7%BB%88%E8%BA%AB%E7%9B%B8%E4%BC%B4%E7%9A%84%E4%BD%A0/","content":"周末正论余生皆恋爱致终身相伴的你\n曾经有一个段子，说是 520 外国男人会买花买礼物，而中国男人只会打发老婆让他干活做饭洗衣服，当然这只是一个段子，因为中国外国人不说中文。\n但除了 520 之外的日子呢，大家又过的怎么样？\n\n没有用是一个很重要的东西\n没有意义也是个很重要的东西\n可能很多时候我们没有条件去挥霍，将之斥之为简简单单的浪费，\n那么我们能留下些什么痕迹呢？\n一粒尘埃，一粒沙子，还是一段思念呢\n中国有 4700 年历史，地球有 46 亿年历史，宇宙有 138 亿年历史，在这么漫长的时间里，我遇见了你，怎么会不是最浪漫的事情呢？\n一些天才曾经用数学来量化爱情，用博弈论，用算法，用模型，\n但是婚姻不是博弈，也没有最优解，甚至没有满意解。\n爱一个人是很平淡的事情，\n愿生如一，死如一，\n人只会相信想要相信的东西，\n与其纠结得失，不如为爱人做些什么吧。\n莫向外求\n当容颜不在，我还会爱着你。\n爱你。\n我们会有着无数次的欢喜和离别，路还很长，我们可以一起走过。\n你永远不会知道明天和意外哪个先来，生活就像一盒巧克力，\n老友记里面有一句话叫做，结婚的意义就在于让你遇到你的真命天女的时候说 i am married.结婚需要什么呢？其实结婚需要的东西很简单，就是。一套被子，一张床最好有个屋子。这叫搭伙过日子。老一辈的婚姻就是如此朴实，因为一个人无法生存，因为两个人可以拥有更高的抗风险比，可以繁衍后代，可以构成一个更加稳健的社会关系。但是也正是因为这样，现在才会有 1&#x2F;3 的离婚率。有着百分之多少的婚内出轨？很多人根本没有想过自己为什么要结婚，他只是年纪大了。他只是因为大家觉得他可以结婚了，他应该结婚了。所以会有很多人催着你。就算排除掉了，那些说。没有婚姻的人生是不完整的，这些脑残言论。还是会有很多长辈会以这为你好。真心实意的为你好的招牌，为你谋算结婚的相关事宜。\n","categories":["杂谈"],"tags":["周末正论"]},{"title":"关于跨性别女性和女性之间资源问题的看法","url":"/2022/05/11/%E6%9D%82%E8%B0%88/%E5%85%B3%E4%BA%8E%E8%B7%A8%E6%80%A7%E5%88%AB%E5%A5%B3%E6%80%A7%E5%92%8C%E5%A5%B3%E6%80%A7%E4%B9%8B%E9%97%B4%E8%B5%84%E6%BA%90%E9%97%AE%E9%A2%98%E7%9A%84%E7%9C%8B%E6%B3%95/","content":"我觉得一个人的社会性别来源于他特殊的独一无二的生活经历，而非他的生理，但是另一方面我们也不应该为社会性别去定义他为此应该做什么。性别的定义恰好是为了快速区分出拥有相似经历，面对统一事件有相似反应，会做出相似决策的人，可以说用生理性别去分群是不精确的，但是靠自我感知是错误的。\n\n事实上我认为人对自己的认知并非是平滑的，或者一成不变的，人本身就是在不断进行着变化，这其中包含着对事物的看法变化，决策变化，也包含着认知变化，我认为按照社会经历分群要比生理和认知人群更加精确，但同时这不代表着要赋予这种分群某种意义，只是为了更精确的找到自己的群体\n放到现实中来讲就是，我认为跨性别女性比起女性，更像是跨性别女性，因为她们拥有更相似的共同体验和反应决策系统。我并不认为她们需要“变得更像女性”，just do like yourself，ok？\n然后下面是暴论时间，有一个姐姐给我科普过一些关于跨性别女性在男性监狱受到强奸的风险和案例数要远远大于在女性监狱中强奸女性的。我很同情她们的遭遇，但我并不认为这是女性的错，付出一些女性的代价就可以换来更多的跨性别女性的安全，类似这样，这里的问题在于，为什么牺牲的是女性\n\n人的政治立场来源于自己的群体，\n\n跨性别女性的立场实际上是跨性别女性群体，而非女性群体，\n\n女权的提高来源于人权的提高，\n\n弱势群体的征求权利之路并不能来源于抢夺，只能来源于更底层的，更深层次更基础的提高。\n简单的说，你把女人吃绝户了你也得不到想要的的，别再盯着女人了\n还有最后一句，社会一直都是以牺牲一部分人，存活一部分人而前进的，一直以来我们牺牲的有弱者，有愚蠢者，有时运不济者，当然也有高洁者，有奉献者，但是随着技术的演进，特别是可以服务于人民的去中心化的技术，让人们有了脱离中心化的机会，我们可以去放弃更应该放弃者，以保全和我们更相似的人\n","categories":["杂谈"],"tags":["跨性别","Transgender"]},{"title":"cron创建自动任务","url":"/2023/11/18/%E5%8F%B6%E5%AD%90%E7%9A%84%E7%A5%9E%E5%A5%87%E5%B0%8F%E5%B7%A5%E5%85%B7/cron%E5%88%9B%E5%BB%BA%E8%87%AA%E5%8A%A8%E4%BB%BB%E5%8A%A1/","content":"引言效果展示过程mail文件可以在 var/spool/mail/ 中找到。\nmaccrontab文件位置没找到，但是可以直接编辑临时文件然后在vim读取。\n也有比如Cronette之类的软件可以直接可视化界面设置，但是我还是觉得命令行比较方便。当时用这个是因为某个版本crontab的权限出了问题，只能找平替。\nmail文件可以在 /private/var/mail/ 中找到。\ncron表达式[2]在crontab中，只要前六个就行。\n在大部分使用cron的场景下， * - , &#x2F; ? 这几个常用字符就可以满足我们的需求了。\n【】：每的意思。在不同的字段上，就代表每秒，每分，每小时等。【-】：指定值的范围。比如[1-10]，在秒字段里就是每分钟的第1到10秒，在分就是每小时的第1到10分钟，以此类推。【,】：指定某几个值。比如[2,4,5]，在秒字段里就是每分钟的第2，第4，第5秒，以此类推。【&#x2F;】：指定值的起始和增加幅度。比如[3&#x2F;5]，在秒字段就是每分钟的第3秒开始，每隔5秒生效一次，也就是第3秒、8秒、13秒，以此类推。【?】：仅用于【日】和【周】字段。因为在指定某日和周几的时候，这两个值实际上是冲突的，所以需要用【?】标识不生效的字段。比如【0 1 ** ?】就代表每年每月每日每小时的1分0秒触发任务。这里的周就没有效果了。\n比如每天的13:10:05运行就是：5 10 13 * * ?\n每天的8-23点每个10:05运行就是：5 10 8-23/1 * * ?\n结论引用\nmac电脑—设置crontab - 知乎\n简洁明了看懂cron表达式 - 知乎\n4-13-2 Linux中的计划作业 — crontab（三、mail 的去向） - 简书\n\n","categories":["叶子的神奇小工具"]},{"title":"结婚相关事宜","url":"/2023/06/17/%E6%9D%82%E8%B0%88/%E7%BB%93%E5%A9%9A%E7%9B%B8%E5%85%B3%E4%BA%8B%E5%AE%9C/","content":"引言","categories":["杂谈"],"tags":["结婚list"]},{"title":"github_repo","url":"/2024/02/22/%E6%94%B6%E9%9B%86/github_repo/","content":"中国科研常用LaTeX模板集GitHub - huangwb8&#x2F;ChineseResearchLaTeX: 中国科研常用LaTeX模板集\n","categories":["收集"]},{"title":"年龄与时间感","url":"/2025/04/05/%E6%9D%82%E8%B0%88/%E5%B9%B4%E9%BE%84%E4%B8%8E%E6%97%B6%E9%97%B4%E6%84%9F/","content":"我相信大家都有一种感觉，就是随着年龄的增大，时间仿佛在越来越快。\n小时候课间十分钟可以去操场跑一个来回顺便去趟小卖部，但是现在快 30 岁的我 20 分钟只够喝杯水，上个厕所。\n于是，我尝试着计算我的一分钟等价于多少事，一分钟我可以游 25m, 可以走 m, 穿着拖鞋跑 m, 可以敲 72 个汉字或个 139 英文字符。\n所以我\n或许，不是时间越来越快，而是记忆越来越多。不愿意放弃任何回忆，就会在不断不断的触发回忆之中无暇思考。\n我想要保持热情，保持新鲜感。我要让自己变得有趣而不是变得”完整”.\n食物也要吃，毒也要吃，才是健康的！\n","categories":["杂谈"]},{"title":"如梦处醒然时间已去不复返","url":"/2024/09/14/%E6%9D%82%E8%B0%88/%E5%A6%82%E6%A2%A6%E5%A4%84%E9%86%92%E7%84%B6%E6%97%B6%E9%97%B4%E5%B7%B2%E5%8E%BB%E4%B8%8D%E5%A4%8D%E8%BF%94/","content":"年少时，我总觉得生活是一场梦，我是一个梦中的人物。\n我的举动会影响我的世界，但又有什么是重要的。\n古圣是存在的吗，未来是存在的吗，我生存的意义是…存在的吗…?\n小学初中的日子倒是无忧无虑，只管草长莺飞莺歌浪漫，但自高中起我就有一些对生命的疑惑。生命的好与坏是谁规定的，生命的价值是谁规定的，我真的要按照社会的规划去走完一生吗？生活中到底有没有转生，有没有重来，有没有穿越，有没有我们所期待的那些浪漫的事情或可以弥补遗憾的事情。\n高中的我或许只是为了逃避或许只是顺着肉体的信号，选择了一条可以说是放纵的路，我逃课，我疯狂看番，我整日沉溺在娱乐当中，也因此并没有取得出色的成绩，但其实我不算很后悔，因为那无疑是”我”的一部分。\n但不知道为什么，我一直有一种幻想，仿佛我在什么时候可以回来，可以重新在这个懵懂无知的时刻再活一次，可以用更超然的更正确的姿态去做人生中重要的选择。\n也同样是不知道为什么，我今天忽然有了实感，有了”啊，我真的已经回不去了”的感觉，是因为年龄到了吗，是因为我重要发现随着时间的无情向前，我熟悉的事物都在老去，我幻想中的那些都不会发生，我所依赖所信赖的也会变化，吗？\n我切实发现了我会成长，会给周边带来影响，会有回忆，会衰老，也会死亡 (如果有那样的一天，可以我希望我可以在众人的环绕中死去)。\n我的人生观一直在改变，高中的时候是知足长乐，大学的时候初尝到了爱情没啥想法，硕士的时候是人生的价值是为了追求美，那么博士的时候就是”负责”，吧。我已经有了太多的羁绊，我已经不仅仅是我了。\n嗯，我依然不是很喜欢那些宏大的事物，因为落到我们个人的头上都太大了，大到我们的眼睛看不到全景。我还是喜欢眼前的事物，我希望我的生活可以更好，我希望我的周边可以更好。\n总之，梦醒了，多了一些脚踏实地的感觉，虽然没有到今日方知我是我的程度，但是总算多了一些”这是我的生活”的觉悟。\n望诸事顺利！\n","categories":["杂谈"]},{"title":"深夜忆刘慈欣短篇作品有感","url":"/2024/09/15/%E6%9D%82%E8%B0%88/%E6%B7%B1%E5%A4%9C%E5%BF%86%E5%88%98%E6%85%88%E6%AC%A3%E7%9F%AD%E7%AF%87%E4%BD%9C%E5%93%81%E6%9C%89%E6%84%9F/","content":"深夜谈到刘浩存和她的九部影片，其中有一部带上她的眼睛，就忽然想到了刘慈欣的许多短篇作品，其中带上她的眼睛算是挺好看的作品了。\n我记得还和其他几个短篇共享世界观，应该是全频带阻塞干扰，这个也要电影化了，讲的是俄罗斯和美国打仗，俄罗斯电子战技术全面被碾压，信号被窃听，系统被利用，然后主角冲进太阳制造了一场黑子爆发彻底阻断了地球信号三天……\n其他很有趣的包括，地球大炮，讲的是人类打通地心做了一个超长电磁炮将上太空的成本降低到差不多为 0，但是因为没有经济收益而把发明者和创建者全干死了的故事（）\n地球大炮里面好像就讲了带上她的眼睛里那艘在地心挂掉的船的一点信息\n刘慈欣最好的短篇当属球状闪电，堪称三体前传，然后是朝闻道，讲的地球科学家面对地外超文明，在无知活下去和得到宇宙答案然后死中毫不犹豫的去死了的故事\n可惜我研究女权后发现三体着实有点厌女，所以书虽然能看但是不太乐意推了，同理还有诗云，初看非常惊艳，讲的外星人因仰慕李白烧完了一个太阳系的资源写出了所有汉字可以写出的诗，却发现没有检索手段所以还是没有发现超越李白的诗噗，这篇点子很给力但充满了理工男的自大，实现过程还不如去看走进修仙 - 毓族失所篇\n刘慈欣其实还写过一批儿童科幻，完全不在意实现过程，但是点子很有趣，烧炭工（完全的童话），微纪元（未来资源短缺人造小人国结果消灭肮脏原人类），镜子（所有人可以随意观看所有人的过去现在），天使时代（基因编辑给人类插上翅膀）\n赡养上帝（创造人类的上帝文明因为不懂自己先人发明的超文明产物而到地球乞讨吃的……），赡养人类（资本主义发展到终末期所有人都只给一个人打工然后这货把用不到的人丢出去打地球了……）\n其中最推荐看的是~~~~，没错就我赡养人类哒，按照“好”的等级排名其实应该是球状闪电，朝闻道，镜子，诗云，带上她的眼睛，但是赡养人类里面的杀手真的很酷所以没有问题\n最可惜的就是镜子了，那篇点子如果有人能写出来一个道德被重塑后的社会绝对会非常有趣，但是大刘这理工男最后得到了一个“道德没有瑕疵的社会死路一条”的结论，excuse me？你们男的不贪就会死是吧？我想看的是在全体开全知的情况下崭新的世界观道德观，崭新的新世界好吧，结果你直接跳过最关键的部分直接给整人类灭绝了……\n未来边缘（不小心回到过去推走了撞地球的小行星的宇航员回家的时候发现因陨石而灭绝的恐龙活到了现代还奴役了人类），白垩纪往事（没碰上陨石的恐龙和蚂蚁走上科技道路），吞食者（对抗恐龙的人类英雄和人类文明的第一次和最 后 一 次星战），诗云（战败人类怂恿超文明写诗导致太阳系被献祭顺便灭绝恐龙（括弧，诗写出来了量太大读不完））\n总之，大刘作品还是值得一看的，倒也不必非要奉为神作放进必读清单，但是解闷还是可以的，里面很多点子很有趣，令人忍不住多想几分，特别是三体 - 黑暗森林，如果只打算看一本，看黑暗森林就对了，这本绝对是大刘的思想和结构的最高峰，反而后面的死神永生在文学性上要差很多\n谢谢大家对叶子电台的收听，嗯，早安，睡了\n——四点半起夜一次却没睡着的叶\n","categories":["杂谈"],"tags":["刘慈欣","科幻小说"]},{"title":"bd 平台单细胞数据定量流程","url":"/2025/06/29/bioinformatics/%E5%8D%95%E7%BB%86%E8%83%9E%E5%88%86%E6%9E%90/bd%E5%B9%B3%E5%8F%B0%E5%AE%9A%E9%87%8F/","content":"引言效果展示过程环境配置## conda env createmamba create -n scbd python=3.11.3conda activate scbd## 安装 CWL-runnerpip install cwlref-runner### 如果pip安装失败，可以选择国内镜像安装pip install cwlref-runner -i https://pypi.douban.com/simple/## 拉取 Docker 镜像docker pull bdgenomics/rhapsody## 确认镜像存在docker images | grep bdgenomics/rhapsody\n\n流程下载地址在:\nhttps://bitbucket.org/CRSwDev/cwl/src/master/v2.0/\nref下载http://bd-rhapsody-public.s3-website-us-east-1.amazonaws.com/Rhapsody-WTA/Pipeline-version2.x_WTA_references/\n结论引用\nBD Rhapsody上游定量流程-腾讯云开发者社区-腾讯云\n\n"},{"title":"单细胞分析过程中的稀疏矩阵删减","url":"/2023/12/21/bioinformatics/%E5%8D%95%E7%BB%86%E8%83%9E%E5%88%86%E6%9E%90/%E5%8D%95%E7%BB%86%E8%83%9E%E5%88%86%E6%9E%90%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%9A%84%E7%A8%80%E7%96%8F%E7%9F%A9%E9%98%B5%E5%88%A0%E5%87%8F/","content":"引言在单细胞转录组分析中，偶尔会出现电脑内存有限等情况，无法直接读取所有数据，这种时候可以考虑分析部分数据。\n网上的教程提供了 python 和 R 两种代码[1,2]，但是实际操作中发现 R 代码并未提供正确的写出功能，所以本文以 python 作为示范。\n文件层级.├── main.py├── data│   ├── barcodes.tsv│   ├── features.tsv│   ├── matrix.mtx.gz│   ├── selected.tsv├── results│   ├── barcodes.tsv.gz│   ├── features.tsv.gz│   └── matrix.mtx.gz\n\n输入文件要求输入文件应被放入data文件夹内。需要matrix.mtx.gz、features.tsv、barcodes.tsv和selected.tsv四个文件，其中selected.tsv为包含了所需细胞名的单列无表头行名的tsv文件。features 或 barcodes 文件如果没有解压，需要提前解压。\n输出文件说明输出文件被输出到results文件夹内。文件名分别为barcodes.tsv.gz、features.tsv.gz和matrix.mtx.gz。输出文件可以被Seurat::Read10X读入。\n过程from scipy.io import mmreadimport pandas as pdimport numpy as np# 读取表达矩阵_index = pd.read_csv(&quot;./data/features.tsv&quot;, index_col=1, sep=&quot;\\t&quot;, header=None)_index.index.name = None  # 把索引列的列名去掉_col = pd.read_csv(&quot;data/barcodes.tsv&quot;, sep=&quot;\\t&quot;, header=None)_col.index.name = None  # 把列名向量的名去掉_data = mmread(&quot;data/matrix.mtx.gz&quot;).todense()# 处理表达矩阵## 挑选需求 col_col.index_selected = pd.read_csv(&quot;./data/selected.tsv&quot;, sep=&quot;\\t&quot;, header=None)_selected.index.name = None  # 把索引列的列名去掉filtered_index = list(set(_col[0]).intersection(_selected[0]))print(filtered_index.__len__())# 加行名列名rna_count = pd.DataFrame(    data=_data, index=_index.index, columns=_col.iloc[:, 0].tolist())filtered_columns = rna_count[filtered_index]rna_count = filtered_columnsprint(rna_count.iloc[0:3, 0:2])print(&quot;gene_ID_len : &quot; + str(rna_count.shape[0]))  ### 获取表达矩阵基因数print(&quot;cell_ID_len : &quot; + str(rna_count.shape[1]))  ### 获取表达矩阵细胞数# 重新写出 DataFrame 为 10X 格式的 sparse matrix 等相关文件import osimport shutilimport gzipimport scipyimport timefmt = &quot;%Y-%m-%d %a %H:%M:%S&quot;Date = time.strftime(fmt, time.localtime(time.time()))outdir = &quot;results&quot;os.makedirs(outdir, exist_ok=True)# Save matrix.mtx.gzreAnno_count_sparse_mtx = scipy.sparse.coo_matrix(rna_count.values)scipy.io.mmwrite(    os.path.join(outdir, &quot;matrix.mtx&quot;),    reAnno_count_sparse_mtx,    comment=&quot;Generate DateTime::&quot; + str(Date),)with open(os.path.join(outdir, &quot;matrix.mtx&quot;), &quot;rb&quot;) as mtx_in:    with gzip.open(        os.path.join(outdir, &quot;matrix.mtx&quot;) + &quot;.gz&quot;, &quot;wb&quot;    ) as mtx_gz:  # 创建一个读写文件&#x27;matrix.mtx.gz&#x27;，用以将 matrix.mtx 拷贝过去        shutil.copyfileobj(mtx_in, mtx_gz)os.remove(os.path.join(outdir, &quot;matrix.mtx&quot;))# Save barcodes.tsv.gzbarcodesFile = pd.DataFrame(rna_count.columns)barcodesFile.to_csv(    os.path.join(outdir, &quot;barcodes.tsv.gz&quot;), sep=&quot;\\t&quot;, header=False, index=False)# Save features.tsv.gzfeaturesFile = _indexfeaturesFile.to_csv(    os.path.join(outdir, &quot;features.tsv.gz&quot;), sep=&quot;\\t&quot;, header=False, index=False)\n\n将文件保存为main.py即可运行。\n下面是用到的库。\nnumpy==1.24.3pandas==2.0.1scipy==1.11.4\n\n结论总而言之但是读进去了，但是也是真慢啊…\n引用\npython 和 R 写出表达矩阵为稀疏矩阵 matrix.mtx.gz 的方法-CSDN 博客\n「单细胞转录组系列」如何从稀疏矩阵中提取部分数据进行分析_单细胞稀疏矩阵-CSDN 博客\n\n","categories":["生物信息学","单细胞分析"],"tags":["python"]},{"title":"记百香果女孩","url":"/2023/06/06/%E6%9D%82%E8%B0%88/%E8%AE%B0%E7%99%BE%E9%A6%99%E6%9E%9C%E5%A5%B3%E5%AD%A9/","content":"记百香果女孩闲来无事看了眼豆瓣, 结果看到了【2018.10.4】灵山奸杀女童案（百香果女孩案）\n, 几近心梗. 人怎么可以这样坏?\n经过2018年10月4日，广西壮族自治区钦州市灵山县伯劳镇平心村发生一起强奸杀人案，一名10岁女童被同村男子杨光毅强奸并杀害。\n2018年10月6日，即两日后，杨光毅投案自首。\n2019年7月12日，一审法院以强奸罪判处杨光毅死刑，剥夺政治权利终身，责令退赔32元给杨晓燕母亲陈礼言。\n其后，杨光毅提出上诉。经广西高院二审，改判死刑，缓期两年执行，剥夺政治权利终身，限制减刑。\n2020年5月10日，最高人民法院决定对广西壮族自治区高级人民法院二审终审的杨光毅强奸一案调卷审查。\n2020年5月11日，被害人家属向广西高院递交申诉，要求维持一审原判，判处杨光毅死刑立即执行。\n2020年11月11日，最高法院决定指令广西高院对杨光毅强奸案再审。\n2020年12月28日，广西壮族自治区高级人民法院对最高人民法院指令再审的原审被告人杨光毅强奸案进行公开宣判，撤销原二审判决，改判杨光毅死刑，剥夺政治权利终身，并依法报请最高人民法院核准。\n2021年2月2日，遵照最高人民法院下达的执行死刑命令，广西壮族自治区钦州市中级人民法院对“百香果女孩被害案”凶手杨光毅执行死刑。执行死刑前，钦州市中级人民法院告知杨光毅可以申请会见近亲属，但杨光毅拒绝申请。\n最高人民法院复核认为，原审被告人杨光毅为发泄私欲，无视国法，经事先预谋，携带刀具强行劫持同村幼女杨晓燕至山上，使用残忍的暴力手段实施奸淫，致杨晓燕死亡。杨光毅的犯罪动机卑劣，犯罪手段特别残忍，犯罪情节特别恶劣，危害后果特别严重，主观恶性深，人身危险性大。案发后，杨光毅在父亲陪同下到公安机关投案并如实供述了强奸致被害人死亡的主要犯罪事实，系自首，但综合考虑杨光毅所犯罪行的性质、情节和对社会的危害程度，结合杨光毅的主观恶性、人身危险性和自首的具体情况，不足以对其从宽处罚。杨光毅的犯罪行为既违国法，又悖天理，更逆人情，严重突破国家法律界限，严重挑战伦理道德底线，严重冲击社会公共安全红线。广西壮族自治区高级人民法院再审刑事判决认定的事实清楚，证据确实、充分，定罪准确，量刑适当，审判程序合法，依法应予核准。\n2021年3月12日，百香果女童母亲领到了钦州市中级人民法院发来的执行案件结案通知书。法院在凶手杨光毅的银行卡内发现了一百多元，将当年百香果女孩遇害时被抢的32元归还，“百香果女童被害案”民事诉讼部分到此结束。\n事件外“百香果女孩”父亲十年前救落水儿童去世，家属申报见义勇为\n随想我觉得”我们”可能需要自私一点。\n因为我们并没有处在一个完美和谐的社会。\n我死也不想要自己的女儿遭遇这样的事情，死也不要。\n引用\n10·4灵山奸杀女童案_百度百科\n\n","categories":["杂谈"]},{"title":"如何使用TCGAbiolinks下载TCGA数据并整理","url":"/2023/03/23/bioinformatics/TCGA/TCGAbiolinks%E5%8C%85%E5%8F%82%E6%95%B0%E8%AF%A6%E8%A7%A3/","content":"引言一般来讲，我们想要使用TCGA数据，大概有三种方法，一是直接从GDC官网或官方下载工具gdc-client下载文件后自行处理，二是使用数据库如UCSC Xena或Firehouse，三是使用TCGAbiolinks R包自动下载并处理。\n从官网下载并不麻烦，但是第一是需要选取非常多的自定义选项，第二是网络环境不好会容易中断，对于初学者倒是一个非常好的了解生物信息学的途径，但遇到批量化处理需求的时候就会难以进行。其后是数据库法，数据库虽然方便，但是并不会随着官网的更新变动，如 GDC Xena Hub 最后一次更新时间是 2019-08-28 ， Firehose 更是停留在了更遥远的 2016_01_28 ……\n那么, 如果我需要批量下载的话, 难道我需要一个个的从网页加入Cart获取mata吗, 我不要……\n幸好，已经有人造了非常好用的轮子，当然可以轻松学习一下用起来啦。\nTCGAbiolinks 包是从TCGA数据库官网接口下载数据的R包。它的一些函数能够轻松地帮我们下载数据和整理数据格式。其实就是broad研究所的firehose命令行工具的R包装！\n需要注意的是，2022年TCGA数据库进行了一次比较大的更新，其中包括了数据格式的变动，因此 TCGAbiolinks 也必须随之更新到最新版。下面，正式开始。\n效果展示可获得文件如下:\n\nTCGA转录组数据原始文件(tsv)及临床原始文件(xml), 均附带清单\n表达矩阵表格(可选&quot;counts&quot;, &quot;fpkm&quot;, &quot;tpm&quot;)\n分组文件\n临床数据, 其中包含生存数据\n\n\n\n\n\n\n过程下载首先是更新最新版的 TCGAbiolinks 包, 我使用的办法是使用Clash获得本地代理后对 R session 进行代理流量转发, 而后直接运行 BiocManager::install(&quot;TCGAbiolinks&quot;) , 选择所有包更新, 很顺利的就更新好了.\nSys.setenv(http_proxy=&quot;http://127.0.0.1:7890&quot;)Sys.setenv(https_proxy=&quot;http://127.0.0.1:7890&quot;)Sys.setenv(all_proxy=&quot;socks5://127.0.0.1:7890&quot;)BiocManager::install(&quot;TCGAbiolinks&quot;)\n\n其中, 127.0.0.1 是本机(local_host)的ip地址, 而7890是Clash的默认端口.\n安装成功后，就可以开始使用了。\n如, 运行 TCGAbiolinks:::getGDCprojects()$project_id 获取各个癌种的项目id, 总计有74个.\nlibrary(TCGAbiolinks)TCGAbiolinks:::getGDCprojects()$project_id# [1] &quot;GENIE-GRCC&quot;                &quot;GENIE-DFCI&quot;                &quot;GENIE-NKI&quot;                 &quot;GENIE-VICC&quot;               # [5] &quot;GENIE-UHN&quot;                 &quot;GENIE-MDA&quot;                 &quot;GENIE-MSK&quot;                 &quot;GENIE-JHU&quot;    #  ... TCGAbiolinks:::getGDCprojects()$project_id %&gt;% length()# [1] 74\n\n如需获取TCGA癌症数据, 可以使用正则表达式获取开头带有 TCGA 的项目.\nprojects &lt;- TCGAbiolinks::getGDCprojects()$project_id ## 获取癌症名字projects &lt;- projects[grepl(&quot;^TCGA&quot;, projects, perl = TRUE)]projects#  [1] &quot;TCGA-CHOL&quot; &quot;TCGA-LIHC&quot; &quot;TCGA-DLBC&quot; &quot;TCGA-BLCA&quot; &quot;TCGA-ACC&quot;  &quot;TCGA-CESC&quot; &quot;TCGA-PCPG&quot; &quot;TCGA-PAAD&quot; &quot;TCGA-MESO&quot; &quot;TCGA-TGCT&quot;# [11] &quot;TCGA-KIRP&quot; &quot;TCGA-UVM&quot;  &quot;TCGA-UCS&quot;  &quot;TCGA-THYM&quot; &quot;TCGA-COAD&quot; &quot;TCGA-ESCA&quot; &quot;TCGA-GBM&quot;  &quot;TCGA-KICH&quot; &quot;TCGA-HNSC&quot; &quot;TCGA-PRAD&quot;# [21] &quot;TCGA-OV&quot;   &quot;TCGA-LUSC&quot; &quot;TCGA-LAML&quot; &quot;TCGA-LGG&quot;  &quot;TCGA-SARC&quot; &quot;TCGA-BRCA&quot; &quot;TCGA-READ&quot; &quot;TCGA-LUAD&quot; &quot;TCGA-STAD&quot; &quot;TCGA-THCA&quot;# [31] &quot;TCGA-KIRC&quot; &quot;TCGA-SKCM&quot; &quot;TCGA-UCEC&quot;projects %&gt;% length# [1] 33\n\nTCGA的33种癌症简写对应全称可在UCSC Xena查到.\n\n查看一个项目内的可下载文件:\nTCGAbiolinks:::getProjectSummary(&quot;TCGA-COAD&quot;)# $file_count# [1] 22585# $data_categories#   file_count case_count               data_category# 1       4007        460       Copy Number Variation# 2       2932        460            Sequencing Reads# 3       6482        434 Simple Nucleotide Variation# 4       1665        457             DNA Methylation# 5        995        461                    Clinical# 6       1978        459     Transcriptome Profiling# 7       2835        461                 Biospecimen# 8        363        360          Proteome Profiling# 9       1328        289        Structural Variation# $case_count# [1] 461# $file_size# [1] 7.004757e+13\n\n下载并提取mRNA的表达矩阵, 其中数据类别 data.category 是 Transcriptome Profiling 代表转录组数据; 数据类型 data.type 是 Gene Expression Quantification , 代表表达谱数据; 定量方式 workflow.type 是 STAR - Counts , 内含了 Counts &#x2F; FPKM 和 FPKM-UQ 三种数据类型.\n# 查询query &lt;- GDCquery(    project = project,    data.category = &quot;Transcriptome Profiling&quot;,    data.type = &quot;Gene Expression Quantification&quot;,    workflow.type = &quot;STAR - Counts&quot;)head(query$results[[1]], n=10) %&gt;% View()# 下载GDCdownload(query, method = &quot;api&quot;, files.per.chunk = 100) # 每次下载100个文件# 整理# GDCprepare(query, save = T, save.filename = paste0(project, &quot;_mRNA.Rdata&quot;))\n\n\n这里出现了一个意外… 我的硬盘提示空间不足了.. 在这个内存动不动64的年代, 我这个硬盘总共200g的可怜人实惨.. 可见 GDCprepare 函数需要强大的内存和硬盘空间, 我的本地电脑是做不到的, 因此继续使用老方案进行数据处理. 目前为止, 通过 TCGAbiolinks 进行数据下载的目的已经圆满达到.\n\n首先保存 MANIFEST 文件以供后续分析:\nshelfEnvironment(paste(imput_dir, &quot;GDCdata&quot;, project, sep = &quot;/&quot;), path = root_dir)write.csv(query$results[[1]], file = paste0(project, &quot;_MANIFEST.csv&quot;))\n\nshelfEnvironment 函数来源于 obgetDEGs 包, 可使用 devtools::install_github(&#39;sandy9707/obgetDEGs&#39;) 命令安装, 函数的作用是将目标文件夹设定为工作目录, 如果该目录不存在便创建. 详情可参考GitHub - sandy9707&#x2F;obgetDEGs.\n 该函数的应用场景是：当需要在R中读取或写入数据时，需要指定存储数据的文件夹路径。但在执行R代码时，可能需要将当前工作目录更改为存储数据的文件夹路径。如果文件夹不存在，需要创建文件夹。这时， shelfEnvironment 函数可以帮助我们检查并创建文件夹，使得数据可以正常读取或写入。\n表达谱数据处理清空环境, 读取MANIFEST信息, 特别是需要样本名和文件夹名.\n# !整理----## 清除当前环境中的所有对象rm(list = ls())## 设置主文件夹路径, 并设置工作目录(root_dir &lt;- sub(&quot;/code.+&quot;, &quot;&quot;, rstudioapi::getSourceEditorContext()$path))source(paste(root_dir, &quot;code&quot;, &quot;prepare.R&quot;, sep = &quot;/&quot;))project &lt;- &quot;TCGA-COAD&quot;shelfEnvironment(paste(imput_dir, &quot;GDCdata&quot;, project, sep = &quot;/&quot;), path = root_dir)json &lt;- read.csv(paste0(project, &quot;_MANIFEST.csv&quot;))# json[, c(&quot;cases&quot;, &quot;file_id&quot;)]case_names &lt;- json[, &quot;cases&quot;]filedir_in_json &lt;- json[, &quot;file_id&quot;]\n\n选择提取部分\n# 提取表达量至一个数据框(以tibble格式),counts值选4,fpkm选8,tpm选7extract_type &lt;- c(&quot;counts&quot;, &quot;fpkm&quot;, &quot;tpm&quot;)[1]extract_num &lt;- switch(extract_type,    &quot;counts&quot; = 4,    &quot;fpkm&quot; = 8,    &quot;tpm&quot; = 7)\n\n开始提取, 原理是进入每一个文件夹并提取某列, 再结合基因类型, 并去重.\n# 开始提取matrix_MMRF_list &lt;- list()shelfEnvironment(paste(imput_dir, &quot;GDCdata&quot;, project,    &quot;/harmonized/Transcriptome_Profiling/Gene_Expression_Quantification&quot;,    sep = &quot;/&quot;), path = root_dir)for (i in 1:length(filedir_in_json)) &#123;    setwd(paste0(&quot;./&quot;, filedir_in_json[i]))    matrix_MMRF_list[[i]] &lt;- read.table(        file = list.files(pattern = &quot;.tsv&quot;),        header = F, fill = TRUE    )[, extract_num]    setwd(&quot;../&quot;)&#125;setwd(paste0(&quot;./&quot;, filedir_in_json[i]))probematrix &lt;- read.table(list.files(pattern = &quot;.tsv&quot;),    header = F, fill = TRUE)[, 2:3]setwd(&quot;../&quot;)matrix_MMRF &lt;- do.call(cbind, matrix_MMRF_list)matrix_MMRF &lt;- cbind(probematrix, matrix_MMRF)tibble_MMRF &lt;- tibble::as_tibble(matrix_MMRF)colnames(tibble_MMRF) &lt;- c(&quot;gene_name&quot;, &quot;gene_type&quot;, str_sub(case_names, 1, 16))#duplicated(colnames(tibble_MMRF), fromLast = TRUE) %&gt;% table()tibble_MMRF &lt;- tibble_MMRF[, !duplicated(colnames(tibble_MMRF), fromLast = TRUE)]duplicated(colnames(tibble_MMRF), fromLast = TRUE) %&gt;% table()\n\n提取蛋白编码基因并将基因名保留转换行名.\n# 提取蛋白编码基因pcg &lt;- c(    &quot;protein_coding&quot;, &quot;IG_V_gene&quot;, &quot;IG_D_gene&quot;, &quot;IG_J_gene&quot;,    &quot;IG_C_gene&quot;, &quot;TR_V_gene&quot;, &quot;TR_D_gene&quot;, &quot;TR_J_gene&quot;, &quot;TR_C_gene&quot;)# 创建一个tibble_MMRF对象，使用dplyr::filter()方法筛选出gene_type包含于pcg的所有行mrna_exprset &lt;- tibble_MMRF %&gt;%    dplyr::filter(gene_type %in% pcg) %&gt;%    # 使用dplyr::select()方法去掉gene_type列    dplyr::select(-gene_type) %&gt;%    # 使用dplyr::distinct()方法去除重复的行，保留第一次出现的行    dplyr::distinct(gene_name, .keep_all = TRUE) %&gt;%    # 使用tibble::column_to_rownames()方法将gene_name列转换为行名    tibble::column_to_rownames(&quot;gene_name&quot;)\n\n通过TCGA样本命名规则筛选需求样本并将对照组前置.\n# 查看去掉01A和11A的样本个数, 通过数量可以看出效果一致mrna_exprset %&gt;%    select(-matches(&quot;[^(01)]A$|[^(11)]A$&quot;)) %&gt;%    ncol()mrna_exprset %&gt;%    select(matches(&quot;[01]1[A]$&quot;)) %&gt;%    ncol()# 筛选, 只要01A和11A的样本# 重新排序,将癌旁排在前面便于下一步筛选,0-9为癌数据,排在后面mrna_exprset &lt;- mrna_exprset %&gt;%    select(matches(&quot;[01]1A$&quot;)) %&gt;%    select(-matches(&quot;.-0[1-9][A]$&quot;), everything())ncol(mrna_exprset)\n\n写出表达矩阵, 特征列表和分组列表.\n# 写出表达矩阵_extract_typeshelfEnvironment(paste(imput_dir, &quot;GDCdata&quot;, project, sep = &quot;/&quot;),    path = root_dir)write.csv(mrna_exprset, paste0(&quot;Eset_&quot;, extract_type, &quot;_ProCoding.csv&quot;), row.names = T)# 写出特征列表, 也就是基因名write.table(rownames(mrna_exprset), &quot;feature_list.csv&quot;,    row.names = FALSE, quote = FALSE, col.names = FALSE)# 写出分组列表, 也就是组别samples &lt;- colnames(mrna_exprset)group_definition_matrix &lt;- data.frame(    samples,    group = ifelse(grepl(&quot;11A$&quot;, samples), &quot;control&quot;, &quot;test&quot;))write.csv(group_definition_matrix,    file = &quot;group_definition_matrix.csv&quot;, row.names = F)\n\nsapply(projects, function(project)&#123;    query &lt;- GDCquery(project = project,                    data.category = &quot;Clinical&quot;,                     file.type = &quot;xml&quot;)  GDCdownload(query)  clinical &lt;- GDCprepare_clinic(query, clinical.info = &quot;patient&quot;)  saveRDS(clinical,file = paste0(project,&quot;_clinical.rds&quot;))&#125;)\n\n临床数据下载及处理# 临床数据projectsapply(projects, function(project) &#123;    query &lt;- GDCquery(        project = project,        data.category = &quot;Clinical&quot;,        file.type = &quot;xml&quot;    )    GDCdownload(query)    clinical &lt;- GDCprepare_clinic(query, clinical.info = &quot;patient&quot;)    # saveRDS(clinical, file = paste0(project, &quot;_clinical.rds&quot;))&#125;)write.csv(clinical, paste0(&quot;Phenodata.csv&quot;), row.names = F)col_survivaldata &lt;- setNames(    data.frame(clinical[, c(&quot;bcr_patient_barcode&quot;, &quot;vital_status&quot;, &quot;days_to_death&quot;)]),    c(&quot;patient&quot;, &quot;status&quot;, &quot;time&quot;))write.csv(col_survivaldata, paste(&quot;Survivalata.csv&quot;, sep = &quot;/&quot;), row.names = F)\n\n总结如想获得本文的全套代码以及工作环境, 只需要在公众号私信发送 TCGA数据下载整理 就可以获得.\n引用\nGDC官网\n官方下载工具gdc-client\nUCSC Xena\nFirehouse\nTCGAbiolinks\nTCGA数据下载—TCGAbiolinks包参数详解 - 腾讯云开发者社区-腾讯云\n新版TCGAbiolinks包学习：批量下载数据新版TCGA数据 - mdnice 墨滴\nTCGA &#x2F; 癌症简称 &#x2F; 缩写 &#x2F; TCGA癌症中英文对照\nGitHub - sandy9707&#x2F;obgetDEGs\nTCGA样本命名规则\n\n","categories":["生物信息学","TCGA"],"tags":["R 语言","TCGA"]},{"title":"TCGA-miRNA数据整理","url":"/2023/05/09/bioinformatics/TCGA/TCGA-miRNA%E6%95%B0%E6%8D%AE%E6%95%B4%E7%90%86/","content":"引言之前介绍过 如何使用TCGAbiolinks下载TCGA数据并整理 , 那么如果手动整理又该如何呢?\n下面以 miRNA 数据整理为例示范.\n效果展示\n\n过程输入文件\n随便下载一些数据, 下载格式选择 Metadata 和 Cart .\n\n下载得到一个 Metadata 的 json 文件和一个包含全部数据的压缩包, 解压可得到 MANIFEST.txt 和一堆文件夹.\n观察可得 Metadata.json 包含了所需读入文件名和样本的 TCGA Submitter Id .\n\n同样对 MANIFEST.txt 观察可得其中包含了所需读入文件名和文件所在的文件夹.\n\n因此就可以使用 R 对已下载数据做简单处理.\nR代码整理配置工作环境# ! 准备----## 清除当前环境中的所有对象rm(list = ls())## 设置主文件夹路径, 并设置工作目录(root_dir &lt;- sub(&quot;/main.*&quot;, &quot;&quot;, rstudioapi::getSourceEditorContext()$path))# root_dir &lt;- &quot;/dev/sda1/home/tenney/RStudio/CFJ&quot;shelf_folder &lt;- function(folder_name, parent_folder = &quot;.&quot;) &#123;    target_folder &lt;- file.path(parent_folder, folder_name)    if (!file.exists(target_folder)) &#123;        dir.create(target_folder, recursive = TRUE)    &#125;    setwd(target_folder)    return(target_folder)&#125;data_folder &lt;- shelf_folder(&quot;data&quot;, root_dir)results_folder &lt;- shelf_folder(&quot;results&quot;, root_dir)# !main----library(librarian)shelf(dplyr, stringr, quiet = TRUE)shelf_folder(&quot;data&quot;, root_dir)\n\n此代码可以在脚本所在目录创建 data 和 results 文件夹，并提供了一个快速创建并设定工作目录的 function。\n\n将所有的TCGA下载文件及解压后的文件夹放入 data 中。\n处理json文件之后使用代码对json文件做处理得到所需读入文件名和样本 TCGA Submitter Id 之间的对应关系, 代码来源于 TCGA数据库：miRNA数据下载与整理(2) | 夜风博客 .\n\n### ---1.处理json文件----------------------# BiocManager::install(&quot;miRBaseVersions.db&quot;)shelf(jsonlite, tidyr) # , miRBaseVersions.db)list.files(data_folder)json_file &lt;- read_json(paste0(data_folder, &quot;/metadata.cart.2023-05-09.json&quot;))length(json_file)filesNameToBarcode &lt;- data.frame(filesName = c(), TCGA_Barcode = c())for (i in 1:length(json_file)) &#123;    TCGA_Barcode &lt;- json_file[[i]][[&quot;associated_entities&quot;]][[1]][[&quot;entity_submitter_id&quot;]]    file_name &lt;- json_file[[i]][[&quot;file_name&quot;]]    filesNameToBarcode &lt;- rbind(filesNameToBarcode, data.frame(filesName = file_name, TCGA_Barcode = TCGA_Barcode))&#125;(rownames(filesNameToBarcode) &lt;- filesNameToBarcode[, 1])\n\n处理MANIFEST文件处理MANIFEST文件得到所需读入文件名和文件所在文件夹的对应关系.\n\n### ---2.处理MANIFEST文件----------------------gdc_folder &lt;- shelf_folder(&quot;gdc_download_20230509_074245.126557&quot;, data_folder)MANIFEST &lt;- read.table(paste0(gdc_folder, &quot;/manifest.txt&quot;), sep = &quot;\\t&quot;, header = TRUE)file_paths &lt;- MANIFEST[, &quot;filename&quot;]file_names &lt;- sub(&quot;.*/&quot;, &quot;&quot;, file_paths)\n\n依次读入文件并合并依次读入文件并合并，原理是创建一个空列表，再利用for循环依次从文件中提取值并填充。之后使用do。call命令对列表内全部项进行cbind处理。需要注意的是，cbind函数要求合并矩阵行名保持一致。\n其中，合并数据为counts或RPM由read.table后的提取列1或2决定。\n\n### ---3.依次读入文件并合并----------------------i &lt;- 1matrix_list &lt;- list()for (i in 1:length(file_paths)) &#123;    file_path &lt;- file_paths[i]    matrix_list[[i]] &lt;- read.table(paste0(gdc_folder, &quot;/&quot;, file_path),        sep = &quot;\\t&quot;, header = TRUE, row.names = 1    )[, 2, drop = FALSE] # 1是counts, 2是RPM&#125;matrix &lt;- do.call(cbind, matrix_list)colnames(matrix) &lt;- filesNameToBarcode$TCGA_Barcode[match(file_names, filesNameToBarcode$filesName)]head(matrix)# ! 导出数据----write.csv(matrix, file = paste0(results_folder, &quot;/matrix.csv&quot;))\n\n根据反馈修改小伙伴反馈表示 miRNA 数据并不一定存在一致的行名, 因此更换思路为按行名分组求和后合并矩阵, 缺失值以 Na 填充.\n\n核心代码为(读入过程和合并过程):\n读入过程使用了group_by函数进行分组，使用了summarise_all(sum)进行组内相加。\nsummarized_data &lt;- data %&gt;%        group_by(miRNA_region) %&gt;%        summarise_all(sum)\n\n合并过程使用了for循环对第二列之后的列依次以left_join函数组合到第一列上.\nmatrix &lt;- matrix_list[[1]]for (i in 2:length(matrix_list)) &#123;    matrix &lt;- left_join(matrix, matrix_list[[i]], by = &quot;miRNA_region&quot;)&#125;\n\n以下为完整代码(可改”reads_per_million_miRNA_mapped”为”read_count”):\n### ---3.依次读入文件并合并----------------------i &lt;- 1matrix_list &lt;- list()for (i in 1:length(file_paths)) &#123;    file_path &lt;- file_paths[i]    data &lt;- read.table(paste0(gdc_folder, &quot;/&quot;, file_path),        sep = &quot;\\t&quot;, header = TRUE    )[, c(&quot;reads_per_million_miRNA_mapped&quot;, &quot;miRNA_region&quot;), drop = FALSE] # 可改&quot;reads_per_million_miRNA_mapped&quot;为&quot;read_count&quot;    # 假设你的数据框名为 data    # 对 miRNA_region 列分组，将其他列相加    summarized_data &lt;- data %&gt;%        group_by(miRNA_region) %&gt;%        summarise_all(sum)    matrix_list[[i]] &lt;- summarized_data    # # 将 miRNA_region 列提取出来并将其设置为行名    # final_data &lt;- summarized_data %&gt;%    #     select(miRNA_region) %&gt;%    #     column_to_rownames(var = &quot;miRNA_region&quot;)    # # 将其他列添加到最终数据框中    # other_cols &lt;- setdiff(colnames(summarized_data), &quot;miRNA_region&quot;)    # matrix_list[[i]] &lt;- cbind(final_data, summarized_data[other_cols])&#125;matrix &lt;- matrix_list[[1]]for (i in 2:length(matrix_list)) &#123;    matrix &lt;- left_join(matrix, matrix_list[[i]], by = &quot;miRNA_region&quot;)&#125;nrow(matrix)head(matrix)# ! 导出数据----length(colnames(matrix))colnames(matrix)[2:length(colnames(matrix))] &lt;- filesNameToBarcode$TCGA_Barcode[match(file_names, filesNameToBarcode$filesName)]head(matrix)write.csv(matrix, file = paste0(results_folder, &quot;/matrix.csv&quot;))\n\n结论\nmiRNA的前体可能对应多个成熟的miRNA，比如hsa-let-7a-1，有两个对应的成熟体，MIMAT0000062(hsa-let-7a-5p)和MIMAT0004481(hsa-let-7a-3p)。这里的值是对所有成熟体miRNA求和的结果。\n\n如 TCGA数据库：miRNA数据下载与整理(2) | 夜风博客 文中所说, miRNA的前体可能对应多个成熟的miRNA, 因此还需要使用miRBaseVersions.db包对miRNA_region进行转换, 过程在原文非常清晰, 在此不在赘述.\n事实上这种提取方法不局限于miRNA数据, 同样可对普通的转录组数据使用, 感兴趣的朋友可以自行摸索.\n本文的完整代码可在公众号回复关键词获得(请复制粘贴):\nTCGA-miRNA数据整理\n引用\nTCGA数据库：miRNA数据下载与整理(2) | 夜风博客\nCodeium\n\n","categories":["生物信息学","TCGA"],"tags":["R 语言","TCGA"]},{"title":"TCGA联合GTEX分析流程","url":"/2023/10/09/bioinformatics/TCGA/TCGA%E8%81%94%E5%90%88GTEX%E5%88%86%E6%9E%90%E6%B5%81%E7%A8%8B/","content":"引言高通量RNA测序（RNA-Seq）已成为转录组分析的强大方法（1），广泛用于了解基因功能和生物模式，找到候选药物靶点，并识别疾病分类和诊断的生物标志物（2）。近年来，癌症基因组图谱（TCGA）（3）和基因型组织表达（GTEx）（4,5）项目为数万个癌症和非癌症样本提供了RNA-Seq数据，为包括癌症生物学在内的许多相关领域提供了前所未有的机会。到目前为止，TCGA已经为33种癌症类型的9736个肿瘤样本提供了RNA-Seq数据，此外还有726个相邻正常组织的数据。肿瘤和正常数据之间的不平衡可能导致各种差异分析的效率低下。幸运的是，GTEx项目为8000多个正常样本提供了RNA-Seq数据，尽管这些样本来自不相关的捐赠者。由于数据处理管道和基因模型等方面的许多差异，此类数据无法直接组合进行综合分析。为了使来自不同来源的数据更加兼容，UCSC Xena项目（http://xena.ucsc.edu/）基于标准管道重新计算了所有表达式原始数据，以尽量减少与不同来源的差异，从而允许形成最新的最全面的表达式数据。\n效果展示过程获取UCSC数据数据可以直接从https://xenabrowser.net/datapages/网站获得。\n获得合并后数据或者分别获得TCGA和GTEx数据均可，为确保可以比较，本文选择直接下载合并数据TCGA TARGET GTEx (13 datasets). 网页提供了gene expression RNAseq的RSEM expected_count (DESeq2 standardized), 可以直接用于差异分析。\n插曲gzip -d TcgaTargetGtex_rsem_gene_tpm.gzgzip -d TCGA-GTEx-TARGET-gene-exp-counts.deseq2-normalized.log2.gz\n\n很奇怪的是，无论使用readr的read.delim函数，还是data.table的fread函数，都无法读取成功。\n而read.table显示信息是：\nr$&gt; data &lt;- read.table(file.path(data_folder, &quot;TCGA-GTEx-TARGET-gene-exp-counts.deseq2-normalized.l    og2.gz&quot;), sep = &quot;\\t&quot;)Error in scan(file = file, what = what, sep = sep, quote = quote, dec = dec,  :   line 11069 did not have 19040 elements\n\ndata &lt;- readr::read.delim(file.path(data_folder, &quot;TCGA-GTEx-TARGET-gene-exp-counts.deseq2-normalized.log2.gz&quot;), header = TRUE, as.is = TRUE)data &lt;- data.table::fread(file.path(data_folder, &quot;TCGA-GTEx-TARGET-gene-exp-counts.deseq2-normalized.log2.gz&quot;), data.table = FALSE)\n\nBrain组织数量与GEPIA不一致的处理方法在经过UCSC处理GTEx中，Brain分为13个组织1148个样本，但GEPIA2将他们分成了由207+945&#x3D;1152两组，那么哪些是可以作为LGG或GBM的对照的呢？\n从TCGA中下载LGG的临床数据，可得都来源于额叶、顶叶、颞叶和枕叶四个脑叶，也就是说都来源于大脑 (Cerebrum), 因此我们要找的也是Cerebrum.\nGTEx Brain的13个组织：\nBrain - Amygdala脑杏仁核（Amygdala）69 正常组织Brain - Anterior Cingulate Cortex (Ba24)大脑前扣带皮质（Ba24）83 正常组织Brain - Caudate (Basal Ganglia)脑尾（基底神经节）（Caudate）108 正常组织Brain - Cerebellar Hemisphere小脑半球（Cerebellar Hemisphere）97 正常组织Brain - Cerebellum小脑（Cerebellum）117 正常组织Brain - Cortex大脑皮质（Cortex）105 正常组织Brain - Frontal Cortex (Ba9)大脑额叶皮质（Ba9）101 正常组织Brain - Hippocampus大脑海马（Hippocampus）84 正常组织Brain - Hypothalamus大脑下丘脑（Hypothalamus）82 正常组织Brain - Nucleus Accumbens (Basal Ganglia)脑积聚核（基底神经节）（Nucleus Accumbens）104 正常组织Brain - Putamen (Basal Ganglia)脑壳Putamen（基底神经节）81 正常组织Brain - Spinal Cord (Cervical C-1)脊髓（颈C-1）（Spinal Cord）60 正常组织Brain - Substantia Nigra大脑黑质（Substantia Nigra）57 正常组织\n\n首先，小脑 (Cerebellum) 和小脑半球 (Cerebellar Hemisphere) 显然属于小脑半球，所以214例属于945组。\n而后，根据 基底核 - 维基百科，自由的百科全书 的说明，基底核（basal ganglia）包括尾&#x2F;壳&#x2F;黑质，共393例，因此属于945组。\n最后，海马，下丘脑，脊髓，杏仁核，前扣带都属于单独的结构，所以推测只有皮质（Cortex）和额叶皮质（Ba9）属于大脑 (Cerebrum), 样本量为206, 在误差范围内，可以被认为是LGG或GBM的对照组。\n基底核（basal ganglia）:\n\n前侧\n纹状体（Striatum）包括\n尾状核（Caudate nucleus）\n壳（Putamen）\n伏隔核（Nucleus accumbens）\n外苍白球（External segment of globus pallidus，GPe）\n内苍白球（Internal segment of globus pallidus，GPi）\n\n\n\n\n后侧，以下这些结构在大脑中更靠下，靠后。\n丘脑下核（Subthalamic nucleus, STN）\n黑质（Substantia nigra, SN），根据内部结构可分为\n黑质致密部（Substantia nigra pars compacta，SNc）\n黑质网状部（Substantia nigra pars reticulata，SNr）\n黑质侧部（Substantia nigra pars lateralis，SNl）\n\n\n\n\n\n结论引用\nGEPIA：用于癌症和正常基因表达分析和交互式分析的网络服务器\n3大数据库超2万RNA-seq数据重新统一处理——关于TCGA-GTEx是否需要标准化 – 王进的个人网站\nGTEx联合TCGA数据库差异分析（更新） – 王进的个人网站\nTCGA和GTEx的数据联合分析实战 - 简书\nGitHub - xjsun1221&#x2F;RSEM_with_limma_edgeR_Deseq2\nGEPIA 2 - Dataset Sources\n\n","categories":["生物信息学","TCGA"]},{"title":"GEOparse - 利用Python处理下载处理GEO数据","url":"/2023/05/23/bioinformatics/GEO/GEOparse%20-%20%E5%88%A9%E7%94%A8Python%E5%A4%84%E7%90%86%E4%B8%8B%E8%BD%BD%E5%A4%84%E7%90%86GEO%E6%95%B0%E6%8D%AE/","content":"引言效果展示过程结论引用\n\n\n","categories":["生物信息学","GEO"]},{"title":"R 中柱状图的画法","url":"/2023/10/11/bioinformatics/R/R%20%E4%B8%AD%E6%9F%B1%E7%8A%B6%E5%9B%BE%E7%9A%84%E7%94%BB%E6%B3%95/","content":"引言效果展示过程结论引用\nR 数据可视化 —— ggplot 柱状图&#x2F;条形图 - 知乎\nBasic histogram with ggplot2 – the R Graph Gallery\n跟顶刊学配色！SCI论文插图经典配色实例第1期 - 知乎\nR包分享|如何一秒获取Science、Nature等高分期刊配色？ - 知乎\nggplot 修改坐标轴名称_ggplot2修改坐标轴名称_基督徒Isaac的博客-CSDN博客\n\n","categories":["生物信息学","R"]},{"title":"rserver 中无法使用 conda 的解决办法","url":"/2024/11/02/bioinformatics/R/rserver%E4%B8%AD%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8conda/","content":"引言rserver 总会有一些奇怪的报错，其中有一个是无论是使用 terminal 还是 reticulate 中试图使用建好的 conda 环境都会报错。\n事实上应该不只是 conda 会出错，而是包含 pip 在内的所有包管理工具都会出错，这是因为这个问题的原因是 rstudioserver 自己使用了一套环境变量而非系统环境变量。\n效果展示\n\n结论诚意推荐少用 rserver。\n来试试 vscode 和 cursor 吧，真的好用!!!\n","categories":["生物信息学","R"],"tags":["rserver","conda"]},{"title":"mac 实现 R 版本的自动切换","url":"/2022/11/17/bioinformatics/R/mac%E5%AE%9E%E7%8E%B0R%E7%89%88%E6%9C%AC%E7%9A%84%E8%87%AA%E5%8A%A8%E5%88%87%E6%8D%A2/","content":"多版本安装问题在使用 RSwitch 的过程中，mac 只会保留最后一次安装的框架及运行程序\n原因\nYou can also use the .pkg versions if you prefer a clicky-installer wizard, but these installers will remove any previous versions of the framework (kinda defeating the purpose)\n\n解决方案 使 pkg 安装不会重置程序框架\nsudo pkgutil --forget org.R-project.R.fw.pkg\n然后直接安装需要版本的 pkg 文件安装即可。每次安装均需要使用一次重置命令。\n版本切换使用 RSwitch 程序进行切换\n创建软连接以在 terminal 中使用 rswitchln -s /Applications/RSwitch.app/Contents/Resources/rswitch-cmd /usr/local/bin/rswitch\n仓库链接\nmac 安装实验版二进制文件的文档说明：https://mac.r-project.org\nRSwitch 下载界面：https://rud.is/rswitch/\nR for macOS pkg 下载地址：https://cran.r-project.org/bin/macosx/base/\nR for macOS tar.gz 下载地址：https://cran.r-project.org/src/base/R-4/\n\n参考链接\n如何在 mac 上安装多个版本的 R？\n199-想在 Mac 上安装多个 R 版本？Easy！\n\n","categories":["生物信息学","R"],"tags":["R","MacOS"]},{"title":"R 在 Linux 等操作系统上的特定版本安装","url":"/2023/12/27/bioinformatics/R/R%20%E5%9C%A8%20Linux%20%E7%AD%89%E6%93%8D%E4%BD%9C%E7%B3%BB%E7%BB%9F%E4%B8%8A%E7%9A%84%E7%89%B9%E5%AE%9A%E7%89%88%E6%9C%AC%E5%AE%89%E8%A3%85/","content":"引言有些时候会存在需要安装特定版本 R 软件的需求，比如为了满足特定软件包的安装使用要求或减少不同平台迁移成本。但是，不同于 Windows 平台拥有便捷的 R 版本切换功能，MacOS 和 Linux 平台都存在着不同程度的安装和切换困难。因此，本文以 Ubuntu 为例分享一下 R 在 Linux 等操作系统上的特定版本安装和 rstudio-server 中 R 版本的切换。\n过程LinuxUbuntu官网提供的安装方法实际只能安装最新版，无法指定安装版本[1]。而官方提供的旧版本安装方法[2]直接旧到 3.4 和 3.6 去了…\n因此，使用 Posit 提供的 deb 安装方法[5,6]。\nPosit# Install required dependenciessudo apt-get updatesudo apt-get install gdebi-core# Specify R version, download and install Rexport R_VERSION=4.2.3curl -O https://cdn.rstudio.com/r/ubuntu-2004/pkgs/r-$&#123;R_VERSION&#125;_1_amd64.debsudo gdebi r-$&#123;R_VERSION&#125;_1_amd64.deb/opt/R/$&#123;R_VERSION&#125;/bin/R --version# Create a symlink to Rsudo ln -s /opt/R/$&#123;R_VERSION&#125;/bin/R /usr/local/bin/Rsudo ln -s /opt/R/$&#123;R_VERSION&#125;/bin/Rscript /usr/local/bin/Rscript# config rstudio-servervim /etc/rstudio/rserver.conf# rsession-which-r=/usr/local/bin/Rsudo rstudio-server restart\n\n值得注意的是，很多教程没有分清rserver.conf和rsession.conf的区别，如果写入了错误的配置文件会导致 rstudio-server 无法启动。事实上 rserver.conf 配置文件控制 Workbench 的 rserver 进程的行为，用来调整身份认证、HTTP 和授权选项等设置[8]。而 rsession.conf 配置文件被用来调整各种 RStudio Pro Session 参数[9]，简单的说，高级版才有用。\n手动编译也可以使用手动编译的方法安装[7]。\nsudo sed -i.bak &quot;/^#.*deb-src.*universe$/s/^# //g&quot; /etc/apt/sources.listsudo apt updatesudo apt build-dep r-baseexport R_VERSION=4.2.3curl -O https://cran.rstudio.com/src/base/R-4/R-$&#123;R_VERSION&#125;.tar.gztar -xzvf R-$&#123;R_VERSION&#125;.tar.gzcd R-$&#123;R_VERSION&#125;./configure \\    --prefix=/opt/R/$&#123;R_VERSION&#125; \\    --enable-R-shlib \\    --enable-memory-profiling \\    --with-blas \\    --with-lapackmakesudo make install\n\ncondawget https://repo.continuum.io/miniconda/Miniconda3-latest-$(uname -s)-$(uname -m).sh## exemple: wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.shbash ./Miniconda3-latest-$(uname -s)-$(uname -m).sh## exemple: bash ./Miniconda3-latest-Linux-x86_64.shsource ~/.bashrc## Conda-forgeconda config --add channels conda-forgeconda config --set channel_priority strict## runconda create -n R4.2conda env listconda activate R4.2conda install r-base=4.2.3conda install r-languageserver radian## Rwhich R# /root/miniconda3/envs/R4.2/bin/Rll /root/miniconda3/envs/R4.2/bin/R# 注意, 在任何情况下都不应该由用户手动写入`/usr/lib`文件夹# ln -s /root/miniconda3/envs/R4.2/lib/R/bin/R /usr/lib/R# rm -rf /usr/lib/R\n\n注意，在任何情况下都不应该由用户手动写入/usr/lib文件夹，因此千万不要用创建软连接的形式进行软件的使用。如果已经创建了并引起了 dpkg 和 apt 的报错，就删除创建的软连接。\n题外官方最新版安装# update indicessudo apt update -qq# install two helper packages we needsudo apt install --no-install-recommends software-properties-common dirmngr# add the signing key (by Michael Rutter) for these repos# To verify key, run gpg --show-keys /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc# Fingerprint: E298A3A825C0D65DFD57CBB651716619E084DAB9wget -qO- https://cloud.r-project.org/bin/linux/ubuntu/marutter_pubkey.asc | sudo tee -a /etc/apt/trusted.gpg.d/cran_ubuntu_key.asc# add the R 4.0 repo from CRAN -- adjust &#x27;focal&#x27; to &#x27;groovy&#x27; or &#x27;bionic&#x27; as neededsudo add-apt-repository &quot;deb https://cloud.r-project.org/bin/linux/ubuntu $(lsb_release -cs)-cran40/&quot;sudo apt install --no-install-recommends r-base\n\nWin各种版本的 R 都可以直接下载。\nPrevious releases of R for Windows\nMacOS可以使用 RSwitch 等软件进行设置。\n引用\nThe Comprehensive R Archive Network\nUbuntu Packages For R - Older Releases\n安装低版本的 R 语言、和自行下载安装各个版本的 R 语言包、以及多环境运行 R_r 官网怎么找旧版本的 r-CSDN 博客\n20.04 - How to install specific R version in ubuntu - Ask Ubuntu\nPosit - Install R - Posit Documentation\nRstudio-server 更改 R 版本 - lypbendlf - 博客园\nPosit - Install R from Source - Posit Documentation\nAdministration Guide - rserver.conf\nAdministration Guide - rsession.conf\n\n","categories":["生物信息学","R"],"tags":["R","Linux"]},{"title":"R 出现不兼容的时候使用 canda 运行","url":"/2024/09/07/bioinformatics/R/R%E5%87%BA%E7%8E%B0%E4%B8%8D%E5%85%BC%E5%AE%B9%E7%9A%84%E6%97%B6%E5%80%99%E4%BD%BF%E7%94%A8canda%E8%BF%90%E8%A1%8C/","content":"引言R 这个混乱的包管理系统经常会出现一下包冲突或者版本冲突所导致的问题，与其花费时间在”解决问题”方面，不如简单些，直接使用万能的 conda 使用纯净环境用来跑代码。\n效果展示过程conda create --name r44conda install mambamamba install r-base r-biocmanager r-dplyr r-librarian\n\n结论引用\n\n\n","categories":["生物信息学","R"]},{"title":"服务器 rstudio-server 问题修复记录","url":"/2023/04/03/bioinformatics/R/%E6%9C%8D%E5%8A%A1%E5%99%A8rstudio-server%E9%97%AE%E9%A2%98%E4%BF%AE%E5%A4%8D%E8%AE%B0%E5%BD%95/","content":"引言R 版本更新过程sudo rstudio-server verify-installation #查看安装是否正常sudo rstudio-server start               #启动RStudio-serversudo rstudio-server status              #查看RStudio-serversudo rstudio-server stop                #关闭RStudio-serversudo rstudio-server restart             #重启RStudio-server\n\n失败记录修改 rserver.confsudo vim /etc/rstudio/rserver.conf# rsession-which-r=/home/tenney/miniconda3/envs/R4.2/bin/Rsudo rstudio-server restartsudo rstudio-server status\n\n修改vim rsession.conf# rsession-which-r=/home/tenney/miniconda3/envs/R4.2/bin/Rsudo rstudio-server restartsudo rstudio-server status\n\n软链接$ (/home/tenney/miniconda3) root@g01:/etc/rstudio$ which R/bin/R$ (/home/tenney/miniconda3) root@g01:/etc/rstudio$ R --versionR version 4.1.2 (2021-11-01) -- &quot;Bird Hippie&quot;$ (/home/tenney/miniconda3) root@g01:/etc/rstudio$ ls -al /bin/R-rwxr-xr-x. 1 root root 8954 9月  25 2018 /bin/R$ mv bin/R bin/R.bak\n\n(R4.2) tenney@g01:~/miniconda3/envs/R4.2/bin$ which R~/miniconda3/envs/R4.2/bin/R(R4.2) 127 tenney@g01:~/miniconda3/envs/R4.2/bin$ pwd/home/tenney/miniconda3/envs/R4.2/bin\n\n所以路径为/home/tenney/miniconda3/envs/R4.2/bin/R\n$defaultPackages[1] &quot;datasets&quot;  &quot;utils&quot;     &quot;grDevices&quot; &quot;graphics&quot;  &quot;stats&quot;     &quot;methods&quot;&gt; loadedNamespaces()[1] &quot;compiler&quot;  &quot;tools&quot;     &quot;utils&quot;     &quot;grDevices&quot; &quot;datasets&quot;  &quot;base&quot;\n\n无法重启修复\nrserver 进程无法正确清理自己。修复它的方法是查找正在运行的 rserver 进程.1\n\nsudo rstudio-server verify-installation# 找到rserver进程并杀死ps -ef | grep rserverkill -9 &lt;PID OF PROCESS&gt;\n\nRtmp 无法创建报错：\nFatal error: cannot create &#39;R_TempDir&#39;\n引用\nTroubleshoot RStudio Server Installation - verify-installation incorrectly reports server is running - R Admins - Posit Community\n\n","categories":["生物信息学","R"],"tags":["R","rstudio-server","linux"]},{"title":"Tailscale 的使用","url":"/2023/11/03/Tech/Intranet%20penetration/Tailscale/","content":"引言引用\n比 zerotier 更好的内网穿透方案 – Tailscale\nTailscale\n\n","categories":["Tech","Intranet penetration"],"tags":["Intranet penetration","内网穿透"]},{"title":"ddnsto 内网穿透的 nas 使用","url":"/2023/09/30/Tech/Intranet%20penetration/ddnsto%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%E7%9A%84nas%E4%BD%BF%E7%94%A8/","content":"安装官方示例：\ndocker run -d \\    --name=ddnsto \\    --restart always \\    --network host \\    -e TOKEN=&lt;填入你的token&gt; \\    -e DEVICE_IDX=&lt;默认0，如果设备ID重复则为1-100之间&gt; \\    -v /etc/localtime:/etc/localtime:ro \\    -v /your/config-path/ddnsto-config:/ddnsto-config \\    -e PUID=&lt;uid for user&gt; \\    -e PGID=&lt;gid for user&gt; \\    linkease/ddnstodocker run -d \\    --name=ddnsto \\    --restart always \\    --network host \\    -e TOKEN=abcdefg-8888-8888-1111-abcdefghijk \\    -e DEVICE_IDX=0 \\    -v /etc/localtime:/etc/localtime:ro \\    -v /mnt/sda1/ddnsto-config:/ddnsto-config \\        -e PUID=0 \\    -e PGID=0 \\    linkease/ddnsto\n\n实际上，我只设置了/ddnsto-config的文件夹映射，忽略了/etc/localtime, 不影响使用。\n环境设置TZ=Asia/ShanghaiPUID=0PGID=0DEVICE_IDX=0TOKEN=****\n\n结论挺好用的，很快，十分钟绝对够了。\n同一台设备好像重装也是同一个 id, 反正确实挺方便的，在没有 zerotier 的时候这个就相当可以了。唯一不满意的大概就是和微信扫码深度绑定…\n引用\nDocker DDNSTO 远程控制 Docker\n\n","categories":["Tech","Intranet penetration"],"tags":["nas"]},{"title":"easyconnet 的 docker 使用","url":"/2024/01/27/Tech/Intranet%20penetration/easyconnet%E7%9A%84docker%E4%BD%BF%E7%94%A8/","content":"easyconnet 的 docker 使用cli（amd64 架构）docker run --rm --device /dev/net/tun --cap-add NET_ADMIN -ti -p 127.0.0.1:1080:1080 -p 127.0.0.1:8888:8888 -e EC_VER=7.6.3 -e CLI_OPTS=&quot;-d vpnaddress -u username -p password&quot; hagb/docker-easyconnect:cli\n\n","categories":["Tech","Intranet penetration"],"tags":["nas"]},{"title":"nas 下的 zerotier 使用","url":"/2023/09/30/Tech/Intranet%20penetration/nas%E4%B8%8B%E7%9A%84zerotier%E4%BD%BF%E7%94%A8/","content":"过程绿联官方的 ssh(远程调试) 功能。\n安装提权对/dev/net/tun提权\nchmod 0666 /dev/net/tun\n\n开机自启以下方法无效\ncrontab -e\n\n@reboot chmod 0666 /dev/net/tun\n\n命令行 docker查看真实地址：\ndocker psdocker inspect 08aa0a8a128a | grep Mounts -A 20\n\n在 Source 内得到 docker 目录真实地址\n/mnt/media_rw/93356ba9-99d4-4309-8a73-51608be5d7d1/.ugreen_nas/179563/docker/\n\ndocker create \\ --restart unless-stopped \\ --device /dev/net/tun \\ --net host \\ --cap-add NET_ADMIN \\ --cap-add SYS_ADMIN \\ -v /mnt/media_rw/93356ba9-99d4-4309-8a73-51608be5d7d1/.ugreen_nas/179563/docker_config/zerotier-aws-planet/zerotier-one:/var/lib/zerotier-one \\ --name zerotier-one \\ zerotier/zerotier\n\n如果用docker start zerotier-one开启软件可以直接在当前 session 输入一下命令，如果没有也可以使用docker exec -it zerotier-one bash进入容器，比较推荐的是用在线的服务直接点击开启，并使用终端功能输入。\n\n\n# 终端进入容器## docker exec -it zerotier-one bashzerotier-cli join 6ab565387a1642c*# 使用自建planet# sudo zerotier-cli orbit 3dc58ead8* 3dc58ead8*zerotier-cli listpeerszerotier-cli peerszerotier-cli listmoons\n\n之后去 zerotier 网页同意一下。\nzerotier 常用命令zerotier-cli info #查看当前zerotier-one的信息zerotier-cli listpeers #列出所有的peerszerotier-cli listnetworks #列出加入的所有的网络zerotier-cli join &lt;network&gt; #加入某个网络zerotier-cli leave &lt;network&gt; #离开某个网络zerotier-cli listmoons #列出加入的Moon节点zerotier-cli orbit &lt;world ID&gt; &lt;seed&gt; #加入某个Moon节点zerotier-cli deorbit &lt;world ID&gt; #离开某个Moon节点\n\n后话发现用了 moon 之后反而连不上了，放弃。\n引用\nzerotier\n\n","categories":["Tech","Intranet penetration"],"tags":["内网穿透","nas","zerotier"]},{"title":"WireGuard 的使用","url":"/2023/07/27/Tech/Intranet%20penetration/WireGuard%E7%9A%84%E4%BD%BF%E7%94%A8/","content":"引言最后失败了，不用看。\n效果展示过程sudo apt install wireguardwg genkey | sudo tee /etc/wireguard/privatekey | wg pubkey | sudo tee /etc/wireguard/publickeysudo vim /etc/wireguard/wg0.conf&#x27;&#x27;&#x27;[Interface]Address = 10.0.0.1/24SaveConfig = trueListenPort = 51820PrivateKey = SERVER_PRIVATE_KEYPostUp = iptables -A FORWARD -i %i -j ACCEPT; iptables -t nat -A POSTROUTING -o eth0 -j MASQUERADEPostDown = iptables -D FORWARD -i %i -j ACCEPT; iptables -t nat -D POSTROUTING -o eth0 -j MASQUERADE&#x27;&#x27;&#x27;cat /etc/wireguard/privatekey# aCkT9TzcacNkD5CgzBnTlP8x4sRkDF+GyoLN0COZTl4=cat /etc/wireguard/publickey# 4exJtmb0mrWC52LtVeEWY3r6/INpB91s5FMZ2L3GaxA=ip -o -4 route show to default | awk &#x27;&#123;print $5&#125;&#x27;# eth0# 启动和检查sudo wg-quick up wg0sudo wg show wg0ip a show wg0# 配置防火墙sudo vim /etc/sysctl.conf## net.ipv4.ip_forward=1sudo sysctl -psudo ufw allow 51820/udp# 添加客户端sudo wg set wg0 peer CpunRSVdM0DUbKaX2mOWTfugYxyZF6DDZWGMorMWTA8= allowed-ips 10.0.0.2# sudo wg set wg0 peer CLIENT_PUBLIC_KEY allowed-ips 10.0.0.2sudo vim /etc/wireguard/wg0.conf&#x27;&#x27;&#x27;[Peer]# Name = macPublicKey = CpunRSVdM0DUbKaX2mOWTfugYxyZF6DDZWGMorMWTA8=AllowedIPs = 10.0.0.2/32&#x27;&#x27;&#x27;# closesudo wg-quick down wg0wg show\n\n结论引用\n如何在 Ubuntu 20.04 安装 WireGuard VPN | myfreax\n\n","categories":["Tech","Intranet penetration"],"tags":["Intranet penetration","内网穿透"]},{"title":"利用 ssh 的端口转发","url":"/2024/02/08/Tech/Intranet%20penetration/%E5%88%A9%E7%94%A8ssh%E7%9A%84%E7%AB%AF%E5%8F%A3%E8%BD%AC%E5%8F%91/","content":"引言效果展示过程-L本地主机 A 指定端口 X 的访问请求转发给主机 B，交由主机 B 对另一指定主机 C 的指定端口 Z 发起访问。命令如下：\nssh -L 主机A端口X:主机C:主机C端口Z username@hostname\n\nssh tenney@10.9.65.32 -p 22 -L 0.0.0.0:58096:10.9.65.32:58096 -Nssh tenney@10.9.65.32 -p 22 -L 0.0.0.0:10080:10.9.65.32:10080 -N\n\nssh tenney@10.9.65.32 -p 22 -N -D 57890\n结论引用\n彻底搞懂 SSH 端口转发命令 - 知乎\n\n","categories":["Tech","Intranet penetration"]},{"title":"无需客户端的内网穿透 - i996","url":"/2023/11/15/Tech/Intranet%20penetration/%E6%97%A0%E9%9C%80%E5%AE%A2%E6%88%B7%E7%AB%AF%E7%9A%84%E5%86%85%E7%BD%91%E7%A9%BF%E9%80%8F%20-%20i996/","content":"引言这玩意比较神奇的就是不需要客户端，直接bash就能跑，缺点是必须公众号…\n还有比较好用的就是可以直接分享局域网下面的其他端口，我觉得还挺有用的。\n效果展示过程结论引用\ni996 内网穿透&#x2F;证书签发\nGitHub - bugfan&#x2F;i996: 免费 免搭建 免安装 内网穿透 ssl证书签发 远程办公 居家办公工具 方便调试微信小程序 (客户端无需安装任何程序拿来即用) 类似于natapp ngrok\n\n","categories":["Tech","Intranet penetration"]},{"title":"Mac VS CODE 无法 ssh-remote 的解决过程","url":"/2023/03/18/Tech/MacOS/Mac%20VS%20CODE%20%E6%97%A0%E6%B3%95%20ssh-remote/","content":"引言将mac air刷回出厂版本 (Mojave) 后，确实获得了无比给力的运行速度和续航能力，开腾讯会议风扇也不转了，又可以一用八小时了，看起来一起都向着好的方向发展，除了一件事：Visual Studio Code(VS Code).\n当我将一切软件都配置好了之后，发现作为我主力编程软件的VS Code竟然无法使用ssh-Remote连接服务器了。更离奇的是VS Code Insider居然成功了一次，之后双双停摆。在我看来这简直是灵异事件的程度了…\n当前情况Terminal: 可ssh\nVS Code: 不可ssh, 不可ssh-Remote\nVS Code Insider: 不可ssh, 不可ssh-Remote(成功仅首次)\n过程删除服务器服务文件第一个值得考虑的就是因为客户端的CODE版本不同产生了不同的服务端configFile文件，先删掉试试。\n在本地点击About Visual Studio Code可获得Commit id如：b3e4e68a0bc097f0ae7907b217c1119af9e03435. 实际上VSCode软件当前版本的提交的HASH值。\n在服务器端可通过ls ~/.vscode-server查看vscode-server的软件目录，看以看到以Commit id命名的相应文件夹。\n这时候可以删除后本地连接使自动下载，也可以去官网下载对应版本的 vscode-server 软件，手动更新，方法来自VSCode Remote 报错，无法连接？？.\n更新依然无法连接。\n绕过密码验证第二次尝试，查看ssh-Remote连接时使用的命令。\n在VS Code中的Terminal中可以得到连接中使用的命令ssh -v  -D 51465 -o ConnectTimeout=15 10.9.65.31, 尝试输入可以获取报错记录。\nTenneys-Air:~ tenney$ ssh 127.0.0.1 -vOpenSSH_7.9p1, LibreSSL 2.7.3...debug1: Authentications that can continue: publickey,password,keyboard-interactivedebug1: Trying private key: /Users/tenney/.ssh/id_dsadebug1: Trying private key: /Users/tenney/.ssh/id_ecdsadebug1: Trying private key: /Users/tenney/.ssh/id_ed25519debug1: Trying private key: /Users/tenney/.ssh/id_xmssdebug1: Next authentication method: keyboard-interactivedebug1: read_passphrase: can&#x27;t open /dev/tty: Device not configureddebug1: Authentications that can continue: publickey,password,keyboard-interactive...Permission denied, please try again.debug1: read_passphrase: can&#x27;t open /dev/tty: Device not configuredReceived disconnect from 127.0.0.1 port 22:2: Too many authentication failuresDisconnected from 127.0.0.1 port 22\n\n可以看出，ssh对/dev/tty进行了多次请求访问，并全部失败。又因访问过多被拒绝。\n查看/dev/tty权限发现无异常，而Terminal可以正常访问说明软件无异常。\n/dev/tty是一个用于验证密码的软件，而且顺序位于密钥验证的后面。虽然没搞懂为什么，但既然提示无法访问，那就不访问，使用公钥连接而非密码就可以跳过这一步，如How do you copy the public key to a ssh-server?.\n# 创建计算机keyssh-keygen# 推送至服务器ssh-copy-id -i ~/.ssh/id_rsa.pub tenney@10.9.65.31\n\n结束后VS Code Termanal成功登录，但依然无法使用ssh-Remote.\n排除终端差异使用env &gt; $HOME/Desktop/userenv.txt分别可以查看Termanal和VS Code Termanal的环境How to export and import environment variables in windows? - Stack Overflow以判断差异，但是无决定性差异。\n升级 openssh查阅网络确实有因系统版本导致ssh不可用的事例，考虑到使用的ssh参数可能不能被服务端支持，尝试升级ssh客户端。\nssh -V获取当前版本。\nOpenSSH_7.9p1, LibreSSL 2.7.3\n现在最新的OpenSSH版本是 9.1, 因此值得更新试试。\n# openssh updatebrew install openssh# successbrew install automakebrew install opencc\n\n其中出现了一些小插曲就是openssh的依赖软件有一个叫mandoc的官网炸了上不去，所以就手动安装了其他的。但是事实上因为没有办法获得mandoc, 所以其实没有安装成功openssh, 只是把一些依赖软件安装了，但是不知道为什么，但是解决了…\n其中安装的最后一个软件是automake, 所以记录一下。\n疑点ssh 的参数到底调整了什么在Terminal中所有的参数都是可以正常使用的，但是在VS Code中除了-v以外的所有参数都会报错。可能是由于-v是查看详细信息，所以对连接过程无影响。\n在使用公钥连接而非密码之后，理应绕过了/dev/tty权限的问题，但-D&#x2F;-o的命令只要添加，就会报错。\n为什么成功了一次最大的疑惑就是为什么在VS Code失败的情况下为什么VS Code Insider成功了第一次，但是之后我在删除所有插件，更换旧版本乃至删除服务器.vscode文件夹都毫无反应。\n实在是分不清啊…\nautomake 是什么\nGNU Automake 是一种编程工具，可以产生供 make 程序使用的 Makefile，用来编译程序。它是自由软件基金会发起的 GNU 计划的其中一项，作为 GNU 构建系统的一部分。automake 所产生的 Makefile 符合 GNU 编程标准。\n\nAutomake - 维基百科，自由的百科全书\n我的理解，是用来给make “make”的。\n结论能用的时候，就尽量不要瞎整，恩。\n毕竟我为了这玩意毫无成就感的折腾了四天…\n","categories":["Tech","MacOS"],"tags":["VS CODE","ssh-remote","ssh"]},{"title":"为shell脚本创造相对一致的环境变量--以MacOS为例","url":"/2023/10/01/Tech/MacOS/Mac%20terminal%E5%88%9B%E9%80%A0%E7%9B%B8%E5%AF%B9%E4%B8%80%E8%87%B4%E7%9A%84%E8%BF%90%E8%A1%8C%E7%8E%AF%E5%A2%83/","content":"引言写个脚本自动运行的时候偶尔会发生一种输出文件乱码或者找不到软件的情况, 很显然是由于sh文件运行环境和terminal运行环境不一致导致的, 因此只要指定本机的运行环境, 就可以使脚本正常运行.\n过程获取env文件首先, 我们可以在terminal中运行env来获得各种参数, 比如我的就是:\n\n显然, 里面有对于脚本有用的, 比如LC_ALL=en_US.UTF-8;LANG=en_US.UTF-8就是输出文件乱码的解决方法,而PATH=...就是找不到软件的解决办法.\n而其他大多数没有用的,但是无所谓, 因为我很懒而且不在乎性能, 所以我全都要.\n咱们可以比较一下在terminal输出的和定时脚本输出的区别.\n使用env &gt; ~/env.txt可以把环境参数输出到自己的根目录.\n我们新建一个sh脚本:\n#!/bin/bashenv &gt; ~/env.txt\n\n我的脚本名字是Untitled-1.sh, 绝对路径是/Users/tenney/Downloads/Untitled-1.sh.\n在terminal里面运行bash /Users/tenney/Downloads/Untitled-1.sh得到env文件, 大约有30行内容.\n\n然后使用crontab -e命令新建一个自动化, 内容是* * * * * bash /Users/tenney/Downloads/Untitled-1.sh, 意思是每秒运行一次创造env文件的脚本. 得到的文件如下, 可以看到仅有8行:\n\n所以保存下来terminal的env文件以下次使用是挺方便的.\n读取env文件# Set environment variables# 检查 env.txt 文件是否存在if [ -f &quot;$&#123;HOME&#125;/env.txt&quot; ]; then  # 如果 env.txt 存在，则运行相应的命令  while IFS=&#x27;=&#x27; read -r key value; do    echo &quot;$key=$value&quot;    export &quot;$key&quot;=&quot;$value&quot;  done &lt; &quot;$&#123;HOME&#125;/env.txt&quot;else  # 运行其他命令  echo &quot;env.txt 文件不存在&quot;fi\n\n结论通过这样的方法, 可以获得相对一致的运行环境, 保证脚本正常运行.\n引用\n【已解决】linux终端出现中文乱码_export lang&#x3D;”en_us”;export language&#x3D;”en_us”;export-CSDN博客\n\n","categories":["Tech","MacOS"],"tags":["shell"]},{"title":"SakuraFRP 内网穿透方法和简易使用教程","url":"/2024/11/06/Tech/Intranet%20penetration/sakurafrp/","content":"引言有服务器，但只能在局域网访问，偶尔是有不方便的。\n效果展示过程tcp 协议流量使用 SakuraFRP 的 tcp 协议，除了 http 协议流量是不需要准备域名，可以直接开启隧道后根据选定的信息访问。\n如果使用国内服务器穿透 http 协议，则需要准备域名，并进行备案。\n一般协议访问方法\nsftp 协议与之类似，但是把 url 和端口换成下面这个：\nfrp-mix.top:61241\nsocket5 协议这里有一个额外的技巧，就是使用 tcp 穿透 socket5 协议，继而通过 SwitchyOmega 实现所有网页的代理。\n对于设置过程中未使用密码的，可以直接使用生成的域名 ip+ 端口进行访问，如 frp-ask.top:41475。\nSwitchyOmega 部分的设置很简单，就直接新建情景模式，代理协议选择 socks5，代理服务器地址填写 frp-mix.top，端口填写 61241, 然后保存就可以了。\n\n对于设置过程中启用了密码的，则需要使用 https:// + 生成的域名 ip + 端口 先进行验证，一定注意是 https:// 开头。对于刚刚的例子就是 https://frp-ask.top:41475。\n结论引用\n首页 | SakuraFrp 帮助文档\n\n","categories":["Tech","Intranet penetration"],"tags":["SakuraFRP"]},{"title":"MacOS 禁用更新","url":"/2025/04/20/Tech/MacOS/MacOS%E7%A6%81%E7%94%A8%E6%9B%B4%E6%96%B0/","content":"引言在第 n 次被更新坑了之后，决定禁用更新。\n关于被坑的经历，大概有这样，比如：\n为了安全，禁止使用商店内应用使用 cmd 作为快捷键。而且没给选项让我可以不安全的用。但社区版可以。\n为了安全，把屏幕录制权限调到一天，甚至几分钟一次提示。而且没给选项让我可以不安全的用。但是改 plist 文件可以延长。\n总之在他悠久的”你好用户我是你爹”的思路下，我还是决定禁用更新得了。\n禁用更新## 禁用软件更新服务sudo defaults write /Library/Preferences/com.apple.SoftwareUpdate AutomaticCheckEnabled -bool false## 禁用更新通知sudo defaults write /Library/Preferences/com.apple.systempreferences AttentionPrefBundleIDs 0sudo defaults write /Library/Preferences/com.apple.systempreferences DidShowPref -bool true## 重启 Finderkillall Finder## 编辑 hostssudo nano /etc/hosts\n\n在 hosts 里添加：\n127.0.0.1 swscan.apple.com127.0.0.1 swquery.apple.com127.0.0.1 swdownload.apple.com127.0.0.1 softwareupdate.apple.com\n\n设置未来的通知日期您可以通过将系统更新通知的日期设置为遥远的未来，来延迟更新提示：​\ndefaults write com.apple.SoftwareUpdate MajorOSUserNotificationDate -date &quot;2030-01-01 00:00:00 +0000&quot;defaults write com.apple.SoftwareUpdate UserNotificationDate -date &quot;2030-01-01 00:00:00 +0000&quot;\n\n这将使系统认为您已被通知过更新，从而延迟再次提示。\n清除更新缓存和偏好设置sudo rm -rf /Library/Updatessudo rm /Library/Preferences/com.apple.SoftwareUpdate.plistrm ~/Library/Preferences/com.apple.preferences.softwareupdate.plist\n","categories":["Tech","MacOS"],"tags":["MacOS"]},{"title":"Mac上运行iOS应用程序和游戏","url":"/2023/11/15/Tech/MacOS/Mac%E4%B8%8A%E8%BF%90%E8%A1%8CiOS%E5%BA%94%E7%94%A8%E7%A8%8B%E5%BA%8F%E5%92%8C%E6%B8%B8%E6%88%8F/","content":"引言为什么在mac上使用ios应用呢？\n比如三国杀移动端和网页不共通，比如手机bing免费GPT-4, 这个时候M1&#x2F;M2就很优秀！\n但是官方是不允许直接安装的，所以我们要想想办法。\n效果展示过程结论引用\n「模拟器」有它就可以在Mac上运行iOS应用程序和游戏 - 知乎\nDecrypt IPA Store\nGitHub - PlayCover&#x2F;PlayCover: Community fork of PlayCover\n叶子库导航 | IOS资源分享—做最稳定最优秀的iPA下载网站\n\n","categories":["Tech","MacOS"]},{"title":"mac 自带 python3 装包无权限解决","url":"/2024/12/28/Tech/MacOS/mac%E8%87%AA%E5%B8%A6python3%E8%A3%85%E5%8C%85%E6%97%A0%E6%9D%83%E9%99%90%E8%A7%A3%E5%86%B3/","content":"引言一般情况下大家都用使用 brew 或 conda 来使用 python, 但是有一些软件没有提供更改 python 的地址。所以极其偶尔需要手动装包。\n我记得原来是可以直接使用/usr/bin/python3 -m pip install requests的方式安装的，但是现在好像不行了。\n效果展示过程这是最终选择的办法，使用 sudo 临时切换权限。\nsudo -i/usr/bin/python3 -m pip install requests\n\n其他还有一些可选的办法比如关闭 SIP 等，感觉代价有点大，而且麻烦。\n另外还有一些无效办法，比如使用--target参数指定有权限的安装位置，但是实际实验好像是不行的。\n/usr/bin/python3 -c &quot;import sys; print(sys.path)&quot;sudo /usr/bin/python3 -m pip install --target=/Library/Python/3.9/site-packages requests\n\n结论凑或用，最好就是别用没有的包。因为我虽然安装了 requests，但是使用中却因为有 urllib3 依赖而报错。而 urllib3 又依赖 LibreSSL, 但是本机自带的 LibreSSL 版本过低还不让升级，所以最后还是用 http.client 解决了。\n引用","categories":["Tech","MacOS"],"tags":["mac"]},{"title":"mediaanalysisd 占据大类空间的原因和解决方案","url":"/2025/04/04/Tech/MacOS/mediaanalysisd%E5%8D%A0%E6%8D%AE%E5%A4%A7%E7%B1%BB%E7%A9%BA%E9%97%B4/","content":"引言不少 Mac 用户在使用过程中可能会发现一个名为 mediaanalysisd 的进程占用了大量的磁盘空间，有时甚至达到几十 GB 或更多，这不免引起担忧：这个进程是什么？为什么它会吞噬宝贵的存储空间？有没有办法解决？\n作者在反复删除半年后终于下定决心研究一下这个问题…但是得出结论是没啥办法，最好的办法就是给他足够的时间和空间让他工作完成。\n如果他耽误了别的工作，就只能手动删除完事，但是鉴于他会不断重新工作建议等他工作完…\n删除代码：\nrm -rf ~/Library/Containers/com.apple.mediaanalysisd/Data/Library/Caches/com.apple.mediaanalysisd/\n\nmediaanalysisd什么是 mediaanalysisd？mediaanalysisd 是 macOS 和 iOS 系统中的一个后台服务进程。它的主要职责是分析你设备上的媒体文件，尤其是照片图库（Photos Library）和视频文件。这项分析工作包括：\n\n人脸识别与分组： 扫描照片和视频，识别其中的人脸，并将同一个人归类到“人物”相册中。\n场景与物体识别： 分析图像内容，识别场景（如海滩、森林、城市）和物体（如狗、汽车、食物），以便你可以通过关键词搜索照片（例如搜索“日落”或“猫”）。\n“回忆”功能生成： 基于分析结果，自动创建“回忆”相册，将相关的照片和视频组合成有意义的集合。\n图像质量分析与优化建议： 对照片进行分析，用于后续的编辑建议或优化。\n为 Spotlight 搜索建立索引： 使你能够通过 Spotlight 搜索照片中的内容。\n\n简单来说，mediaanalysisd 是让你的照片应用更智能、搜索更强大、体验更丰富的幕后功臣。它通过机器学习技术，深度理解你的媒体内容。\n为什么 mediaanalysisd 会占用大量空间？mediaanalysisd 在执行上述分析任务时，需要处理大量的媒体数据，尤其是高分辨率的照片和视频。这个过程中会产生一些中间文件和缓存数据，导致其占用较多空间，主要原因包括：\n\n首次分析或大型库导入： 当你首次在新系统上运行照片应用、刚完成系统大版本更新、或者一次性导入大量照片和视频时，mediaanalysisd 需要对整个媒体库进行全面的扫描和分析。这个过程可能非常耗时，并且会产生大量的临时分析数据和索引文件。\niCloud 照片同步： 如果你开启了 iCloud 照片同步，当有大量新照片或视频从云端下载到本地时，mediaanalysisd 也会被触发进行分析。\n生成复杂的分析缓存： 为了快速响应搜索和实现各种智能功能，mediaanalysisd 会将分析结果（如人脸特征数据、物体标签、场景信息等）存储在缓存文件中。媒体库越大、内容越复杂，所需的缓存空间就可能越大。\n进程卡住或异常： 在极少数情况下，mediaanalysisd 进程可能因为某些原因（如遇到损坏的媒体文件、系统 Bug 等）卡住或进入异常状态，导致临时文件无法被及时清理，空间占用持续增长。\n\n占用了多久？多大空间？\n占用空间大小： 这个没有固定数值，完全取决于你的媒体库大小、系统状态和分析进度。对于小型库，可能只占用几 GB。但对于拥有数万张照片和大量视频的大型库，占用几十 GB 甚至上百 GB 的情况也时有发生，尤其是在首次分析阶段。通常，这部分空间会被归类到“系统数据”（System Data）或“其他宗卷”（Other Volumes）里，让你难以直接定位。\n占用时长： 首次全库分析可能需要数小时到数天甚至数周，具体取决于你的 Mac 性能、媒体库大小以及你是否在使用设备（分析通常在设备空闲且接通电源时进行）。正常情况下，分析完成后，占用的部分临时空间会被系统回收。但其生成的核心缓存数据会长期存在，以支持照片应用的各项功能。\n\n如何检查和解决 mediaanalysisd 空间占用问题？如果你发现 mediaanalysisd 占用了异常大的空间，或者长时间居高不下，可以尝试以下步骤：\n\n耐心等待（尤其是首次分析）： 如果你刚更新了系统、导入了大量照片或启用了 iCloud 照片，请给 mediaanalysisd 一些时间完成工作。保持 Mac 连接电源并处于唤醒状态（可以关闭屏幕），尤其是在夜间，让它有充足的时间在后台运行。这是最常见且最应该首先尝试的方法。\n查看活动监视器（Activity Monitor）： 打开“应用程序” &gt; “实用工具” &gt; “活动监视器”。在 CPU 或内存标签页搜索 mediaanalysisd，可以观察它的活动状态。虽然这不能直接显示磁盘占用，但可以看出它是否在活跃运行。如果在 CPU 页持续高占用率，说明它正在工作。\n查看存储空间管理：\n点击屏幕左上角的苹果菜单  &gt; “关于本机” &gt; “储存空间” &gt; “管理…”。\n在这里仔细查看各个分类。“系统数据”通常是 mediaanalysisd 缓存可能存在的地方。虽然无法直接看到 mediaanalysisd 的具体占用，但如果“系统数据”异常庞大，这可能是一个线索。\n\n\n重启你的 Mac： 有时简单的重启可以解决进程卡住或临时文件未被清理的问题。\n确保系统和照片应用是最新版本： 前往“系统偏好设置”（或“系统设置”）&gt; “软件更新”，确保你的 macOS 是最新的。同时，打开 App Store 检查照片应用是否有更新。Apple 可能在更新中修复了导致 mediaanalysisd 行为异常的 Bug。\n检查照片图库状态：\n打开“照片”应用。确保它没有显示任何错误信息或卡在某个进程（如“正在更新”、“正在扫描人脸”等）。\n如果使用 iCloud 照片，检查“照片” &gt; “设置”（或“偏好设置”）&gt; “iCloud”标签页的同步状态是否正常。同步问题有时会间接影响分析进程。\n\n\n（谨慎操作）修复照片图库： 如果怀疑照片图库本身存在问题，可以尝试修复它。操作前请务必备份你的照片图库！\n退出“照片”应用。\n按住 Option + Command 键，同时点击 Dock 上的“照片”图标启动应用。\n在弹出的窗口中点击“修复”。这个过程可能需要一些时间。修复后，mediaanalysisd 可能需要重新进行部分分析。\n\n\n释放常规磁盘空间： 确保你的 Mac 有足够的可用空间（建议至少保留 10%-15% 的总空间）。磁盘空间不足会影响 macOS 的正常运行，包括缓存管理。删除不需要的文件、清理废纸篓、卸载不用的应用等。\n联系 Apple 支持： 如果以上方法都无法解决问题，并且空间占用持续异常，这可能暗示着更深层次的问题。联系 Apple 官方支持寻求帮助是个不错的选择。\n\n总结mediaanalysisd 是 macOS 和 iOS 系统中一个重要的后台进程，它通过分析媒体文件为照片应用带来了诸多智能特性。虽然它在分析过程中（尤其是首次或大量更新后）可能会占用较多存储空间，但这通常是正常且暂时的行为。\n遇到 mediaanalysisd 占用大量空间时，首先应保持耐心，给它足够的时间完成任务。如果问题持续存在，可以尝试重启、更新系统、检查照片库状态等基本排错步骤。理解它的作用和工作方式，有助于你更从容地应对相关问题。记住，在进行任何可能影响数据的操作（如图库修复）前，备份总是最重要的。\n引用\nMacBook 中 mediaanalysisd 占… - Apple 社区\n如何阻止 mediaanalysisd 在 macOS 中占用你的 CPU-表盘吧\n\n","categories":["Tech","MacOS"],"tags":["MacOS","mediaanalysisd"]},{"title":"python 项目自动生成环境配置文件 requirements.txt","url":"/2023/11/29/Tech/MacOS/python%20%E9%A1%B9%E7%9B%AE%E8%87%AA%E5%8A%A8%E7%94%9F%E6%88%90%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE%E6%96%87%E4%BB%B6requirements.txt/","content":"引言新环境安装相当恼火啊。\n效果展示过程pipreqsfreeze 这种全要的太不美感了，不如 pipreqs 只生成单个项目中优雅。\npip install pipreqspipreqs .\n\n如果已有用pipreqs . --force.\n结论篇外pyforest如果使用 jupyter 的话，pyforest [4] 貌似是一个很好的选择。\n引用\npython 项目自动生成环境配置文件 requirements.txt\nPython3：我低调的只用一行代码，就导入 Python 所有库！-CSDN 博客\nPython3，选择 Python 自动安装第三方库，从此跟 pip 说拜拜！！_powershell 无法将 项识别为_Carl_奕然的博客-CSDN 博客\nGitHub - 8080labs&#x2F;pyforest: pyforest - feel the bliss of automated imports\n\n","categories":["Tech","MacOS"]},{"title":"如何在 Mac 上预览 md 文件","url":"/2023/10/22/Tech/MacOS/%E5%A6%82%E4%BD%95%E5%9C%A8%20Mac%20%E4%B8%8A%E9%A2%84%E8%A7%88%20md%20%E6%96%87%E4%BB%B6/","content":"brew install qlmarkdown# brew install qlcolorcode qlstephen qlmarkdown quicklook-json webpquicklook suspicious-package quicklookase qlvideo\n\n引用\nQLMarkdown – 像「预览」一样快速查看 Markdown 文档[macOS]\nQLMarkdown - github\n\n","categories":["Tech","MacOS"]},{"title":"如何在 Mac 上安装 Xcode 命令行工具","url":"/2023/03/18/Tech/MacOS/%E5%A6%82%E4%BD%95%E5%9C%A8%20Mac%20%E4%B8%8A%E5%AE%89%E8%A3%85%20Xcode%20%E5%91%BD%E4%BB%A4%E8%A1%8C%E5%B7%A5%E5%85%B7/","content":"引言什么是 Xcode 命令行工具？如果你不是为苹果设备开发软件，你将不需要完整的 Xcode 应用程序（它需要超过 40GB 的磁盘空间！）。\n相反，你将安装 Xcode 命令行工具。这是一个较小的软件包，为软件开发人员提供了在命令行（也就是在终端应用程序）上运行的工具。\n自从计算机诞生以来，程序员就在 Unix 操作系统上使用这些工具，它们几乎是所有软件开发的基础。\n幸运的是，Xcode 命令行工具包在你的磁盘上只需要 1.2GB 的空间。\n你有三种选择在 Mac 上安装 Xcode 命令行工具：\n\n安装完整的 Xcode 包\n当被一个命令触发时安装 Xcode 命令行工具\n安装 Xcode 命令行工具作为 Homebrew 安装的一部分\n\n我不建议安装完整的 Xcode 包，除非你在为苹果设备开发软件。下载它的时间太长，而且会消耗不必要的磁盘空间。请尝试两种更快的方法之一。\n效果展示&gt; xcode-select -p$ /Library/Developer/CommandLineTools\n\n过程/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;\n\n引用\n## 如何在 Mac 上安装 Xcode 命令行工具\n\n","categories":["Tech","MacOS"]},{"title":"安装 Homebrew","url":"/2023/11/29/Tech/MacOS/%E5%AE%89%E8%A3%85Homebrew/","content":"引言brew 太好用了，值得每一个 mac 玩家使用。\n效果展示过程安装命令在可以正常连接”互联网”的情况下运行：\n/bin/bash -c &quot;$(curl -fsSL https://raw.githubusercontent.com/Homebrew/install/HEAD/install.sh)&quot;\n结论引用\nHomebrew\n\n","categories":["Tech","MacOS"]},{"title":"更优雅的命令行输入工具 - Oh-My-ZSH","url":"/2023/05/28/Tech/MacOS/%E6%9B%B4%E4%BC%98%E9%9B%85%E7%9A%84%E5%91%BD%E4%BB%A4%E8%A1%8C%E8%BE%93%E5%85%A5%E5%B7%A5%E5%85%B7%20-%20Oh-My-ZSH/","content":"引言自macOS Catalina起， zsh 已取代 bash 成为新版操作系统中的默认 shell 。既然有这个条件，不如试试更优雅的命令行输入吧。\nOh My Zsh是一个基于zsh命令行，提供了主题配置，插件机制，并内置了许多便捷操作的命令行输入工具。正如Oh My Zsh官网描述的Unleash your terminal like never before., 他确实给我带来了全新的输入体验。\n其中最另我不能脱离的功能有二。\n\n根据历史记录自动补全\n不用cd直接进入文件夹\n\n\nOh My Zsh is a delightful, open source, community-driven framework for managing your Zsh configuration. It comes bundled with thousands of helpful functions, helpers, plugins, themes, and a few things that make you shout…\n\n效果展示\n过程下载首先用zsh --version检查zsh是否存在以及已安装版本。\n如不存在，可以根据平台自行选择安装版本，具体参考知乎zsh 安装与配置：9 步打造高效命令行.\n需要注意的是，Oh-My-ZSH需要 v4.3.9 及其以上。\n如满足安装要求，可使用curl, wget或fetch等工具下载。\nsh -c &quot;$(curl -fsSL https://raw.githubusercontent.com/ohmyzsh/ohmyzsh/master/tools/install.sh)&quot;\n\n如运行失败考虑是网络环境不好，自行解决。\n插件插件的安装使用有两种方法，一种是启用官方插件目录中的插件，一种是手动启用。\noh-my-zsh 的自带插件都储存在~/.oh-my-zsh/plugins目录中，如果希望使用一个自带插件，可以在~/.zshrc的plugins=(xxx, xxx, ...)这一行里加入插件名称。\n当插件不包含在官方库中时，可以自行下载并启用，以zsh-autosuggestions: zsh-autosuggestions - github为例。\n\nzsh-syntax-highlighting 是一个命令语法校验插件，在输入命令的过程中，若指令不合法，则指令显示为红色，若指令合法就会显示为绿色。效果如下：\n\nOh My ZshClone this repositoryClone this repository into $ZSH_CUSTOM/plugins (by default ~/.oh-my-zsh/custom/plugins)\ngit clone https://github.com/zsh-users/zsh-autosuggestions $&#123;ZSH_CUSTOM:-~/.oh-my-zsh/custom&#125;/plugins/zsh-autosuggestions\n\nAdd the plugin to the list of pluginsAdd the plugin to the list of plugins for Oh My Zsh to load (inside ~/.zshrc)\nplugins=(    # other plugins...    zsh-autosuggestions)\n\nStart a new terminal sessionStart a new terminal session\nManual (Git Clone)\nClone this repository somewhere on your machine. This guide will assume ~/.zsh/zsh-autosuggestions.\n\n# zsh-autosuggestionsgit clone https://github.com/zsh-users/zsh-autosuggestions ~/.zsh/zsh-autosuggestions# zsh-syntax-highlightinggit clone https://github.com/zsh-users/zsh-syntax-highlighting.git ~/.zsh/zsh-syntax-highlighting\n\n\nAdd the following to your .zshrc:\n\n# zsh-autosuggestionssource ~/.zsh/zsh-autosuggestions/zsh-autosuggestions.zsh# zsh-syntax-highlightingsource ~/.zsh/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh\n\n\nStart a new terminal session.\n\n另外，Homebrew可提供了一些插件的下载，如：\n# Homebrewbrew install zsh-syntax-highlighting\n\n之后同样source /usr/local/share/zsh-syntax-highlighting/zsh-syntax-highlighting.zsh.\n主题Oh My Zsh支持许多主题的设置，编辑 ~/.zshrc 文件即可体验。\n官方提供了许多默认主题，可以在oh-my-zsh 的 Wiki查看截图，并在~/.zshrc中更改ZSH_THEME=&quot;xxx&quot;更换。如使用alanpeabody主题就是ZSH_THEME=&quot;alanpeabody&quot;.\n\nMac 终端中文乱码修复详见Mac 终端使用 oh-my-zsh 中文乱码.\n# 更改vim ~/.zshrc# 更改后source ~/.zshrc\n\n更改内容：\nexport LC_ALL=en_US.UTF-8export LANG=en_US.UTF-8\n\nubuntu 安装需要提前安装 zsh, 其他与MacOS一致。\n# apt安装软件sudo apt-get install zsh# 查看系统可以用的 shellcat /etc/shells# 使用命令将 zsh 设置为系统默认 shellchsh -s /bin/zsh\n\n自动更新关闭使用vim ~/.zshrc更改配置文件。\n具体讲就是加上被注释掉的DISABLE_AUTO_UPDATE=&quot;true&quot;.\n参考\nGitHub - ohmyzsh&#x2F;ohmyzsh\n打造一个简单好看实用的终端：Oh-My-Zsh 安装，配置以及设置终端代理\n关闭 Oh my zsh 自动更新\n\n","categories":["Tech","MacOS"],"tags":["Oh-My-ZSH","macOS","zsh","bash"]},{"title":"服务器使用 Time Machine 备份简易方案","url":"/2024/02/09/Tech/MacOS/%E6%9C%8D%E5%8A%A1%E5%99%A8%E4%BD%BF%E7%94%A8TimeMachine%E5%A4%87%E4%BB%BD%E7%AE%80%E6%98%93%E6%96%B9%E6%A1%88/","content":"引言想使用 Time Machine 进行备份要么需要外接硬盘，要么需要专用的设备，但是如果要求不是很高的话也可以使用随便一个可以连接到的网络空间。\n效果展示\n过程大概需要三步：\n\n创造空白镜像\n连接网络上的空间\n在已连接的空间打开新建镜像\n\n创建空白镜像重点是：\n\nSelect the “New Image” option to create you new disk image and save it to your Desktop. 左上角创建空白镜像。\nStart at the bottom with changing the Image Format to “sparse bundle disk image”. 格式是稀疏捆绑磁盘镜像。\nChange “Partitions” selection to “No partition map.” 没有分区映射。\n“Volume Format” to “Mac OS Extended (Case-sensitive, Journaled)”.\nChange “Volume Size” to “Custom” and enter a volume size that suits your needs. 大概 300G 以上。\n\n在已连接的空间打开新建镜像记一下挂载后的位置，替换掉 setdestination 后面的字符。\nsudo tmutil setdestination /Volumes/time_machine\n\n可以使用nload查看上传下载速度。\n结论效果还行，主要看网络情况。\n引用\n树莓派、Windows 设备都可以做你 Mac 的「时间机器」——利用 SMB 协议进行 Time Machine 备份 - 少数派\n时间机器“没有可用的时间机器目的位置”的解决办法-CSDN 博客\nSolution to: “Time Machine could not complete the … - NETGEAR Communities\nLinux 下大家喜欢用什么命令查看流量？ - 知乎\n\n","categories":["Tech","MacOS"]},{"title":"手动 VS CODE 不符合习惯的提示","url":"/2023/10/09/Tech/VS%20CODE/%E6%89%8B%E5%8A%A8VS%20CODE%E4%B8%8D%E7%AC%A6%E5%90%88%E4%B9%A0%E6%83%AF%E7%9A%84%E6%8F%90%E7%A4%BA/","content":"引言在VS CODE中使用R的时候，经常会冒出不符合使用习惯的 linter 提示，这里搜寻了一些解决办法。\n效果展示过程关闭部分 linter 提示我关闭的是超过 80 字符提示和1:nrow()改为seq_提示，因为 R 和别的语言确实不太一样…\n在~/.lintr下添加：\nlinters: with_defaults(line_length_linter = NULL, seq_linter = NULL)\n\n结论引用\nr - how to control the behaviour of lintr in visual studio code? - Stack Overflow\nAvailable linters — linters • lintr\nVisual Studio Code 如何关闭代码智能提示？ - 知乎\n\n","categories":["Tech","VS CODE"],"tags":["VS CODE"]},{"title":"更现代的 R 代码编辑器----本地 VSCode-R 搭建","url":"/2023/03/08/Tech/VS%20CODE/%E6%9B%B4%E7%8E%B0%E4%BB%A3%E7%9A%84R%E4%BB%A3%E7%A0%81%E7%BC%96%E8%BE%91%E5%99%A8----%E6%9C%AC%E5%9C%B0VSCode-R%E6%90%AD%E5%BB%BA/","content":"引言每一位初学者接触 R，想必都是从 RStudio 开始的，甚至将 RStudio 当作 R 本身的也不在少数。尽管 RStudio 是一个非常受欢迎的 R 编程环境，但它也有一些缺点。\n\n单 session\n布局固定\n内存消耗大\n\n首先， “得益于”单 session 操作，当 RStudio 的 Console 中运行了一个命令后，整个编辑器就会失去响应，而时不时的无响应对编程的打击是巨大的。\n其次，RStudio 的界面不够灵活。相信不是只有我一个人觉得右下角的文件导航窗没用吧，RStudio 的默认布局可能不适合每个用户的需求，而且更改布局需要花费一定的时间和努力。相比之下，其他 IDE 通常允许用户自定义和调整布局，以适应个人喜好和工作流程。\n此外，RStudio 的性能问题可能会影响大型数据分析项目。当处理大型数据集时，RStudio 可能会变得缓慢，特别是在使用 RMarkdown 等功能时。在这种情况下，使用其他工具和方法可能更加有效和高效。\n最后，RStudio 的可扩展性不如其他 IDE。虽然 RStudio 支持许多有用的插件和扩展，但它的扩展生态系统相对较小，没有像其他 IDE 那样广泛的社区支持和开发者社区。\n因此，虽然 RStudio 是一个很好的工具，但它也有一些缺点，这些缺点可能会对一些用户造成问题。\n所以为什么不来试试真正的”现代化代码编辑器”呢？比如，VSCode？\n首先，VSCode 提供了与其他编程语言的无缝集成，使您可以在同一编辑器中编写和调试多种编程语言。这意味着您可以在一个环境中同时使用 R 和其他编程语言，而无需切换到不同的编辑器。\n其次，VSCode 具有出色的代码自动完成功能和强大的代码编辑工具，这些工具可以帮助您更快地编写和调试代码。您可以轻松地自定义代码片段、快捷键和扩展，以便更好地适应自己的编码风格和需求。\n此外，VSCode 还具有出色的 Git 集成，可以使您更轻松地管理代码版本控制。您可以使用 VSCode 内置的 Git 功能轻松查看代码差异、提交更改和解决冲突。\n最后，VSCode 是一个轻量级的编辑器，可以更快地启动和运行，这意味着您可以更快地开始编写代码。它也可以更好地适应低性能计算机，因为它不需要太多的系统资源。\n因此，如果你正在寻找一个更灵活、更高效的 R 代码编辑器，那么 VSCode 是一个值得考虑的选择。\n效果展示常用自带及插件附加功能\n\n\n奇妙插件或许是昙花一现的奇思妙想，或许是有望长久存在于各位列表中的奇思妙想\n自动写代码!!!\n\n自动写文档!!!\n\n自动改 md!!!\n\n过程–以 macOS 为例我们需要的东西\n本地 VS Code 及插件\nR(R LSP Client已被整合，不需要单独安装)\nR tools\n\n\n本地 R 包\nlanguageserver\nhttpgd\n\n\n服务器应用\npython\nradian\n\n\n\n安装本地 VS Code 及插件打开 VSCode，最左侧是活动栏。活动栏上的最后一个按钮就是“扩展”按钮。点击它之后你会看到大量可安装的扩展，也可以按快捷键组合 Ctrl + Shift + X 来启动扩展栏的侧面面板。\n\nR\nR tools\n\nR 包在 terminal 中进入 R 环境，安装 languageserver :\ninstall.packages(&quot;languageserver&quot;)install.packages(&quot;httpgd&quot;)\n\n安装过程中可能出现 stringi 无法安装的情况，请详细参见引用 2\n应用conda install radian 或 pip install radian 都行，取决于想往哪放。\n值得注意的是，使用 M1 或 M2 的 mac 应该使用 arm64 构架的 R.\n相应的安装包可以在以下页面找到：\nR for macOS Developers\n配置VS CODE 配置设置 - 插件-R, 将 Bracketed Paste 点上，网上的教程一般还要点 alwaysUseActiveTerminal, 但是我的实际体验是不好用…. 因为设置了之后就无法自动从 terminal 打开 r 了。\n\n使用 which radian 获取路径并填入 Rterm: Mac , 同时建议在 ~/.zshrc 中 alias r=&quot;radian&quot; .\n\n使用 which R 获取路径并填入 Rpath: Mac .\n\n\n这是设置的 json 文件：\n&#123; &quot;r.rterm.option&quot;: [        &quot;--no-site-file&quot;,        &quot;--r-binary=/usr/local/bin/R&quot;,    ],    &quot;r.rterm.mac&quot;: &quot;/Users/sandy/opt/anaconda3/bin/radian&quot;,    &quot;r.bracketedPaste&quot;: true,    &quot;r.rpath.mac&quot;: &quot;/usr/local/bin/R&quot;,    &quot;r.lsp.debug&quot;: true,    &quot;r.lsp.path&quot;: &quot;/usr/local/bin/R&quot;,    &quot;r.sessionWatcher&quot;: true, &quot;r.plot.useHttpgd&quot;: true,&#125;\n\n在设置界面点右上角进入：\n引用\n使用 vscode 进行 R 远程开发\n## 如何在 VSCODE 中高效使用 R 语言（图文详解）\n## VS Code 系列文章（二）：Mac OS 系统下配置 VS Code 的 R 运行环境\n## shiny 服务器未响应，忘掉 Rstudio，来用 VSCode 愉快地进行 R 远程开发\n使用 VSCode 愉快地进行远程 R 开发\n\n","categories":["Tech","VS CODE"],"tags":["R 语言"]},{"title":"自动中英修正工具 - AutoCorrect","url":"/2023/10/29/Tech/VS%20CODE/%E8%87%AA%E5%8A%A8%E4%B8%AD%E8%8B%B1%E4%BF%AE%E6%AD%A3%E5%B7%A5%E5%85%B7%20-%20AutoCorrect/","content":"引言\n一个 VSCode 插件，基于 Rust 编写的工具，用于「自动纠正」或「检查并建议」文案，给 CJK（中文、日语、韩语）与英文混写的场景，补充正确的空格，纠正单词，同时尝试以安全的方式自动纠正标点符号等等。类似 ESlint、Rubocop、Gofmt 等工具，AutoCorrect 可以用于 CI 环境，它提供 Lint 功能，能便捷的检测出项目中有问题的文案，起到统一规范的作用。支持各种类型源代码文件，能自动识别文件名，并准确找到字符串、注释做自动纠正。AutoCorrect 的愿景是提供一套标准化的文案较正方案。以便于在各类场景（例如：撰写书籍、文档、内容发布、项目源代码…）里面应用，让使用者轻松实现标准化、专业化的文案输出 &#x2F; 校正。\n\n同样是纠正，我觉得 AutoCorrect [1]比 cSpell 好多了，虽然还没有探究字典功能，但是开箱即用真的很爽。而且能自动纠正标点符号特别好，特别好啊!! 不过经过我的实验，好像!是不纠正的。\n可以下载各端的应用程序[2]以对各种文档格式化，但我更喜欢 VSCode 插件[3]的方式。\n效果展示\n\n过程在工作区禁用某些规则在工作区的根目录增加.autocorrectrc文件，默认的文件可以在 github[4] 获得。\n结论引用\nGitHub - huacnlee&#x2F;autocorrect: A linter and formatter to help you to improve copywriting, correct spaces, words, and punctuations between CJK (Chinese, Japanese, Korean).\nAutoCorrect\nAutoCorrect - Visual Studio Marketplace\nhuacnlee&#x2F;autocorrect - autocorrect&#x2F;autocorrect&#x2F;.autocorrectrc.default | github\n\n","categories":["Tech","VS CODE"]},{"title":"uniapp 开发","url":"/2024/12/27/Tech/WebDevelopment/uniapp_dev/","content":"引言效果展示过程npm install -g @vue/cli\n\n如果速度不够快可以添加国内镜像源：https://registry.npmmirror.com\n结论报错解决无法使用公共依赖在 HBuiderX 界面中，对待使用的模块右键点击”管理公共模块依赖”.\n\nCannot find module‘uni-id’：uniCloud admin uniapp 新手遇到的问题_林哥哥_好物分享网 BestSvps(未授权)\n\n另外对于登录失败： Error: not found collection的问题和这个类似，需要在 HBuiderX 界面点击”初始化数据库”.\nuni-id 登录问题\n写在最前!!!! 直接用 uni-starter 就对了！不要深究直接用！散装全是坑，但是用轮子就真的好用！\n\n首先，由于 3.5 版本后uni-id已经变成了uni-id-common, 所以之前的使用方式已经不推荐使用了，这一点造成了很大麻烦因为教程上可能还是旧版本。\n首先现在的uni-id分为了 8 个模块。\n\n\n\n模块\n说明\n\n\n\n前端 uni-app 框架的相关 API\nuniIdRouter 页面路由、token 管理客户端 API\n\n\n前端页面 uni-id-pages\n登录、注册、修改密码、忘记密码、个人中心、修改头像等前端页面\n\n\n网络传输自动管理用户 token\n自动保存、续期 token、网络自动传输 token\n\n\n云端云对象 uni-id-co\n与 uni-id-pages 搭配的云对象，相关业务的云端部分\n\n\n云端配置 uni-config-center\n在 uni-config-center 下提供各种配置\n\n\n云端公共模块 uni-id-common\n用于云函数或云对象集成该模块验证 token 身份\n\n\n云数据库的用户相关数据表\nuni-id-users 等各种 opendb 数据表\n\n\nuni-admin\nAdmin 管理后台，包括用户角色权限管理、注册用户统计\n\n\n可以看到，有三个本地&#x2F;四个云端和一个后台。\n我要完成的是小程序，所以：\n第一步，要填写mp-weixin.oauth.weixin, 配置文件uni-id的云端配置文件在uniCloud/cloudfunctions/common/uni-config-center/uni-id/config.json中。如果没有提供这个文件需要自己创建，注意这个文件不能有注释，所以从官网粘贴的要自己删除。\n体验 uni-id 需保证 uniCloud 服务空间至少有数据表 uni-id-users、opendb-verify-codes（验证码表）.\n&quot;mp-weixin&quot;: &#123;&quot;tokenExpiresIn&quot;: 259200,&quot;tokenExpiresThreshold&quot;: 86400,&quot;oauth&quot;: &#123;    // 微信小程序登录所用的 appid、appsecret 需要在对应的小程序管理控制台获取    &quot;weixin&quot;: &#123;    &quot;appid&quot;: &quot;&quot;,    &quot;appsecret&quot;: &quot;&quot;    &#125;&#125;&#125;,\n\n第二步，在登录按钮的脚本调用中使用：\nuniCloud.callFunction(&#123;    name: &#x27;login&#x27;,    data: &#123;    provider: &#x27;mp-weixin&#x27;    &#125;&#125;)\n\n\nuniCloud\nuniapp 使用云函数中的插件 uni-id 实现微信小程序的登录 - 简书\n\n引用\nnpm ,yarn 更换使用国内镜像源，阿里源，清华大学源\n\n","categories":["Tech","WebDevelopment"],"tags":["uniapp"]},{"title":"无法使用 git 的解决方法","url":"/2024/03/03/Tech/git/%E6%97%A0%E6%B3%95%E4%BD%BF%E7%94%A8git%E7%9A%84%E8%A7%A3%E5%86%B3/","content":"引言效果展示过程全局设置用户名两种效果一样，命令比较简单。\n命令git config user.name &quot;your-username&quot;git config user.email &quot;your-email-address&quot;\n\n文件~/.gitconfig\n[user]    name = your-username    email = your-email-address\n\ncould not read Username for ‘https://github.com‘fatal: could not read Username for &#39;https://github.com&#39;: No such device or address\n结论引用\ngit - GitHub - fatal: could not read Username for ‘https://github.com': No such file or directory - Stack Overflow\ngit config 的全局和本地配置 - 知乎\n\n","categories":["Tech","git"]},{"title":"miniconda 安装及使用","url":"/2023/05/24/Tech/conda/miniconda%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/","content":"引言conda 是一个不需要介绍的好用软件，其中又分为 anaconda 和 miniconda, 从名字可以看出一个是完全版一个是精简版。我更喜欢先安装精简版，用的着什么的时候再下载。\n效果展示过程安装 condaLinux:\nwget https://repo.continuum.io/miniconda/Miniconda3-latest-$(uname -s)-$(uname -m).sh## exemple: wget https://repo.continuum.io/miniconda/Miniconda3-latest-Linux-x86_64.shbash ./Miniconda3-latest-$(uname -s)-$(uname -m).sh## exemple: bash ./Miniconda3-latest-Linux-x86_64.shsource ~/.bashrc\n\nMacOS:\n在Miniconda 官网下载\nConda-forge## Conda-forgeconda config --add channels conda-forgeconda config --set channel_priority strict\n\n中国镜像清华源conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/freeconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/conda-forgeconda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/cloud/biocondaconda config --set show_channel_urls yesconda config --show-sources  ## 查看新增channels\n\n阿里云源Linux 用户可以通过修改用户目录下的 .condarc 文件 (即~/.condarc)。\nchannels:  - defaultsshow_channel_urls: truedefault_channels:  - http://mirrors.aliyun.com/anaconda/pkgs/main  - http://mirrors.aliyun.com/anaconda/pkgs/r  - http://mirrors.aliyun.com/anaconda/pkgs/msys2custom_channels:  conda-forge: http://mirrors.aliyun.com/anaconda/cloud  msys2: http://mirrors.aliyun.com/anaconda/cloud  bioconda: http://mirrors.aliyun.com/anaconda/cloud  menpo: http://mirrors.aliyun.com/anaconda/cloud  pytorch: http://mirrors.aliyun.com/anaconda/cloud  simpleitk: http://mirrors.aliyun.com/anaconda/cloud\n\nconda 使用python 的使用conda create -n python3conda env listconda activate python3conda install python=3.9conda install auto-sklearn scipy\n\nR 的使用## runconda create -n R4.2conda env listconda activate R4.2conda install r-base=4.2.3conda install r-languageserver radian\n\ncanda 的命令# 常规操作conda -V# 源conda config --show-sourcesconda config --remove-key channels# 包conda sreachconda updateconda search auto-sklearn --channel conda-forgeconda update --all# 重置conda clean --allconda update conda\n\nconda 使用在 shell 脚本中的使用通过bash hook是其中的一种方案^[3]^.\n#!/bin/basheval &quot;$(conda shell.bash hook)&quot;conda activate wrfpypython test.py\n\nconda 位置修改&#x2F;卸载我帮大家试过了，结合网友的经历[6]，我可以说改完路径后环境改不完，根本改不完…\n所以大家想修改位置，果断卸载然后重装就行了。\n有可视化的话，就直接把文件删了，~/.zshrc或者~/.bashrc里面的激活部分删了就行。\n没有的话就用官方命令，也很方便[7]。\nconda install anaconda-cleananaconda-clean --yes\n\n结论引用\nMiniconda 安装及使用–小白上路\nShell 脚本中获取命令运行结果、特殊变量使用、条件判断等常用操作_shell 命令运行结果_AlbertS 的博客-CSDN 博客\nshell 脚本中激活 conda 虚拟环境 - 知乎\nanaconda 镜像_anaconda 下载地址_anaconda 安装教程 - 阿里巴巴开源镜像站\nMiniconda\n修改 conda 安装路径\n正确卸载 anaconda\n\n","categories":["Tech","conda"],"tags":["conda"]},{"title":"ResilioSync搭配Alist实现共享文档展示","url":"/2023/08/31/Tech/docker/ResilioSync%E6%90%AD%E9%85%8DAlist%E5%AE%9E%E7%8E%B0%E5%85%B1%E4%BA%AB%E6%96%87%E6%A1%A3%E5%B1%95%E7%A4%BA/","content":"引言效果展示过程ResilioSync搭建DATA_FOLDER=/dev/sda1/ResilioSyncWEBUI_PORT=55588mkdir -p $DATA_FOLDERdocker run -d --name Sync \\           -p 127.0.0.1:$WEBUI_PORT:8888 \\           -p 55555 \\           -v $DATA_FOLDER:/mnt/sync \\           --restart on-failure \\           resilio/sync\n\nAlist搭建docker run -d --restart=always -v /dev/sda1/ResilioSync/folders:/opt/alist/data -p 5244:5244 -e PUID=0 -e PGID=0 -e UMASK=022 --name=&quot;alist&quot; xhofe/alist:latestdocker exec -it alist ./alist admin set yeyezi\n\n结论引用\nresilio&#x2F;sync docker hub\n\n","categories":["Tech","docker"]},{"title":"YesPlayMusic+UnblockNeteaseMusic网页部署","url":"/2023/09/05/Tech/docker/YesPlayMusic+UnblockNeteaseMusic%E7%BD%91%E9%A1%B5%E9%83%A8%E7%BD%B2/","content":"引言已失败, 以鄙人的技术玩不成这个.\n踩过得坑总结有:\n\nUnblockNeteaseMusic_docker就没成功过, 安ca证书也不行.\n海外服务器可用性存疑, ping出来的103.126.92.133也不行.\n\n灵感来源于Tepesto的搭建自己的音乐站（解锁网易云无版权音乐）Docker部署YesPlayMusic+UnblockNeteaseMusic - Rainmos.\n使用的YesPlayMusic版本: v0.4.7\nGitHub - qier222&#x2F;YesPlayMusic at v0.4.7\n使用的UnblockNeteaseMusic版本: v0.27.3\nGitHub - UnblockNeteaseMusic&#x2F;server: Revive unavailable songs for Netease Cloud Music (Refactored &amp; Enhanced version)\n效果展示过程部署最新YesPlayMusic网页## clonegit clone https://github.com/qier222/YesPlayMusic.git## 构建 Docker Imagedocker build -t yesplaymusic .## 构建 Docker Imagedocker run -d --name yesplaymusic -p 3000:80 yesplaymusic## Docker Compose 启动# docker-compose up -d\n\nunblock-netease-music-enhanced编辑docker-compose.yml如下:\n其中, 推测unblock services的-a和yesplaymusic services的extra_hosts都是填自己服务器地址, 然后把unblock services的端口设置为80, 也就是http的默认端口.\n但是我的nginx已经把80给占了, 又懒得改, 所以作罢, 算了算了, 没这个福气..\nversion: &#x27;3&#x27;services:  # unblock:  #   image: pan93412/unblock-netease-music-enhanced  #   container_name: unblock  #   command: &quot;-o pyncmd kugou kuwo bilibili migu -p 4080:8080 -p 4081:8081 -a 107.175.142.245 -f 103.126.92.133 -e https://unblock-netease.yeyeziblog.eu.org/http&quot;  #   dns:  #     - 119.29.29.29  #     - 223.5.5.5  YesPlayMusic:    build:      context: .    image: yesplaymusic    container_name: yesplaymusic    volumes:      - /etc/localtime:/etc/localtime:ro      - /etc/timezone:/etc/timezone:ro    ports:      - 3000:80    restart: always    # extra_hosts:    #   - &quot;music.163.com:172.168.10.163&quot;    #   - &quot;interface.music.163.com:172.168.10.163&quot;    #   - &quot;interface3.music.163.com:172.168.10.163&quot;    dns:      - 119.29.29.29      - 223.5.5.5    environment:      NODE_TLS_REJECT_UNAUTHORIZED: &quot;0&quot;\n\ndocker compose up -d\n\n结论引用\n搭建自己的音乐站（解锁网易云无版权音乐）Docker部署YesPlayMusic+UnblockNeteaseMusic - Rainmos\nNeteaseCloudMusicApi +YesPlayMusic +UnblockNeteaseMusic搭建自己的音乐站（解锁网易云无版权音乐） - OrzLee\nIOS端如果提示“网络不给力无法播放”，请加上-f 参数即可正常播放。 · Issue #779 · nondanee&#x2F;UnblockNeteaseMusic · GitHub\n\n","categories":["Tech","docker"]},{"title":"code-server","url":"/2024/01/04/Tech/docker/code-server/","content":"引言效果展示过程chmod a+rw /var/run/docker.sock# chmod a+rw /run/docker.sock\n\ndocker run -d \\  --name=code-server \\  -e PUID=0 \\  -e PGID=0 \\  -e TZ=Asia/Shanghai \\  -e PASSWORD=1111 `#optional` \\  -e SUDO_PASSWORD=1111 `#optional` \\  -v /mnt/dm-1/.ugreen_nas/179563/vscode/config:/config \\    -v /mnt/dm-1/.ugreen_nas/179563/vscode:/config/workspace \\    -v /var/run/docker.sock:/var/run/docker.sock \\    -v $(which docker):/usr/bin/docker \\    -v $(which docker-compose):/usr/bin/docker-compose \\  --net host \\  --restart always \\  --privileged=true \\  linuxserver/code-server:latest\n\n# 切换 root 用户sudo su# 更新源sed -i &quot;s/archive.ubuntu.com/mirrors.aliyun.com/g&quot; /etc/apt/sources.list &amp;&amp; apt update# 安装 pythonapt install -y python# 安装 nodejs，自行调整版本curl -sL https://deb.nodesource.com/setup_14.x | sudo bashapt install -y nodejs# 安装 jdkapt install -y openjdk-8-jdk\n\nssh-keygenssh-copy-id -i /root/.ssh/id_rsa.pub root@127.0.0.1 -p 922ssh -p &#x27;922&#x27; &#x27;root@127.0.0.1&#x27;vi /etc/ssh/sshd_configservice sshd restart\n\n结论引用\nDocker 搭建云端开发环境 code-server - 知乎\nDocker\n\n","categories":["Tech","docker"]},{"title":"dashy 安装和使用","url":"/2024/01/15/Tech/docker/dashy%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","content":"引言nas 或服务器上服务多了，有时候就不太好找。可以搭一个 dashboard 统一管理，而遵循一切皆文件原则的 dashy 或许可以作为一个选项。\n效果展示\n过程搭建服务器mkdir -p /home/tenney/docker/dashytouch /home/tenney/docker/dashy/conf.ymlvim /home/tenney/docker/dashy/conf.yml# Configuringchown tenney:tenney /home/tenney/docker/dashy/conf.ymldocker run -d \\  -p 54000:8080 \\  -v /home/tenney/docker/dashy/config/conf.yml:/app/user-data/conf.yml \\  --name dashy \\  --restart=always \\  lissy93/dashy:latest\n\n以下为更新前方法：\n\n\nsudo docker run -d \\  -e PUID=1001 \\  -e PGID=1001 \\  -p 54000:80 \\  -v /home/tenney/docker/dashy/conf.yml:/app/public/conf.yml \\  --name dashy \\  --restart=always \\  lissy93/dashy:latest\n\n\n\n登录页面：\nhttp://127.0.0.1:54000\n可以使用反向代理挂载到 80 端口实现自动进入。\nlocation ^~ / &#123;    proxy_pass http://127.0.0.1:54000;    proxy_set_header Host $host;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    proxy_set_header REMOTE-HOST $remote_addr;    proxy_set_header Upgrade $http_upgrade;    proxy_set_header Connection &quot;upgrade&quot;;    proxy_set_header X-Forwarded-Proto $scheme;    proxy_http_version 1.1;    add_header X-Cache $upstream_cache_status;&#125;\n\nnasdocker run -d \\  -p 4000:80 \\  -v /root/my-local-conf.yml:/app/public/conf.yml \\  --name my-dashboard \\  --restart=always \\  lissy93/dashy:latest\n\n密码设置密码的加密方式是 SHA256, 可以使用任意在线工具创建。\nSHA256 - Online Tools\nappConfig:  auth:    users:    - user: alicia      hash: 4D1E58C90B3B94BCAD9848ECCACD6D2A8C9FBC5CA913304BBA5CDEAB36FEEFA3      type: admin    - user: bob      hash: 5E884898DA28047151D0E56F8DC6292773603D0D6AABBDD62A11EF721D1542D8\n\n结论比起自己的收藏夹，dashy 可以更方便的进行分享和权限管理，除此之外，还可以不局限于单一浏览器访问，对于单服务器应用较多的情况比较适用。\n引用\nDeployment | Dashy\nSHA256 - Online Tools\n用 Dashy 为 NAS 部署一个服务导航页，管理所有端口的服务 - #UNTAG\nGitHub - Lissy93&#x2F;dashy: 🚀 A self-hostable personal dashboard built for you. Includes status-checking, widgets, themes, icon packs, a UI editor and tons more!\nAuthentication | Dashy\nauthentication · Lissy93&#x2F;dashy Wiki · GitHub\n\n","categories":["Tech","docker"],"tags":["nas","dashboard"]},{"title":"Flutter 学习笔记","url":"/2024/12/12/Tech/WebDevelopment/FlutterLearning/","content":"引言效果展示过程Development toolssudo apt-get update -y &amp;&amp; sudo apt-get upgrade -y;sudo apt-get install -y curl git unzip xz-utils zip libglu1-mesa\n\nInstall the Flutter SDKUse VS Code to installPrompt VS Code to install Flutter\n\nLaunch VS Code.\n\nTo open the Command Palette, press Control + Shift + P.\n\nIn the Command Palette, type flutter.\n\nSelect Flutter: New Project.\n\nVS Code prompts you to locate the Flutter SDK on your computer.\n\nIf you have the Flutter SDK installed, click Locate SDK.\nIf you do not have the Flutter SDK installed, click Download SDK.\n\n This option sends you the Flutter install page if you have not installed Git as directed in the development tools prerequisites.\n\nWhen prompted Which Flutter template?, ignore it. Press Esc. You can create a test project after checking your development setup.\n\n\n结论引用\n\n\n","categories":["Tech","WebDevelopment"],"tags":["Flutter"]},{"title":"docker firefox 搭建","url":"/2023/09/03/Tech/docker/docker%20firefox%E6%90%AD%E5%BB%BA/","content":"docker带 vncGitHub - jlesage&#x2F;docker-firefox: Docker container for Firefox\ndocker run -d \\    --name=firefox \\    -p 5800:5800 \\    -v /docker/appdata/firefox:/config:rw \\    jlesage/firefox\n\n官方docker run -d \\  --name=firefox \\  --security-opt seccomp=unconfined `#optional` \\  -e PUID=1000 \\  -e PGID=1000 \\  -e TZ=Etc/UTC \\  -p 3000:3000 \\  -p 3001:3001 \\  -v /path/to/config:/config \\  --shm-size=&quot;1gb&quot; \\  --restart unless-stopped \\  lscr.io/linuxserver/firefox:latest\n\nnas## 限制最大内存=1000 mb## 端口3000:30003001:3001## 存储使用/path/to/config:/config/path/to/download:/download## 环境PUID=0PGID=0TZ=Asia/Shanghai\n\n\nlinuxserver&#x2F;firefox - LinuxServer.io\n\n","categories":["Tech","docker"]},{"title":"dugs","url":"/2024/08/31/Tech/docker/dugs/","content":"引言起因是看到了一个开发 macos 展示的 Web Serve, 然后发现 linux 有非常好用的相关应用，于是选择了 dugs 进行体验。\n效果展示\n过程docker run -v `pwd`:/data -p 5000:5000 --rm sigoden/dufs /data -A\n\n\n\n\n\n结论引用\n\n\n","categories":["Tech","docker"]},{"title":"qbittorrent 安装和使用","url":"/2024/01/13/Tech/docker/qbittorrent%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","content":"引言效果展示过程idsudo docker run -d \\  --name=qbittorrent \\  -e PUID=1001 \\  -e PGID=1001 \\  -e TZ=Asia/Shanghai \\  -e WEBUI_PORT=8080 \\  -p 58080:8080 \\  -p 56881:6881 \\  -p 56881:6881/udp \\  -v /home/tenney/docker/qb/config:/config \\  -v /home/tenney/docker/qb/downloads:/downloads \\  --restart unless-stopped \\  lscr.io/linuxserver/qbittorrent:latest\n\nsudo docker run -d \\  --name emby \\  -e NO_PROXY=172.17.0.1,127.0.0.1,localhost \\  -e ALL_PROXY=http://10.9.65.31:7890 \\  -e HTTP_PROXY=http://10.9.65.31:7890 \\  -p 58096:8096 \\  -v /home/tenney/docker/emby/config:/config \\  -v /home/tenney/docker/qb/downloads:/media \\  emby/embyserver\n\nsudo docker stop qbittorrent# 在`/config/qBittorrent/qBittorrent.conf`文件中加上sudo docker start qbittorrent\n\n# 在`/config/qBittorrent/qBittorrent.conf`文件中加上：WebUI\\HTTPS\\Enabled=falseWebUI\\HostHeaderValidation=falseWebUI\\ServerDomains=*WebUI\\AuthSubnetWhitelist=@Invalid()WebUI\\Password_PBKDF2=&quot;@ByteArray(BCJLroZTytMttwovkOCMtw==:kZaDiNhciEq/uyXFQs5g4ycy2dA4p5+Uq9Qozo67Sr9PV3DLQTMeBbPwIkkkwiLKqPCuop1Njb6fVLUCC8QrLQ==)&quot;\n\n注意，这里设置的密码是adminadmin\n结论引用\nqbittorrent - LinuxServer.io\ndocker 部署 qb，显示无效的用户名或密码问题的解决办法【pt 吧】\nhttps://tieba.baidu.com/p/8742913978\n\n","categories":["Tech","docker"]},{"title":"docker 安装","url":"/2023/04/05/Tech/docker/docker%E9%87%8D%E8%A3%85/","content":"引言效果展示过程docker pull 配置代理[1]sudo mkdir -p /etc/systemd/system/docker.service.dsudo touch /etc/systemd/system/docker.service.d/proxy.conf\n\n[Service]Environment=&quot;HTTP_PROXY=http://proxy.example.com:8080/&quot;Environment=&quot;HTTPS_PROXY=http://proxy.example.com:8080/&quot;Environment=&quot;NO_PROXY=localhost,127.0.0.1,.example.com&quot;\n\ndocker 重装ubuntudocker stop $(docker ps -a -q)docker rm $(docker ps -a -q)sudo apt-get remove docker docker-engine docker.io docker-cesudo apt-get purge docker-enginesudo apt-get autoremove –purge docker-enginerm -rf /var/lib/dockersudo apt updatesudo apt install docker.iosudo systemctl start dockersudo systemctl enable dockerdocker -v\n\ncentOSdocker stop $(docker ps -a -q)docker rm $(docker ps -a -q)sudo yum remove docker docker-engine docker.io docker-cesudo yum purge docker-enginesudo yum autoremove –purge docker-enginerm -rf /var/lib/dockersudo yum update\n\n## 一键脚本有可能替换repo, 废弃## curl -sSL https://get.daocloud.io/docker | sh## 手动sudo yum remove docker \\                  docker-client \\                  docker-client-latest \\                  docker-common \\                  docker-latest \\                  docker-latest-logrotate \\                  docker-logrotate \\                  docker-enginesudo yum install -y yum-utils \\  device-mapper-persistent-data \\  lvm2sudo yum-config-manager \\    --add-repo \\    https://mirrors.tuna.tsinghua.edu.cn/docker-ce/linux/centos/docker-ce.reposudo yum install docker-ce docker-ce-cli containerd.io docker-compose-pluginsudo systemctl start dockersudo systemctl enable dockersudo docker run hello-worlddocker -v\n\n结论引用\n如何优雅的给 Docker 配置网络代理\n\n","categories":["Tech","docker"]},{"title":"unblockneteasemusic搭建","url":"/2023/08/19/Tech/docker/unblockneteasemusic%E6%90%AD%E5%BB%BA/","content":"引言效果展示过程下载镜像^1^下载项目https://github.com/592767809/docker_pull的文件，安装python环境\n添加国内镜像docker run  -d -p 8080:8080  -m 300M --memory-swap -1 -e ENABLE_LOCAL_VIP=true -e NO_CACHE=true -e ENABLE_FLAC=true -e NODE_ENV=production --restart=always --log-opt max-size=10m --name=win_music pan93412/unblock-netease-music-enhanced -e https://music.163.com\n\n结论引用\n海外解锁网易云音乐版权限制歌曲\n[Windows] 绿联云NAS搞机笔记（一）安装transmission\n\n","categories":["Tech","docker"]},{"title":"不同设备docker转移容器","url":"/2023/06/07/Tech/docker/%E4%B8%8D%E5%90%8C%E8%AE%BE%E5%A4%87docker%E8%BD%AC%E7%A7%BB%E5%AE%B9%E5%99%A8/","content":"引言\ndocker save和docker export的区别：docker save保存的是镜像（image），docker export保存的是容器（container）；docker load用来载入镜像包，docker import用来载入容器包，但两者都会恢复为镜像；docker load不能对载入的镜像重命名，而docker import可以为镜像指定新名称；docker save和docker load过程能够保留镜像分层的文件系统，docker export和docker import则没有保存。\n\n从Docker 镜像该怎么传 - 知乎可以得到两种转移容器的方式.\n效果展示过程# 保存的是容器docker save -o output.tar resilio/sync# 下载保存文件wget file.yeyeziblog.eu.org/files/output.tar# 导入容器docker load -i output.tar # 测试docker run resilio/sync\n\n# 源docker save -o output.tar whyour/qinglong docker stop qinglong# 目标docker load -i output.tar docker run qinglong## WARNING: The requested image&#x27;s platform (linux/arm64) does not match the detected host platform (linux/amd64/v3) and no specific platform was requested## exec ./docker/docker-entrypoint.sh: exec format error\n\n镜像迁移将更新导出为镜像后，就可以开始镜像迁移。\n由于Docker以集中的方式管理镜像的，所以在迁移之前，需要先从Docker中取出镜像。docker save命令可以将镜像输出，提供了保存镜像到Docker外部的方式。\ndocker save webapp:1.0 &gt; webapp-1.0.tar默认定义下，docker save命令会将镜像内容放入输出流中，这种用法有时不太友好，docker save命令还提供了-o选项，用来指定输出文件，使用这个选项可以让命令更具有统一性。\ndocker save -o .&#x2F;webapp-1.0.tar webapp:1.0镜像导出之后可以找到已经存储镜像内容的webapp-1.0.tar文件。通过解压软件查看其中的内容，会看到里面就是镜像所基于的几个镜像层的记录文件。\n四、导入镜像\n可以通过很多种方式将导出的镜像文件复制到另一台机器上，之后将镜像导入到新机器中运行的Docker中。使用与docker save相对的docker load命令即可。\ndocker load &lt; webapp-1.0.tardocker load从输入流中读取镜像的数据，也能够使用-i选项指定输入文件。\ndocker load -i webapp-1.0.tar镜像导入后，就可以通过docker images看到，导入的镜像会延用原有的镜像名称。\n五、批量迁移\n通过docker save和docker load命令还能够批量迁移镜像，只要在docker save中传入多个镜像名作为参数，它就能够将这些镜像都打成一个包，便于一次性迁移多个镜像。\ndocker save -o .&#x2F;images.tar webapp:1.0 nginx:1.12 mysql:5.7装有多个镜像的包可以直接被docker load识别和读取，将这个包导入后，其中所有镜像都会被导入到Docker之中。\n导出和导入容器提交镜像修改，再导出镜像进行迁移的方法还不够效率，使用docker export命令可以直接导出容器，把它简单的理解为docker commit与docker save的结合体。\ndocker export -o ./webapp.tar webapp\n相对的，使用docker export导出的容器包，需要使用docker import导入，导入的结果还是一个镜像，而不是容器。\n结论引用","categories":["Tech","docker"]},{"title":"企业级高性能多维表格 teable","url":"/2025/04/13/Tech/docker/%E4%BC%81%E4%B8%9A%E7%BA%A7%E9%AB%98%E6%80%A7%E8%83%BD%E5%A4%9A%E7%BB%B4%E8%A1%A8%E6%A0%BCteable/","content":"引言为什么选择 TeableTeable 独创的可持续性架构，让企业数据增长不再受制于软件的瓶颈，通过极低的操作门槛加速企业数字化渗透率。每个团队可以按需构建可扩展的业务系统，让应用跟得上业务变化，更能适应业务增长。\nTeable 不仅是一个无代码解决方案，更是助力先进的企业数字化得力工具，确保每个团队都能获得适合自己需求的平台。Teable 致力于帮助企业实现数字化转型，让每个团队都能轻松构建和管理自己的业务系统，从而更好地适应企业的发展和变化。\n效果展示过程创建 docker-compose 文件进入服务器，创建并进入 teable 文件夹\nmkdir teablecd teable\n\n创建一个 docker-compose.yaml 以及一个 .env 文件，并粘贴下面内容，已使用国内镜像源以保证顺畅安装\nvim docker-compose.yaml\n\n当使用自己的数据库时, 可以使用最精简版:\nversion: &quot;3.9&quot;services:  teable:    image: registry.cn-shenzhen.aliyuncs.com/teable/teable:latest    restart: always    ports:      - &quot;3000:3000&quot;    volumes:      - teable-data:/app/.assets:rw    env_file:      - .env    environment:      - NEXT_ENV_IMAGES_ALL_REMOTE=true    networks:      - teable    # depends_on:    # teable-db:    #   condition: service_healthy    healthcheck:      test: [&quot;CMD&quot;, &quot;curl&quot;, &quot;-f&quot;, &quot;http://localhost:3000/health&quot;]      start_period: 5s      interval: 5s      timeout: 3s      retries: 3networks:  teable:    name: teable-networkvolumes:  teable-data: &#123;&#125;\n\n创建 .env 文件\n# 请将下面替换为可公开访问的地址PUBLIC_ORIGIN=http://0.0.0.0:3000# ---------------------# PostgresPOSTGRES_HOST=172.17.0.1POSTGRES_PORT=5432POSTGRES_DB=teablePOSTGRES_USER=user_iA*****POSTGRES_PASSWORD=password_4y*****# RedisREDIS_HOST=172.17.0.1REDIS_PORT=6379REDIS_DB=0REDIS_PASSWORD=redis_XE*****# AppPRISMA_DATABASE_URL=postgresql://$&#123;POSTGRES_USER&#125;:$&#123;POSTGRES_PASSWORD&#125;@$&#123;POSTGRES_HOST&#125;:$&#123;POSTGRES_PORT&#125;/$&#123;POSTGRES_DB&#125;# 获取方式：登录网页版QQ邮箱 → 设置 → 账户 → 开启「POP3/SMTP服务」→ 获取授权码BACKEND_MAIL_HOST=smtp.qq.comBACKEND_MAIL_PORT=465BACKEND_MAIL_SECURE=trueBACKEND_MAIL_SENDER=te********@qq.comBACKEND_MAIL_SENDER_NAME=系统通知BACKEND_MAIL_AUTH_USER=te********@qq.comBACKEND_MAIL_AUTH_PASS=nl****e# 请将下面替换为可公开访问的地址PUBLIC_DATABASE_PROXY=db-proxy.example.com:port\n\n# 运行 docker-composedocker-compose pulldocker-compose up -d## 关闭docker-compose down\n\n结论引用\n\n\n"},{"title":"青龙面板+京东搭建","url":"/2023/06/08/Tech/docker/%E9%9D%92%E9%BE%99%E9%9D%A2%E6%9D%BF%E6%90%AD%E5%BB%BA/","content":"引言效果展示过程青龙面板docker添加国内镜像\nmkdir -p /etc/dockertee /etc/docker/daemon.json &lt;&lt;-&#x27;EOF&#x27;&#123;  &quot;registry-mirrors&quot;: [    &quot;https://0b27f0a81a00f3560fbdc00ddd2f99e0.mirror.swr.myhuaweicloud.com&quot;,    &quot;https://ypzju6vq.mirror.aliyuncs.com&quot;,    &quot;https://registry.docker-cn.com&quot;,    &quot;http://hub-mirror.c.163.com&quot;,    &quot;https://docker.mirrors.ustc.edu.cn&quot;  ]&#125;EOFsystemctl daemon-reloadsystemctl restart docker\n\n下载镜像并运行, 注意先复制docker run -dit \\再复制后面.\ndocker pull whyour/qinglong:latestdocker run -dit \\-v $PWD/ql/config:/ql/config \\   -v $PWD/ql/log:/ql/log \\   -v $PWD/ql/db:/ql/db \\   -v $PWD/ql/repo:/ql/repo \\   -v $PWD/ql/raw:/ql/raw \\   -v $PWD/ql/scripts:/ql/scripts \\   -v $PWD/ql/jbot:/ql/jbot \\   -p 5700:5700 \\   --name qinglong \\   --hostname qinglong \\   --restart unless-stopped \\   whyour/qinglong:latest\n\nnas目录规则和原来似乎有一些变化, 我感觉有一个/ql/data/就够了…\n原来的教程中的/ql/应该是已经失效了.\n为了使用代理方便我设置网络为host, 这样本地代理可以直接用.\n\n\nfaker3(京东)创建拉取任务创建任务, 名字随便, 时间随便, 用完就可以删, 我随便设的0 15 10 15 1 1.\nql repo https://git.metauniverse-cn.com/https://github.com/shufflewzc/faker3.git &quot;jd_|jx_|gua_|jddj_|jdCookie&quot; &quot;activity|backUp&quot; &quot;^jd[^_]|USER|function|utils|sendNotify|ZooFaker_Necklace.js|JDJRValidator_|sign_graphics_validate|ql|JDSignValidator|magic|depend|h5sts&quot; &quot;main&quot;\n\n\n依赖安装免代码安装依赖点击青龙面板的依赖管理——&gt;新建依赖——&gt;选择NodeJs、自动拆分选择是、复制以下的依赖填到名称里——&gt;点击确定，等待安装完成。\n脚本自动(推荐)^[7]^如果有青龙日志分析 &amp;&amp; 自动补全依赖脚本的话, 可以在Configuration Files里面加一句代码解决.\n## QL_LOG_AUTO_INSTALL_DEPENDexport QL_LOG_AUTO_INSTALL_DEPEND=&quot;true&quot;\n\n如果有单容器 二叉树修复脚本依赖文件脚本的话, 可以在Configuration Files里面加一句代码解决.\n## export ec_fix_dep=&quot;true&quot;export ec_fix_dep=&quot;true&quot;\n\n手动别的可以自动安装, 但是requests需要手动.\n考虑到nas有进不去命令行的情况, 可以继续创建任务.\npip install requests\nCOOKIE获取最好是用wskey, 可以达到半永久效果.\nIOS抓包可以用stream.\n按引用[5]的步骤, 找到GET https://im-x.jd.com开头的链接，点进去往下滑，找到cookie里的pin和wskey，但是我只找到了wskey和pin_hash, 万幸经测试pt_pin和pin是等效的.\n结论引用\n【关闭】进阶教程：群晖Docker青龙面板ninja扫码搭建指南【ninja已下架】 - 知乎\n小白教程：群晖Docker青龙面板部署方法 - 知乎\nNotion – 青龙Faker仓库教程合集\n青龙必装依赖以及各种依赖问题解决方案！_青龙一键修复依赖环境_木子的白猫的博客-CSDN博客\n安卓抓取JD wskey + 添加脚本自动转换JD cookie_jd_wsck_Akashi_FD的博客-CSDN博客\n获取京东cookie（青龙面板，含各种库）_pq不会飞的博客-CSDN博客\n[青龙面板]依赖管理-一键安装&#x2F;免代码安装_青龙面板一键安装依赖_xiaojing_yu的博客-CSDN博客\n\n","categories":["Tech","docker"]},{"title":"Markdown 编辑器特点总结及推荐","url":"/2023/09/05/Tech/markdown/Markdown%E7%BC%96%E8%BE%91%E5%99%A8%E7%89%B9%E7%82%B9%E6%80%BB%E7%BB%93%E5%8F%8A%E6%8E%A8%E8%8D%90/","content":"引言Markdown 是一种轻量级的标记语言，简单易学，适用于各种场景，如写作、笔记、博客等。在选择 Markdown 工具时，需要根据自己的需求和使用习惯来选择适合自己的工具。以下是一些推荐：\n初学组\n语雀：适合富文本编辑习惯的 Markdown 编辑器。它的编辑器支持实时预览和实时语法高亮，所以即使你不熟悉 Markdown 语法也可以快速上手。此外，语雀还提供了云端存储和团队协作功能，非常适合团队合作写作。\n\nObsidian：输入简单的双链的本地 Markdown 笔记软件，特别适合喜欢使用笔记本和标签的人。Obsidian 有强大的链接和搜索功能，使得笔记间可以相互链接，从而构建知识网络。另外，Obsidian 的文档存储在本地，保证了安全性和隐私性。\n\n\n习惯组\nVS Code：强力插件全面辅助。VS Code 是一个功能强大的代码编辑器，它可以通过安装 Markdown 插件来支持 Markdown 语法。在编辑 Markdown 文件时，VS Code 可以提供实时预览、语法高亮、自动补全、代码折叠等功能，大大提高了工作效率。\n\n任何网页 Markdown 编辑器：网页 Markdown 编辑器是一种无需安装软件的 Markdown 编辑器，用户只需在浏览器中打开网站，就可以开始编辑 Markdown 文件。以下是一些值得推荐的网页 Markdown 编辑器：\n\nTelegraph：Telegraph 是一个简洁美观的 Markdown 编辑器，支持实时预览、语法高亮、自动保存等功能。它的最大特点是可以将编辑的内容直接发布到互联网上，非常适合写短文或者分享笔记。\n\n腾讯云开发者社区：腾讯云开发者社区是一个集成了 Markdown 编辑器的社交平台，用户可以在这里写文章、发布笔记、和其他开发者交流。编辑器支持实时预览、语法高亮、图片上传等功能。\n\n\n\n\n综上所述，选择适合自己的 Markdown 工具是非常重要的。初学者可以选择语雀和 Obsidian，而习惯使用 Markdown 的用户可以选择 VS Code 和任何网页 Markdown 编辑器，根据自己的需求和使用习惯来选择适合自己的工具。\n效果展示引用","categories":["Tech","markdown"],"tags":["叶子的神奇小软件","markdown"]},{"title":"tinyproxy","url":"/2024/04/25/Tech/luci/tinyproxy/","content":"引言效果展示过程路由器端内网ip: 192.168.1.1\n外网ip: 172.16.7.95\n/etc/init.d/tinyproxy restart\n\ncurl 192.168.1.1curl 172.16.7.95curl httpbin.org/ipcurl httpbin.org/ip --proxy http://192.168.1.1:8888curl httpbin.org/ip --proxy 192.168.1.1:8888 -kcurl httpbin.org/ip --proxy http://172.16.7.95:8888 -kexport https_proxy=http://192.168.1.1:8888 http_proxy=http://192.168.1.1:8888 all_proxy=http://192.168.1.1:8888export https_proxy=http://172.16.7.95:8888 http_proxy=http://172.16.7.95:8888 all_proxy=http://172.16.7.95:8888wget -O /dev/null http://speedtest.wdc01.softlayer.com/downloads/test10.zip\n\n服务器端ssh root@172.16.7.47 -p 22 -D 57890curl httpbin.org/ip --proxy http://10.9.65.32:57890\n\nBad Request实际成功了，但是没有请求相应的内容。\n结论引用\nTinyProxy status page not working - Installing and Using OpenWrt - OpenWrt Forum\n使用 TinyProxy 代理 - TheBadZhang’s Blog\n\n","categories":["Tech","luci"]},{"title":"VS Code 括号、引号的自动补全","url":"/2023/10/23/Tech/markdown/VS%20Code%20%E6%8B%AC%E5%8F%B7%E3%80%81%E5%BC%95%E5%8F%B7%E7%9A%84%E8%87%AA%E5%8A%A8%E8%A1%A5%E5%85%A8/","content":"引言效果展示过程/Applications/Microsoft/Visual Studio Code.app/Contents/Resources/app/extensions/markdown-basics/language-configuration.json\n\n结论引用\n\n\n","categories":["Tech","markdown"]},{"title":"为什么我要用 markdown 写 word","url":"/2023/03/21/Tech/markdown/%E4%B8%BA%E4%BB%80%E4%B9%88%E6%88%91%E8%A6%81%E7%94%A8markdown%E5%86%99word/","content":"引言当需要写长文档或者学术论文时，很多人会选择使用 Microsoft Word 这类传统的文字处理软件，但是使用 Markdown 写作后再将其转换成 Word 格式也是一种很不错的选择。\nWord 的优势在于表现形式丰富多样，也就是”富文本编辑”，但相对的带来了文档之间格式不统一，复制容易出错，字体、大小、颜色均容易出现各种各样的问题，当进行长文档写作就很容易出现写作十分钟，格式半小时的窘境。而 Markdown 恰恰相反，所有的格式将由内容和模板提供。作为内容和文本解离的成果，你可以尽情关注于写作本身。\n需要提醒的是，Markdown 并不适合所有人，AllinOne 式的工具观是不必要的，合适的场合用合适的工具是最高效且实用的。对于团队协作和同步写作来讲，十几 K 的 md 文档自然比几 M 的 Word 好上几个等量级，对于办公室办公来讲，天然 A4 纸的 Word 自然就比 md 适合打印。工具本身没有高下，但使用的场景决定了工具的价值。\n所以，十分钟就可以学会的 Markdown 教程，试一下？\n效果展示\n正文1. Markdown 的优势和 Word 的不便Markdown 的优势\n格式精准： Markdown 可以通过简单的语法实现精准的格式控制，从而使生成的 Word 文档保持原来的排版和格式。\n自带大纲： Markdown 支持使用 #、##、### 等符号来表示标题的级别，自带大纲功能可以方便地生成目录。\n代码可读性好： Markdown 支持代码块的语法，可以将代码片段以可读性好的形式展示在 Word 文档中。\n易于维护和修改： Markdown 的语法相对简单，文本文件也容易备份和管理，可以在不同的编辑器和平台上进行修改。\n\nWord 的不便\n排版不稳定： 在 Microsoft Word 中，即使在同一台电脑上使用同一个版本的软件，不同的文档在不同的电脑上打开也会出现格式错乱的情况，导致排版不稳定。\n版式难以复用： Word 文档中的版式很难被复用，需要手动逐个调整样式和格式。\n代码展示不佳： Word 文档中的代码块的展示不够美观，不利于代码的阅读和分享。\n难以协作： Word 文档通常需要通过电子邮件或者在线共享文档的方式进行协作，但是多人同时编辑同一个文档可能会导致格式错乱和版本混乱的问题。\n\n2. Markdown 的语法简单结构Markdown 是一种轻量级的标记语言，广泛应用于写作和发布文本内容。使用 Markdown，可以轻松地创建具有丰富排版样式的文本，而不必学习 HTML 或 CSS 等更复杂的语言。下面是有关 Markdown 语法使用的一些基本介绍。\n标题 Markdown 支持 6 种级别的标题，可以通过在行首添加 1 到 6 个#符号来表示，分别对应 H1 到 H6 的标题级别。例如：\n## 这是一个一级标题### 这是一个二级标题#### 这是一个三级标题\n\n这是一个一级标题这是一个二级标题这是一个三级标题段落和换行 Markdown 中，一个段落由一行或多行文本组成，每个段落之间用一个或多个空行隔开。如果想在同一段中换行，可以在行末添加两个空格符。\n强调和斜体 可以使用星号 ( * ) 或下划线 ( _ ) 来表示斜体和加粗样式。一个星号或下划线表示斜体，两个星号或下划线表示加粗。例如：\n_这是斜体文字_ _这也是斜体文字_**这是加粗文字** **这也是加粗文字*****这是加粗斜体文字***\n\n这是斜体文字 这也是斜体文字\n这是加粗文字 这也是加粗文字\n这是加粗文字\n链接 Markdown 中使用中括号 ( [] ) 来表示链接文字，紧随其后的圆括号 ( () ) 表示链接地址。例如：\n[Markdown 官方网站](https://daringfireball.net/projects/markdown/)\n\nMarkdown 官方网站\n图片和链接类似，Markdown 也支持插入图片。使用感叹号 ( ! ) 加中括号 ( [] ) 表示图片的替代文本，紧随其后的圆括号 ( () ) 表示图片的 URL 地址。例如：\n![](https://yeyezi-1258021402.cos.ap-nanjing.myqcloud.com/pic/2023-03-09-17-37-25-2.png)![](/img/为什么我要用markdown写word_2023-09-05-16-03-22.png)\n\n\n列表Markdown 支持有序和无序列表。无序列表使用星号 ( * )、加号 ( + ) 或减号 ( - ) 加空格表示，有序列表使用数字加句点 ( . ) 加空格表示。例如：\n无序列表-   项目 1-   项目 2-   项目 3\n\n\n项目 1\n项目 2\n项目 3\n\n有序列表1. 项目 12. 项目 23. 项目 3\n\n\n项目 1\n项目 2\n项目 3\n\n代码块如果您需要在 Markdown 中插入代码块，可以使用三个反引号 ( \\ \\ `) 表示代码块的开始和结束位置。您还可以在开始位置后添加代码块的语言类型，以便在呈现时高亮显示代码。例如\n\\```pythonprint(&quot;Hello World!&quot;)\\```\n\nprint(&quot;Hello World!&quot;)\n\n在md写作中, 添加代码块的语言类型是被鼓励的.\n引用在Markdown中，可以使用大于号(&gt;)来表示引用的文本。您还可以嵌套引用，只需添加更多的大于号即可。例如\n&gt; 这是一段引用文本。&gt;&gt; &gt; 这是一个嵌套的引用文本。\n\n\n这是一段引用文本。\n\n这是一个嵌套的引用文本。\n\n\n表格 Markdown中，可以使用竖线( | )和短横线( - )来表示表格的结构。在第一行中，使用竖线来分隔每个单元格，使用短横线来表示表头。在下一行中，使用竖线来分隔每个单元格，使用空格来表示单元格中的内容。不推荐使用，如有必要可使用excel编辑，使用插件自动输入md。\n代码和特殊字符 如果您需要在Markdown中插入代码或特殊字符，可以使用反斜线(`)来表示它们。例如：\n这是一段包含 `code` 的文本。\n\n这是一段包含 code 的文本。\n如果您需要在Markdown中插入星号或下划线等特殊字符，也可以使用反斜线来转义它们。例如：\n这是一段包含 \\`code 的文本。\n\n这是一段包含 `code 的文本。\nmd转word的方案Markdown是一种纯文本标记语言，它的优点在于它简单易学，易于阅读和编写。但是，如果您需要将Markdown格式的文档转换为Microsoft Word格式的文档，可能需要一些额外的工作。下面是几种将Markdown转换为Word的方案。\nPandocPandoc 是一个由John MacFarlane 开发的通用文档转换工具，可以支持大量标记语言之间的格式转换，例如Markdown 、Microsoft Word、PowerPoint、 Jupyter Notebook、HTML、PDF、LaTeX、Wiki、EPUB 格式之间的相互转换。\nPandoc支持将Markdown转换为多种格式，包括Word格式。Pandoc支持Windows、Mac OS X和Linux等多个操作系统。您可以使用以下命令将Markdown文件转换为Word文件：\npandoc input.md -o output.docx\n\n其中，input.md是您要转换的Markdown文件名，output.docx是生成的Word文件名。\nPandoc还支持设置样式和格式，可以使用LaTeX等排版工具来控制输出文件的样式和格式。\nMicrosoft Word的插件markdown转换器writage（Markdown plugin for Microsoft Word）\n在线转换工具Try pandoc!\nmd的高级用法md的编辑器Markdown是一种轻量级标记语言，不仅可以用于创建文档，还可以用于构建网页。本文将介绍Markdown在网页构建、CSS和LUA脚本等方面的高级用法。\n网页构建使用Markdown可以很容易地构建网页。通过Markdown语言，可以快速创建HTML代码。例如，下面是一个使用Markdown创建HTML代码的示例：\n## 这是一个标题这是一个段落。- 列表项 1- 列表项 2这是一个链接[点此进入](http://www.example.com)。\n\n将上述Markdown代码用pandoc保存为HTML文件，然后用浏览器打开，就可以看到一个网页了。\nCSSMarkdown本身并不包含CSS样式，但可以通过CSS来美化Markdown文档。通过CSS可以控制Markdown文档中的字体、颜色、边框等样式。下面是一个简单的CSS样式表示例：\nbody &#123;  font-family: Arial, sans-serif;  background-color: #f2f2f2;&#125;h1 &#123;  font-size: 24px;  color: #333;  border-bottom: 1px solid #ccc;&#125;\n\n将上述CSS样式保存为文件，并将其与Markdown文档一起使用，就可以让Markdown文档的样式更加美观。\nLUA脚本Markdown支持使用LUA脚本扩展其功能。使用LUA脚本可以实现一些高级功能，例如自动编号、目录生成等。下面是一个使用LUA脚本生成目录的示例：\nfunction header(elem)  if elem.level == 1 then    toc = &#123;&#125;    return pandoc.Header(elem.level, pandoc.List(toc))  elseif elem.level == 2 then    table.insert(toc, pandoc.ListItem(pandoc.Link(elem.content, &quot;#&quot; .. elem.identifier), pandoc.List()))  endend\n\n将上述 LUA 脚本保存为文件，并在命令行中使用 pandoc 转换 Markdown 文档时指定 LUA 脚本文件，就可以生成包含目录的 HTML 文件了。\n总之，Markdown 具有广泛的应用场景，特别是在网页制作方面。\nPandoc 模板简单的 Pandoc 模板如下，只需要导出一份标准模板而后自行修改即可，默认字段的格式自动生成为目标格式。利用这一点，可以创建一个易于复用的标准模板，便于统一每一份文稿的格式。\n如果想获得叶子的 Pandoc 模板，只需要在公众号输入 叶子的Pandoc模板 即可自动获得。\n实用的 Markdown 编辑器初学组\n语雀 (符合富文本编辑习惯的 Markdown 编辑器)\nObsidian(输入简单的双链的本地 Markdown 笔记软件)\n\n习惯组\nVS Code(强力插件全面辅助)\n任何网页 Markdown 编辑器\nTelegraph\n腾讯云开发者社区\n…\n\n\n\n结论从易用性来说，txt–&gt;Word–&gt;MD–&gt;LaTex,\n从表现力来说，LaTex–&gt;Word–&gt;MD–&gt;txt,\n从学习成本来说，txt–&gt;MD–&gt;Word–&gt;LaTex.\n总而言之，比起 Word 文档，Markdown 文档具有许多优点，包括更轻便、易于阅读和编辑、格式统一等。此外，Markdown 还有一些高级用法，可以进一步提升文档的质量和可读性，以完成高要求的复杂文本写作如论文等。\n明天作者将对论文写作书写一下自己的看法，后天会对软件进行讨论，尽请期待，谢谢各位。\n –&gt;符号代表优于，如 A–&gt;B 代表 A 优于 B.\n参考\n为什么用 Markdown，而不用 Word？ - 知乎\n关于 Markdown 的一点疑问，为什么很多人说 markdown 比 word 好用？ - 知乎\nChatGPT\n\n","categories":["Tech","markdown"],"tags":["markdown","ms-word","pandoc"]},{"title":"pandoc 转换 markdown 为自定义样式的 pdf","url":"/2024/01/17/Tech/markdown/pandoc%20%E8%BD%AC%E6%8D%A2%20markdown%20%E4%B8%BA%E8%87%AA%E5%AE%9A%E4%B9%89%E6%A0%B7%E5%BC%8F%E7%9A%84%20pdf/","content":"引言效果展示过程结论引用\nmacOS 环境下使用 pandoc 转换 markdown 为自定义样式的 pdf - 少数派\npython 之 xhtml2pdf: HTML 转 PDF 工具示例详解_python xhtml2pdf-CSDN 博客\n\n","categories":["Tech","markdown"]},{"title":"如何用 Markdown 写毕业论文","url":"/2023/03/21/Tech/markdown/%E5%A6%82%E4%BD%95%E7%94%A8Markdown%E5%86%99%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87/","content":"引言上一回说道，Markdown 可以使用一些高级用法进一步提升文档的质量和可读性，以完成高要求的复杂文本写作如论文等。\n那么，为什么我们需要用 Markdown 来写论文呢？\n先总结一下毕业论文的特点：\n\n文本量大，需要几十页甚至几百页\n格式要求完全统一，每种段落都有自己的特有格式\n图表均需要带有序号，并随章节次序动态调整\n参考文献角标编号随顺序调整\n…\n\n那么，Word 可以为我们带来哪些呢？\n\n所见即所得\n样式模板设置各级标题及正文\n自动生成目录\n结合文献管理器自动生成参考文献列表及角标\n页面设置及输出 PDF\n…\n\n看起来还不错，但是相应存在的问题是「易分心」和「易崩溃」。分段式的写作调整格式将会成为噩梦，一切超出输入时预想的格式修改，都将消耗掉成倍的时间与精力。一旦输入时没有规范好，写完之后掉过头来修改都会让难度指数式上升。而输入和排版同时进行加大了文件的复杂度，在保存耗时增加的同时使程序易于崩溃，而且在崩溃之后往往无法修复，版本控制也因此变得一团糟。\n最令人烦躁的是，当你用 Word 和别人协作的时候，Word 本身就足以成为灾难。以参考文献引用为例，如果你不把 Mendeley 或者 Zotero 的文献库页同步给对方，那么自动生成的标记大概率就会面目全非。\n另外还有，无法修改的表格框，因图片而全部被挤到下一页的正文，因富文本粘贴而改变的字体、字号，不知所起的自动编号，不知所云的空格添加，莫名其妙的错误提示，一切的一切都是因为 Word 所见即所得的功能。\n所谓成也萧何，败也萧何。Word 归根结底是一个文字编辑软件，而不是一个排版软件，无法做到所见及所得模式下输入和排版的结合。因此，就算不提编辑时”顺眼”的问题，单从实用性的角度，至少 Word 不是一个适用于长文本输入的软件。\n既然提到排版和论文写作，怎么可以不提一下 LaTeX 呢？LaTeX 作为极专业的排版软件，可以满足一切你对排版的需求，文本和格式完全分离带来了输入时的”沉浸”体验，对科技类期刊投稿只需要换一个模板而不需要编辑内容，同时 overleaf 堪称最强团队协作软件，免去了本地配置的烦恼，做到了 LaTeX 的开箱即用。\n那么，为什么不用 LaTex？\n\n学习成本高\n如找不到对应的模板难以自行设计\n国内期刊很少提供 LaTeX 模板\nlatex 的本地环境配置难\n不能转换成 word\n…\n\n说了这么多，比起 Word 或 LaTex, Markdown 又有什么独特的优势呢？\n\n语法简单\n便于版本控制\n实时保存，不易崩溃\n可转换成 Word 对排版进行补全\n\n而最大的优点是：\n来，跟我一起念！\n计算机永远不会错！\n复制粘贴永远不会错！\n自动生成永远不会错！\n当然，如果真出了错，那肯定只能是我自己的错……\n效果展示今天重点介绍发布于 github 的 nju-thesis-markdown 项目，作者是 centixkadon.\n功能特色\n可排版硕士、学士学位论文（学士论文封面、摘要暂未直接生成）；\n相比 LaTeX 简单多了，兼顾文本文件的版本控制和 Microsoft Word 的编辑功能；\n导出的 docx 文件用书签和域来引用，插入图、表、公式导致的编号变化可以直接更新；\n导出的 docx 文件可以给不使用 LaTeX 的导师修改；\n功能不足的地方可以导出 docx 文件后用 Microsoft Word 补足。\n\n图例输入文件\n源文件\n过程首先使用 git clone 将仓库克隆到本地。\n## sandy @ sandys-Mac-mini in ~ [15:35:29]$ cd /Users/sandy/Downloads## sandy @ sandys-Mac-mini in ~/Downloads [15:35:33]$ git clone https://github.com/centixkadon/nju-thesis-markdown.gitCloning into &#x27;nju-thesis-markdown&#x27;...remote: Enumerating objects: 202, done.remote: Counting objects: 100% (202/202), done.remote: Compressing objects: 100% (119/119), done.remote: Total 202 (delta 103), reused 173 (delta 77), pack-reused 0Receiving objects: 100% (202/202), 828.64 KiB | 3.14 MiB/s, done.Resolving deltas: 100% (103/103), done.\n\n进入目录 nju-thesis-markdown/thesis 并使用命令 pandoc --lua-filter ../src/thesis.lua --citeproc sample.md --reference-doc nju-thesis-reference.docx --output sample.docx .\nWindows 为 /path/to/pandoc.exe --lua-filter ../src/thesis.lua --citeproc sample.md --reference-doc nju-thesis-reference.docx --output sample.docx , 在 powershell 或 cmd 中输入，其中 /path/to/pandoc.exe 代表 pandoc 的位置。\n## sandy @ sandys-Mac-mini in ~/Downloads [15:35:40]$ cd ./nju-thesis-markdown/thesis## sandy @ sandys-Mac-mini in ~/Downloads/nju-thesis-markdown/thesis on git:master o [15:38:01] C:127$ pandoc --lua-filter ../src/thesis.lua --citeproc sample.md --reference-doc nju-thesis-reference.docx --output sample.docx\n\n结论总之，Markdown 不一定是最好的模式，但可以给你一个新的选择。\nLife is short, you need Markdown.\n报错all choices failed根据lua crash when checking equality of built-in objects #8267|github, 应该是版本过老，出现了未修复的 bug.\n引用\nGitHub - centixkadon&#x2F;nju-thesis-markdown: 南京大学学位论文排版工具 (硕士&#x2F;本科) - Life is short, you need Markdown.\n学术论文写作新武器：Markdown-上篇 | 连享会主页\n如何用 Markdown 写论文？ - 少数派\n\n","categories":["Tech","markdown"],"tags":["markdown","ms-word","pandoc"]},{"title":"Hexo+云服务器构建简易不失效图床","url":"/2023/04/29/Tech/hexo/Hexo+%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E6%9E%84%E5%BB%BA%E7%AE%80%E6%98%93%E4%B8%8D%E5%A4%B1%E6%95%88%E5%9B%BE%E5%BA%8A/","content":"引言目前我的公众号发布流程都是把图片通过 PicGo 上传到 腾讯云COS 上面，再通过链接的方式转存到腾讯云开发者社区和公众号上。\n但是这样面临两个问题：\n第1，是腾讯云COS是收费的，每次上传和引用都是需要付费的。\n第2，如果将来脱离腾讯云COS的话，这些链接就会失效，无法访问。\n因此，综合考虑的话，将图片直接存到本地是一个收益比较高的方式。\n具体流程如下：\n在本地写，然后将图片存在 /source/img/ 文件夹里面。然后直接上传到服务器。这样将会获得一个类似于 https://yeyeziblog.eu.org/img/img.png 的可用链接。\n通过这样的方式就可以实现 markdown 文本编辑时查看图片和获得链接的功能，需要的软件是 vs code 的插件和 Hexo 。\n另外, 如需将 Markdown 文件上传到 Markdown Nice 之类的软件的时候需要将图片链接手动添加上自己的网址。\n效果展示\n\n过程vs code - Paste Image 设置下载 Paste Image 插件并根据官方提示将以下代码录入 setting.json 即可。\n&quot;pasteImage.namePrefix&quot;: &quot;$&#123;currentFileNameWithoutExt&#125;_&quot;,&quot;pasteImage.path&quot;: &quot;$&#123;projectRoot&#125;/source/img&quot;,&quot;pasteImage.basePath&quot;: &quot;$&#123;projectRoot&#125;/source&quot;,&quot;pasteImage.forceUnixStyleSeparator&quot;: true,&quot;pasteImage.prefix&quot;: &quot;/&quot;\n\n作用:\n将图片直接复制入 projectRoot 目录下的 /source/img 中, 命名为编辑文件名+时间, 如: 趣闻收集202304_2023-04-28-20-47-08 .\n上传至服务器注: 无需安装 hexo 插件.\n服务器命令git init yeyeziblog.git --bare --sharedcd yeyeziblog.gitcat &gt; hooks/post-receivegit --work-tree=/www/wwwroot/simpread.yeyeziblog.eu.org --git-dir=/home/tenney/git/simpread.git checkout -f mastercat hooks/post-receivechmod +x hooks/post-receive\n\n本地更改配置文件deploy:  type: git  repo: ssh://tenney@107.175.142.245:22/home/tenney/git/yeyeziblog.git  branch: master\n\n上传脚本#!/bin/bashSHELL_FOLDER=$(cd &quot;$(dirname &quot;$0&quot;)&quot;;pwd)echo $SHELL_FOLDERcd $SHELL_FOLDERhexo cleanhexo g &amp;&amp; hexo d\n\n修改图片链接上传之后在对所有 (/img/ 进行搜索, 并修改为 (https://yeyeziblog.eu.org/img/ 相似的格式.\n结论无论出现多少好用的工具，以本地文件形式保存大概率都是最自由和安全的，我们需要努力的地方是使其更加便捷。\n引用\nPaste Image - Visual Studio Marketplace\nvsc-markdown-image&#x2F;README.zh-cn.md - GitHub\nhexo插入图片并排 插入jpg，png，gif - 简书\n\n","categories":["Tech","hexo"],"tags":["Hexo","wscode-extensions","Markdown","图床"]},{"title":"Hexo-butterfly 增加评论系统：Gittalk","url":"/2023/11/25/Tech/hexo/Hexo-butterfly%E5%A2%9E%E5%8A%A0%E8%AF%84%E8%AE%BA%E7%B3%BB%E7%BB%9F/","content":"引言有时候还是想要评论区的…\n效果展示\n过程创建 OAuth Application如果没有，点击这里申请\n过程中，Authorization callback URL 填写当前使用插件页面的域名。\n在 Hexo-butterfly 中增加在themes/butterfly/_config.yml或source/_data/_config.butterfly.yml中编辑 gitalk 字段。\ncomments:  use: Gitalk # Valine,Disqus# gitalk# https://github.com/gitalk/gitalkgitalk:  client_id: ...\n\n必填的有clientID&#x2F;clientSecret&#x2F;repo&#x2F;owner&#x2F;admin五个。\nrepo 可以用已有的，也可以新建。\n授权上传后，在文章页面点击登录授权。\n结论挺方便的，好用。\n引用\nHexo-butterfly 评论系统配置：Gittalk_hexo butterfly 免费评论-CSDN 博客\ngitalk&#x2F;readme-cn.md | github\nGitHub - jerryc127&#x2F;hexo-theme-butterfly: 🦋 A Hexo Theme: Butterfly\n\n","categories":["Tech","hexo"]},{"title":"butterfly 主题自定义修改","url":"/2023/12/01/Tech/hexo/butterfly%E4%B8%BB%E9%A2%98%E8%87%AA%E5%AE%9A%E4%B9%89%E4%BF%AE%E6%94%B9/","content":"引言效果展示过程双栏布局参考[1]\n使用npm i hexo-butterfly-article-double-row --save下载并对根目录_config 配置项添加以下代码即可。感谢大佬啊…\nbutterfly_article_double_row:  enable: true\n\n结论引用\n教程：butterfly 主题文章双栏布局插件 | 小冰博客\n\n","categories":["Tech","hexo"],"tags":["双栏布局"]},{"title":"hexo 增加 google AdSense 广告","url":"/2024/02/21/Tech/hexo/hexo%20%E5%A2%9E%E5%8A%A0%20google%20AdSense%20%E5%B9%BF%E5%91%8A/","content":"引言本着蚊子再小也是肉原则，也有看一下真实访问量的想法，加一个广告试试。\n效果展示\n\n\n\n     (adsbygoogle = window.adsbygoogle || []).push({});\n\n\n过程注册谷歌广告https://www.google.com/adsense/\n添加 ads.txt光说验证的话其实添加 ads.txt 比较简单，请务必确定是 ads.txt 而不是 Ads.txt, 因为在不区分大小写的系统里面如果第一次上传了 Ads.txt 之后是不会被覆盖掉的，会导致验证失败。\n新建一个 ads.txt 文件，内容示例如下：\ngoogle.com, pub-**68719829292929, DIRECT, f08c47fec0942fa0\n\n然后上传到博客的 source 文件夹下。\n修改主题配置文件使用的是 Hexo 的谷歌广告插件[2]，用途说明：\n支持使用 Hexo 自定义标签将谷歌广告代码动态插入到指定的文章的特定位置中，广告类型一般是谷歌的文章内嵌广告，但也支持谷歌其他类型的广告。\n使用步骤\n\n安装插件：npm install hexo-google-adsense --save\n编辑 Hexo 的 _config.yml 配置文件，添加对应的插件配置信息\n在本地或网络上创建存放谷歌广告代码的文件，并拷贝谷歌的广告代码到文件中\n编辑 Hexo 的 MarkDown 文件，在希望添加谷歌广告的地方，增加右边这行内容即可： &#123;% GoogleAdsense %&#125;\n\n提示： &#123;% GoogleAdsense %&#125; 中的 GoogleAdsense 是 Hexo 自定义标签默认的名称\n配置示例\nhexo_google_adsense:  enable: true  log_msg: true  tag_name: &#x27;GoogleAdsense&#x27;  file_path: &#x27;source/ads/google/article_ads.html&#x27;\n\n参数说明\n\nenable：是否启用插件，默认值为：false\nlog_msg：是否打印日志信息，默认值为：false\ntag_name：Hexo 自定义标签的名称，默认值为：GoogleAdsense\nfile_path：谷歌广告代码文件的路径，支持使用绝对路径或者相对于 Hexo 博客根目录的路径（例如：source&#x2F;ads&#x2F;google&#x2F;article_ads.html），同时支持使用 URL 路径（例如：https://www.example.com/ads/google/article_ads.html）\n\n注意事项\n根据谷歌官方的要求，使用此插件时必须在 Hexo 主题的模板文件中的 Head 标签内添加如下的一行代码（请自行替换掉 xxxx）：\n&lt;head&gt;  &lt;script data-ad-client=&quot;xxxx&quot; async src=&quot;https://pagead2.googlesyndication.com/pagead/js/adsbygoogle.js&quot;&gt;&lt;/script&gt;&lt;/head&gt;\n\n待优化功能目前只支持在 Hexo 的 _config.yml 文件中配置单一类型的谷歌广告，后续考虑结合 Hexo 自定义标签的参数，支持在不同的文章中插入不同类型的广告。\n结论引用\nHexo Next 接入 google AdSense 广告 - 腾讯云开发者社区 - 腾讯云\nGitHub - rqh656418510&#x2F;hexo-google-adsense: hexo tag plugin for google adsense\nHexo 博客添加 Google Adsense ads.txt - Alan Lee\n\n","categories":["Tech","hexo"]},{"title":"使用 VSCode + Joplin 作为笔记工具","url":"/2023/10/22/Tech/markdown/%E4%BD%BF%E7%94%A8%20VSCode%20+%20Joplin%20%E4%BD%9C%E4%B8%BA%E7%AC%94%E8%AE%B0%E5%B7%A5%E5%85%B7/","content":"引言效果展示过程结论引用\n使用 VSCode + Joplin 作为笔记工具\n\n","categories":["Tech","markdown"]},{"title":"利用单端口代理多个服务和使用 ssh 创建代理访问校园网","url":"/2024/01/20/Tech/nginx/%E5%88%A9%E7%94%A8%E5%8D%95%E7%AB%AF%E5%8F%A3%E4%BB%A3%E7%90%86%E5%A4%9A%E4%B8%AA%E6%9C%8D%E5%8A%A1/","content":"引言我实在是馋学校的 vpn, 所以决定搞一搞内网穿透。\n关于校外使用不在 vpn 白名单端口的方式，可以只查看：二级标题 - 校外使用服务器服务方法。\n关于利用单端口代理多个服务的使用方式，可以只查看：二级标题 - 单端口代理多个服务过程。\n效果展示\n校外使用服务器服务方法目前有两种方案。\n一种是自搭的 zerotier 服务，效果是把电脑拉到一个局域网，然后重新分配一个 ip 号，好处是软件很轻型，很适合把自己的设备全拉进去，但是缺点是不适合团队使用，而且偶尔会不稳定。\n另一个是学校买的软件 easyconnect, 效果是创造一个 vpn 可以直接连上校内服务，但是学校服务器只有用来 ssh 的 22 端口能用。\nEasyConnect + ssh根据第二种方案，连接 ssh 创造一条自建隧道，就可以使用服务器的网络上网了，自然就可以连接 22 以外的服务了。\n通过 SSH 隧道在 EasyConnect VPN 上实现不受限制的访问 - Nativus’ Space\n\nSSH，安全外壳协议，应该大家都用过，但大部分情况下只是使用它连接远程的 Shell。这里我们利用他的另一个特性，实现隧道。\n-D $ProxyPort 指定 SSH 在本地开启的端口。我们后面通过这个端口开启的代理实现无限制的访问。\n\n完整代码如下（注意将命令中的信息替换为自己的）：\nProxyPort=57890User=tenneyHost=10.9.65.31RemoteSSHPort=22# unset all_proxy &amp;&amp; unset ALL_PROXY# ssh -o &quot;ProxyCommand=ncat --proxy-type socks5 --proxy 127.0.0.1:22 %h %p&quot; -D $ProxyPort $User@$Host -p $RemoteSSHPortssh $User@$Host -p $RemoteSSHPort -D $ProxyPort\n\n注意：\n\nProxyPort 是本机打开用于连接的 socks5 代理\nUser, Host, RemoteSSHPort 是目标服务器的 ssh 信息\n原文使用的是 docker 版本的 EasyConnect 所以需要使用-o 参数跳板登录，非必须。\n\n连接代理上网两种方案，一种是使用浏览器插件，一种是直接设置系统代理。\n浏览器插件配置 SwitchyOmega 实现网页访问，在谷歌浏览器下载插件 SwitchyOmega, 并新建情景模式，如图：\n\n图中的 57890 即为刚刚设置的 $ProxyPort。\n使用的方式是在目标网页点击插件，选择创建的目标代理。\n\n系统代理各系统大同小异，都在网络设置里面，注意选择 socks5 代理。\n在设置了代理之后，就等于使用服务器的网络进行连接，自然就可以使用服务器服务了。\n单端口代理多个服务过程[1-6]首先，单端口代理多个服务成功了，但是学校提供的 vpn 并不支持直接 http 协议转发，所以本部分无实际意义，可以跳过。\n学校的 EasyConnect 只开通了 22 端口，所以难点有两个，一是在 22 端口实现多服务反向代理，二是浏览器访问 22 端口。\n我很懒，所以我创建网页和反向代理是通过 1panel 直接添加的，然后自己再改细节。1panel 使用的是 OpenResty, 和 nginx 配置方式一致。\n本部分演示服务器 ip 地址为 10.9.65.33，ssh 端口已修改为 50022。\n主配置在 nginx 主配置中将 stream 块添加到与 http 同级的部分以代理 tcp 流量。注意 upstream 和 proxy_pass 后的词需要保持一致。stream 块的作用是把 80 端口的所以流量代理到 22 端口。\n1panel 配置修改方式：网站 - 网站 - 设置 - 配置修改。\nstream&#123;    upstream http&#123;        server 10.9.65.33:80 max_fails=2 fail_timeout=5s weight=2;    &#125;    server&#123;        listen 22; # 任意不占用的端口        proxy_connect_timeout 10s;        proxy_timeout 300s;        proxy_pass http; # 注意写法，不带 http://    &#125;&#125;\n\n反向代理网站搭建主域名：10.9.65.33\n代理地址：10.9.65.33:8787\n网站配置文件部分展示：\nserver &#123;    listen 80 ;    server_name 10.9.65.33;\n\n1panel 配置修改方式：网站 - 网站 - 创建网站 - 反向代理。\nRStudio serverslocation ^~ / &#123;    proxy_pass http://10.9.65.33:8787/;    proxy_set_header Host $host;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    proxy_set_header REMOTE-HOST $remote_addr;    proxy_set_header Upgrade $http_upgrade;    proxy_set_header Connection &quot;upgrade&quot;;    proxy_set_header X-Forwarded-Proto $scheme;    proxy_http_version 1.1;    add_header Cache-Control no-cache;&#125;\n\n浏览器设置[7]因 22 端口属于安全端口，一般浏览器默认禁用访问，推荐使用火狐 (firefox) 浏览器。\n打开 firefox 浏览器，在地址栏输入about:config,搜索network.security.ports.banned.override, 点击添加，选择string, 输入22-10000.\n登录而后地址栏输入http://10.9.65.33:22/即可。\n如显示 OpenResty 默认窗口可尝试多关掉刷新几次或使用http://10.9.65.33/auth-sign-in试试。\nhexo 博客因为只有一个端口可以使用，所以一看是的设想是使用:22/r访问 RStudio servers, 使用:22/server访问其他的应用，但是由于二级路径转不明白，就直接使用:22/(根) 来代理 RStudio servers 了。但是依然在探索的过程中明白了一些 nginx 的应用。比如使用:22/zhishanc204来代理其他服务器搭建的博客。\n最主要的部分在于前端请求路径和后端代理地址的对应关系。\n匹配规则统一用^~就可以，但两种路径最好的/非常重要，简单的说 nginx 发送到后端的地址是会将前端请求路径替换为后端代理地址进行请求。因此关于/的规则是：\n\n可以都不带\n可以都带\n可以上面带下面不带\n不能上面不带下面带\n\nlocation ^~ /zhishanc204/ &#123;    proxy_pass http://10.9.65.31:80/;    proxy_set_header Host $host;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    proxy_set_header REMOTE-HOST $remote_addr;    proxy_set_header Upgrade $http_upgrade;    proxy_set_header Connection &quot;upgrade&quot;;    proxy_set_header X-Forwarded-Proto $scheme;    proxy_http_version 1.1;    add_header Cache-Control no-cache;&#125;location ^~ /202 &#123;    proxy_pass http://10.9.65.31:80/202;    proxy_set_header Host $host;    proxy_set_header X-Real-IP $remote_addr;    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;    proxy_set_header REMOTE-HOST $remote_addr;    proxy_set_header Upgrade $http_upgrade;    proxy_set_header Connection &quot;upgrade&quot;;    proxy_set_header X-Forwarded-Proto $scheme;    proxy_http_version 1.1;    add_header Cache-Control no-cache;&#125;\n\n最后，因为没啥用所以把 22 代理了 50022 继续 ssh, 把 80 代了一下 50204，但是 80 还是继续使用，所以直接打开 10.9.65.33 也可以看到 RStudio-servers 的内容。\n结论总之玩了一天我还挺开心的，对 nginx 和 ssh 的理解都加深了一层。\n引用\nopenresty(nginx) 配置 stream 转发 - 哈喽哈喽 111111 - 博客园\nNginx 反向代理 TCP 协议【反代 SSH 端口】 - 知乎\nNginx 增加二级目录的反向代理时，最常见的两个问题 - 知乎\nNginx 路由转发和反向代理 location 配置「建议收藏」- 腾讯云开发者社区 - 腾讯云\n如何解决 Nginx 实现动静分离或反向代理时资源路径不匹配 - 知乎\nNginx 反向代理之路径替换 - 钟小嘿 - 博客园\n解决火狐浏览器的（此网址已被限制，此网址使用了一个通常用于网络浏览以外目的的端口，出于安全原因，Firefox 取消了该请求）问题\nDownload the Free Nmap Security Scanner for Linux&#x2F;Mac&#x2F;Windows\nNcat 跨网络读写数据 - 知乎\n利用 SSH 搭建隧道 - 流量伪装 - 知乎\nMAC  VsCode 跳板机 远程连接服务器_vscode 跳板机连服务器 macos-CSDN 博客\n\n","categories":["Tech","nginx"],"tags":["ssh","nginx","EasyConnect"]},{"title":"hexo 添加搜索 - algolia","url":"/2023/11/27/Tech/hexo/hexo%E6%B7%BB%E5%8A%A0%E6%90%9C%E7%B4%A2%20-%20algolia/","content":"引言效果展示过程获取 api KEYhttps://dashboard.algolia.com/account/api-keys/\n安装插件npm install --save hexo-algolia\n上传脚本export HEXO_ALGOLIA_INDEXING_KEY=&quot;&quot;# hexo  hexo cleanhexo algoliahexo g  &amp;&amp; hexo d\n\n结论引用\nHexo 集成 Algolia 实现搜索功能_hexo-algoliasearch_Baret-H 的博客-CSDN 博客\n\n","categories":["Tech","hexo"]},{"title":"hexo添加友链","url":"/2023/11/24/Tech/hexo/hexo%E6%B7%BB%E5%8A%A0%E5%8F%8B%E9%93%BE/","content":"引言想给自己添加一些常用的网站。\n效果展示过程我使用的是Butterfly主题，所以自带了添加功能。\n\n使用hexo new page link添加页面\n为source/link/index.md元数据添加type: &quot;link&quot;\n创建source/_data/link.yml以自定义链接\n取消themes/butterfly/_config.yml中menu:Link的注释\n\n结论引用\nButterfly 安裝文檔 (二) 主題頁面 | Butterfly\n给butterfly添加不一样的友链 | 安知鱼\n\n","categories":["Tech","hexo"]},{"title":"hexo-vscode-pandoc","url":"/2023/04/30/Tech/hexo/hexo-vscode-pandoc/","content":"引言使用了 Hexo+云服务器构建简易不失效图床 的技巧后，发现无法使用 pandoc 导出了。于是修理。\n效果展示过程pandoc&quot;pandoc.docxOptString&quot;: &quot;--reference-doc=/Users/sandy/.local/share/pandoc/templ.docx --resource-path=/Users/sandy/ResilioSync/ResilioSync/Documents/github/yeyeziblog/source/&quot;,\n\n--resource-path= 是指定图片目录用的。另外，可以使用 : 分隔来输入多个目录。\nvs code - Paste Image 设置对 Paste Image 插件官方提示代码修改。\n&quot;pasteImage.prefix&quot;: &quot;/&quot;\n\n&quot;pasteImage.prefix&quot;: &quot;/&quot;\n\n结论pandoc 命令行还是得学。\n另外， pandoc 默认输出到本地文件夹，但 docx 并不会被 hexo 上传，可放心传入。\n引用","categories":["Tech","hexo"],"tags":["Hexo","wscode-extensions","Markdown","图床"]},{"title":"JavaScript脚本书签","url":"/2023/06/18/Tech/javascript/JavaScript%E8%84%9A%E6%9C%AC%E4%B9%A6%E7%AD%BE/","content":"引言效果展示过程示例javascript: alert(&quot;你执行了一个书签JS脚本！&quot;);\n\n无敌风火轮javascript:R=0; x1=.1; y1=.05; x2=.25; y2=.24; x3=1.6; y3=.24; x4=300; y4=200; x5=300; y5=200; DI=document.getElementsByTagName(&quot;img&quot;); DIL=DI.length; function A()&#123;for(i=0; i-DIL; i++)&#123;DIS=DI[ i ].style; DIS.position=&#x27;absolute&#x27;; DIS.left=(Math.sin(R*x1+i*x2+x3)*x4+x5)+&quot;px&quot;; DIS.top=(Math.cos(R*y1+i*y2+y3)*y4+y5)+&quot;px&quot;&#125;R++&#125;setInterval(&#x27;A()&#x27;,100); void(0);\n\n依次加载图片javascript: const images = document.querySelectorAll(&#x27;img&#x27;); let i = 0; const scrollInterval = setInterval(() =&gt; &#123; if (i &gt;= images.length) &#123; clearInterval(scrollInterval); return; &#125; images[i].scrollIntoView(); i++; setTimeout(() =&gt; &#123; console.log(`Waited 1 second for image $&#123;i&#125;`); &#125;, 1000); &#125;, 2000);\n\n结论引用\n【JS】把JavaScript脚本作为书签收藏起来并可单击执行_书签执行js_想去潘达利亚的Bush的博客-CSDN博客\n可添加至收藏夹并在浏览器地址栏运行的JS代码 - 景北斗 - 博客园\n\n","categories":["Tech","javascript"]},{"title":"论文中使用的 word 小技巧","url":"/2023/11/04/Tech/office/%E8%AE%BA%E6%96%87%E4%B8%AD%E4%BD%BF%E7%94%A8%E7%9A%84%20word%20%E5%B0%8F%E6%8A%80%E5%B7%A7/","content":"向整个文档添加行号在 “布局” 选项卡上的 “页面设置” 组中，单击 “行号”。\n“页面设置” 组中的行号\n注意：如果您的文档分为多个部分，并且您希望为整个文档添加行号，首先需要选择该文档。在 “开始” 选项卡上的 “编辑” 组中单击 “选择”，然后单击 “全选”。或按 CTRL + A。\n执行下列操作之一：\n若要在整个文档中连续编号，请单击 “连续”。\n若要从每页上的数字 1 开始，请单击 “重新开始每一页”。\n若要在每个分节符后开始编号，请单击 “每节重新编号”。\n有关更多高级行编号选项（如以不同间隔编号），请单击 “行号选项”，然后单击 “布局” 选项卡上的 “行号”。\n","categories":["Tech","office"],"tags":["论文","word"]},{"title":"去除 Excel 和金山在线表格的工作表保护密码","url":"/2023/11/27/Tech/office/%E5%8E%BB%E9%99%A4Excel%E5%92%8C%E9%87%91%E5%B1%B1%E5%9C%A8%E7%BA%BF%E8%A1%A8%E6%A0%BC%E7%9A%84%E5%B7%A5%E4%BD%9C%E8%A1%A8%E4%BF%9D%E6%8A%A4%E5%AF%86%E7%A0%81/","content":"引言很尴尬的忘记了金山在线文档的工作表保护密码，但是因为已经设置好权限了，没法下下来去除密码。\n效果展示过程vba打开 vba 编辑器，在需要解除的 sheet 上右键，选择插入 - 模块，输入代码。\nSub PasswordBreaker()Dim i As Integer, j As Integer, k As IntegerDim l As Integer, m As Integer, n As IntegerDim i1 As Integer, i2 As Integer, i3 As IntegerDim i4 As Integer, i5 As Integer, i6 As IntegerOn Error Resume NextFor i = 65 To 66: For j = 65 To 66: For k = 65 To 66For l = 65 To 66: For m = 65 To 66: For i1 = 65 To 66For i2 = 65 To 66: For i3 = 65 To 66: For i4 = 65 To 66For i5 = 65 To 66: For i6 = 65 To 66: For n = 32 To 126ActiveSheet.Unprotect Chr(i) &amp; Chr(j) &amp; Chr(k) &amp; _Chr(l) &amp; Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; Chr(i3) &amp; _Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)If ActiveSheet.ProtectContents = False ThenMsgBox &quot;One usable password is &quot; &amp; Chr(i) &amp; Chr(j) &amp; _Chr(k) &amp; Chr(l) &amp; Chr(m) &amp; Chr(i1) &amp; Chr(i2) &amp; _Chr(i3) &amp; Chr(i4) &amp; Chr(i5) &amp; Chr(i6) &amp; Chr(n)Exit SubEnd IfNext: Next: Next: Next: Next: NextNext: Next: Next: Next: Next: NextEnd Sub\n\n点击运行，得到一串字母，不是原密码，但是能用，神！\n结论引用\nHow to Unprotect an Excel Sheet or Workbook With or Without Password\n\n","categories":["Tech","office"]},{"title":"BiliBiliToolPro","url":"/2024/01/07/Tech/qinglong/BiliBiliToolPro/","content":"引言效果展示过程结论篇外GitHub 加速拉库时，如果服务器在国内，访问 GitHub 速度慢，可以在仓库地址前加上 https://ghproxy.com/ 进行加速，如：ql repo https://ghproxy.com/https://github.com/RayWangQvQ/BiliBiliToolPro.git &quot;bili_task_&quot;\n引用\nBiliBiliToolPro&#x2F;qinglong&#x2F;README.md\n\n","categories":["Tech","qinglong"]},{"title":"基于 selenium 的动态网页爬虫服务器版","url":"/2024/01/25/Tech/python/%E5%9F%BA%E4%BA%8Eselenium%E7%9A%84%E5%8A%A8%E6%80%81%E7%BD%91%E9%A1%B5%E7%88%AC%E8%99%AB%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%89%88/","content":"引言虽然尝试了，但是最后大概还是 X11 的问题，只能在有图形化的界面运行，无图形化的命令行连无头浏览器都无法运行。所以我寻思着，要么就用 X11 转发，要么远程操控 (虽然有点奇怪但是这就算简单的).\n过程安装依赖# Prerequisitessudo apt install -y unzip xvfb libxi6 libgconf-2-4sudo apt install default-jdk# Install Google Chrome## export https_proxy=http://10.9.65.31:7890 http_proxy=http://10.9.65.31:7890 all_proxy=http://10.9.65.31:7890sudo curl -sS -o - https://dl-ssl.google.com/linux/linux_signing_key.pub | apt-key add## sudo curl -sS -o - https://dl-ssl.google.com/linux/linux_signing_key.pub -x http://10.9.65.31:7890 | apt-key addsudo bash -c &quot;echo &#x27;deb [arch=amd64] http://dl.google.com/linux/chrome/deb/ stable main&#x27; &gt;&gt; /etc/apt/sources.list.d/google-chrome.list&quot;sudo apt -y updatesudo apt -y install google-chrome-stablegoogle-chrome --version# Installing ChromeDriverwget https://edgedl.me.gvt1.com/edgedl/chrome/chrome-for-testing/121.0.6167.85/linux64/chromedriver-linux64.zipunzip chromedriver-linux64.zipsudo mv chromedriver-linux64 /usr/bin/chromedriversudo chown root:root /usr/bin/chromedriversudo chmod +x /usr/bin/chromedriver## apt install chromium-chromedriverchromedriver -v\n\njava 版安装# Download Required Jar Fileswget http://selenium-release.storage.googleapis.com/4.0/selenium-server-standalone-4.0.0-alpha-2.jarmv selenium-server-standalone-4.0.0-alpha-2.jar selenium-server-standalone.jar# Start Chrome via Selenium Serverxvfb-run java -Dwebdriver.chrome.driver=/usr/bin/chromedriver -jar selenium-server-standalone.jar\n\n安装 python 版pip install -U selenium\n\nchrome试过了，能打开但是不管啥用…\n# chrome --no-sandbox --remote-debugging-port=13888  --user-data-dir=/data/chrome/13888 --ignore-certificate-errorsgoogle-chrome --no-sandbox --remote-debugging-port=13888  --user-data-dir=~/chrome/13888 --ignore-certificate-errors --no-sandbox --allowed-origins=&quot;*&quot;chromedriver --port=13889 --whitelisted-ips --enable-webgl --no-sandbox --disable-dev-shm-usage --allowed-origins=&quot;*&quot;\n\n引用\nHow to Setup Selenium with ChromeDriver on Ubuntu 22.04, 20.04 &amp; 18.04\nselenium-release.storage.googleapis.com&#x2F;xml\nselenium-release.storage.googleapis.com&#x2F;index.html\nseleniuim chromedriver 固定 chrome 浏览器端口以及远程调试（windows &amp; linux）python\n\n","categories":["Tech","python"]},{"title":"使用 RSSHub 订阅目标信息","url":"/2023/10/29/Tech/rss/%E4%BD%BF%E7%94%A8RSSHub%E8%AE%A2%E9%98%85%E7%9B%AE%E6%A0%87%E4%BF%A1%E6%81%AF/","content":"引言效果展示过程Trending articles​\nSupport Sci-Hub\nAuthor: @y9c @nczitzk\nExample: https://rsshub.app/pubmed/trending\nRoute: &#x2F;pubmed&#x2F;trending&#x2F;:filter?\nParameters:\nfilter, optional - Filters, can be found in URLTIPFor the parameter filter, the filter parameter in the URL should be split into a string by ,, here is an example.\nIn https://pubmed.ncbi.nlm.nih.gov/trending/?filter=simsearch1.fha&amp;filter=pubt.clinicaltrial&amp;filter=pubt.randomizedcontrolledtrial, the filter parameters are simsearch1.fha, pubt.clinicaltrial, and pubt.randomizedcontrolledtrial. Therefore, the filter corresponding to the route should be filled with simsearch1.fha,pubt.clinicaltrial,pubt.randomizedcontrolledtrial, and the route is &#x2F;pubmed&#x2F;trending&#x2F;simsearch1.fha,pubt .clinicaltrial,pubt.randomizedcontrolledtrial\n结论引用\n\n\n","categories":["Tech","rss"],"tags":["RSS","RSSHub"]},{"title":"Docker-OSX","url":"/2024/10/18/Tech/Linux/Docker-OSX/","content":"引言效果展示过程## dependencysudo apt install qemu qemu-kvm libvirt-clients libvirt-daemon-system# docker pull sickcodes/docker-osxdocker pull dickhub/docker-osx## runxhost +local:docker# Catalina (10.15)docker run -it \\    --device /dev/kvm \\    -p 50922:10022 \\    -v /tmp/.X11-unix:/tmp/.X11-unix \\    -e &quot;DISPLAY=$&#123;DISPLAY:-:0.0&#125;&quot; \\    -e SHORTNAME=big-sur \\    -e RAM=16 \\    --name osx \\    dickhub/docker-osx:latest# docker build -t docker-osx .## run by defaultsudo docker run --privileged -e &quot;DISPLAY=$&#123;DISPLAY:-:0.0&#125;&quot; -v /tmp/.X11-unix:/tmp/.X11-unix dickhub/docker-osx# docker update --memoryswap=8g --memory=8g containerID# docker exec -it containerID /bin/bash# vi Launch.sh# RAM=8\n\n结论引用\n没钱买苹果电脑，试试这个开源黑苹果，享受原生级 macOS 体验！\n\n\n","categories":["Tech","Linux"],"tags":["Docker"]},{"title":"Linux 操作小技巧","url":"/2023/06/05/Tech/Linux/Linux%E6%93%8D%E4%BD%9C%E5%B0%8F%E6%8A%80%E5%B7%A7/","content":"引言效果展示过程内存占用过高# 查看内存占用前10位：ps aux | head -1;ps aux |grep -v PID |sort -rn -k +4 | head -101# 或者ps aux --sort -rss | head -n 10# 杀死前7位sudo kill $(ps aux |grep -v PID |sort -rn -k +4 | head -7 | awk &#x27;&#123;print $2&#125;&#x27;)\n\n解决缓存区空间不足查看硬盘占用find / -xdev -size +1G -exec ls -l &#123;&#125; \\;\n\n查看硬盘类型cat /sys/block/sda/queue/rotationalcat /sys/block/sdb/queue/rotationallssci\n\n解决如果有新硬盘可以用新硬盘。\n免密登录失效很大概率考虑权限问题。\nsudo chown -R $&#123;LOGNAME&#125;:tenney $HOME\n\n结论引用\nCentos7 服务器内存使用过高排查 - taotaozh - 博客园\nLinux centos 内存高，查看占用内存命令\nCentOS 系统根目录 &#x2F;dev&#x2F;mapper&#x2F;cl-root 100% 耗尽的解决方案\nlinux 查看磁盘类型（是否 SSD 盘）\nLinux 下两种增加&#x2F;tmp 文件的方法\n如何增加 Linux 下临时文件夹 &#x2F;tmp 的大小\nlaravel - zsh: permission denied: reading anyway - Stack Overflow\n\n","categories":["Tech","Linux"]},{"title":"Linux账户管理","url":"/2023/05/07/Tech/Linux/Linux%E8%B4%A6%E6%88%B7%E7%AE%A1%E7%90%86/","content":"引言效果展示过程Ubuntu 修改用户的默认目录Ubuntu 系统中，每次打开终端，就会进入系统默认的用户目录&#x2F;home&#x2F;username，有时候我们想要修改用户默认目录，以更快速地进入项目进行操作，这时候我们就需要通过以下方法来修改用户默认目录。\n第一步执行以下代码，修改passwd配置文件 sudo vi /etc/passwd\n第二步找到用户所在行，vim是用 :/你的用户名 来快速查找，找到所在行类似下面这种：\nsmy:x:1000:1000:Shelming.Song:/home/smy:/bin/bash\n\n将其中的&#x2F;home&#x2F;smy改成你想要修改成的目录（采用绝对路径），如&#x2F;dev&#x2F;sda1&#x2F;home&#x2F;smy，其余内容都别改，保存后关闭。\n第三步关闭终端，重新打开，就自动进入你修改的目录了。\n第四步\n将原根目录的.bashrc和.project文件复制入新根目录.\nmv /home/smy /dev/sda1/home/smy\n\n免密上传可生成并上传本地密钥到服务器, 完成免密上传.\nssh-copy-id -i ~/.ssh/id_rsa.pub tenney@10.9.65.31\n\n结论引用\nUbuntu 修改用户的默认目录 - 简书\n\n","categories":["Tech","Linux"],"tags":["Ubuntu"]},{"url":"/2023/05/24/Tech/Linux/centOS%208.5.2111%20repo/","content":"引言效果展示过程wget -O /etc/yum.repos.d/CentOS-Base.repo http://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.reposudo yum makecache\n\n结论阿里云是唯一一个提供了repo文件下载的\n引用\ncentos-vault | 镜像站使用帮助 | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror\ncentos 8.5.2111中yum.repos.d的文件清空后无法执行yum命令，如何恢复？ - 知乎\nCentOS Vault 软件仓库镜像使用帮助 - MirrorZ Help\n清华源镜像的内容已经过时，当前对于 CentOS 8 您应当这么执行： m | Leonn的博客\ncentos镜像_centos下载地址_centos安装教程-阿里巴巴开源镜像站\n\n","categories":["Tech","Linux"]},{"title":"美化 linux 桌面：chadwm 安装及使用","url":"/2024/10/25/Tech/Linux/dwm%E5%AE%89%E8%A3%85%E5%8F%8A%E4%BD%BF%E7%94%A8/","content":"引言效果展示过程安装git clone https://github.com/siduck/chadwm --depth 1  ~/.config/chadwmcd ~/.config/chadwm/mv eww ~/.configcd chadwmsudo make install\n\nRun chadwmWith startx\nstartx ~/.config/chadwm/scripts/run.sh\n\nWith sx\nsx sh ~/.config/chadwm/scripts/run.sh\n\nMake an alias for this :v\nalias chadwm=&#x27;startx ~/.config/chadwm/scripts/run.sh&#x27;\n\nWith Display Manager\nCreate a desktop entry (make sure to change user with your user):\nsudo touch /usr/share/xsessions/chadwm.desktop\n\n[Desktop Entry]Name=chadwmComment=dwm made beautifulExec=/home/user/.config/chadwm/scripts/./run.shType=Application\n\n结论引用\nGitHub - siduck&#x2F;chadwm: Making dwm as beautiful as possible!\n\n","categories":["Tech","Linux"],"tags":["Linux"]},{"title":"centos 使用 telnet 连接","url":"/2024/10/25/Tech/Linux/centos%E4%BD%BF%E7%94%A8telnet%E8%BF%9E%E6%8E%A5/","content":"引言效果展示过程首先阿里云的镜像可能不能使用，建议使用清华的镜像。\n更新系统软件源在安装 Telnet 之前，先确保系统的软件源是最新的。可以使用以下命令更新软件包列表：\nyum update\n\n安装 Telnet 和 xinetd通过以下命令安装 xinetd 和 telnet-server：\nyum -y install xinetd telnet-server\n\n这将自动下载并安装所有必要的依赖包。安装完成后，xinetd 的配置文件将存储在 &#x2F;etc&#x2F;xinetd.d 目录中。\n增加具有管理员权限的用户在配置 Telnet 服务时，通常建议创建一个具备管理权限的用户，而不是直接使用 root 登录。以下步骤将展示如何添加用户 test 并为其配置 sudo 权限。\n添加新用户使用以下命令创建一个新的用户 test：\nadduser testpasswd test\n\n配置 sudo 权限修改 sudoers 文件，赋予 test 用户管理员权限：\nchmod u+w /etc/sudoersvim /etc/sudoers\n\n在 root ALL&#x3D;(ALL) ALL 行下添加以下内容，允许 test 用户执行所有命令时不需要输入密码：\ntest ALL=(ALL) NOPASSWD:ALL\n\n完成后，将 sudoers 文件设为只读：\nchmod u-w /etc/sudoers\n\n启动和管理 Telnet 服务安装完成后，我们需要启动 Telnet 服务和 xinetd，并确保它们在系统重启后自动启动。\n启动服务使用以下命令启动 Telnet 和 xinetd：\nsudo systemctl restart telnet.socketsudo systemctl restart xinetd\n\n设置服务自启动为了确保服务在系统重启后仍然自动启动，执行以下命令：\nsudo systemctl enable telnet.socketsudo systemctl enable xinetd\n\n此时，Telnet 服务已经启动并可以接受远程连接。\n配置防火墙允许 Telnet 通信为了确保外部主机能够通过 Telnet 访问服务器，我们需要在防火墙中开放 Telnet 使用的 23 端口。\n修改防火墙规则使用以下命令放行 23 端口：\nfirewall-cmd --zone=public --add-port=23/tcp --permanentfirewall-cmd --reload\n\n此命令会重新加载防火墙规则，允许外部主机通过 23 端口连接。\n配置 Telnet 服务Telnet 服务的配置文件存储在 &#x2F;etc&#x2F;xinetd.d 目录中。如果文件不存在，您需要手动创建。\n创建和编辑配置文件进入 &#x2F;etc&#x2F;xinetd.d 目录，并创建 Telnet 服务的配置文件：\ncd /etc/xinetd.dvi telnet\n\n在文件中添加以下内容：\nservice telnet&#123;    disable = no    flags = REUSE    socket_type = stream    wait = no    user = root    server = /usr/sbin/in.telnetd    log_on_failure += USERID&#125;\n\n配置完成后保存并退出。\n测试连接telnet 127.0.0.1 23\n\n结论引用\nCentOS 7 系统中安装与配置 Telnet 服务详解（使用非 root 用户登录）_centos7 telnet-CSDN 博客\ntelnet 使用教程（新手篇）及问题集锦-CSDN 博客\n\n","categories":["Tech","Linux"],"tags":["Linux"]},{"title":"linux 安装 windows 虚拟机","url":"/2024/10/16/Tech/Linux/linux%E5%AE%89%E8%A3%85windows/","content":"引言效果展示过程sudo dpkg --add-architecture i386sudo apt install zenity wine winetricks libimage-exiftool-perl icoutils gnome-terminal# 安装 flatpaksudo apt install flatpaksudo apt install gnome-software-plugin-flatpakflatpak remote-add --if-not-exists flathub https://dl.flathub.org/repo/flathub.flatpakrepo# 安装 WineZGUIsudo -E flatpak install flathub io.github.fastrizwaan.WineZGUI\n\n结论引用\nWineZGUI\n在 Linux 上使用 WineZGUI 运行 Windows 应用和游戏 | Linux 中国\n\n","categories":["Tech","Linux"],"tags":["Linux"]},{"title":"VScode使用remote-ssh实现服务器上绘图可视化","url":"/2023/10/23/Tech/Linux/macOS%E4%BD%BF%E7%94%A8XQuartz%E6%94%AF%E6%8C%81X11%E5%AE%9E%E7%8E%B0Linux%E5%9B%BE%E5%BD%A2%E5%8C%96%E7%95%8C%E9%9D%A2%E6%98%BE%E7%A4%BA/","content":"引言有时候在服务器上绘图会受到结果不显示的困扰，无论是R还是python都会有类似的情况，那么有什么比较方便的应用呢？\n本文的前提是你使用VScode并以安装好python等环境，可以日常在服务器工作。\n使用的方案是X协议，详细介绍见[4]. 具体使用软件是MacOS的Quartz或Windows的Xming, Linux的xauth, VScode的插件remote X11和remote X11（ssh）.\n效果展示\n过程可视化方案大概需要三个步骤：\n\n安装本地X端 (X client)\n安装服务器X端 (X Server)\n安装和配置VScode插件\n\n安装本地X端 (X client)MacOSMacOS用的应用是Quartz, 可以直接从官网[5]下载，也可以从brew下载。\n一般情况都推荐brew, 但是我Ventura 13.0.1 (22A400) 系统的Apple M1不可用，所以尽量建议官网下载安装包，安装之后记得重启一下。\nbrew install xquartz\n\nWindowsWindows用的应用是Xming[6], 具体应用和配置见[1,2,3].\n安装服务器X端 (X Server)主要需要安装的是xauth, 建议一并安装xclock方便测试。\n如果是centOS可以使用yum install -y xauth xclock.\n安装和配置VScode插件需要的插件有两个：\n\nremote X11\nremote X11 (ssh)\n\n已有免密登录的情况下，在Remote Explorer 中点击设置，在Host下面增加三句转发指令\nHost 172.18.187.21 HostName 172.18.187.21 User root ForwardX11 yes ForwardX11Trusted yes ForwardAgent yes\n\n如果没有免密登录，可以通过下面的代码[7]:\nssh-keygen scp-copy-id user@host\n\n结论当需要不断改图或者用matplotlib以外的东西画图时，还是有个可视化窗口方便一些。\n篇外其他方案其实保存图看也不是不可以，也挺方便。\nR先提供两种R不用可视化的方案：\n自带：\n# 1. 画板pdf(&quot;filename.pdf&quot;)plot()dev.off()# 2. ggplotggsave(&quot;filename.pdf&quot;)\n\n然后是R可视化方案：\n主要是配合VScode使用httpgd包：\nhttpgd::hgd()\n\n甚至可以通过修改根目录的.Rprofile文件来自动使用：\nif (interactive() &amp;&amp; Sys.getenv(&quot;TERM_PROGRAM&quot;) == &quot;vscode&quot;) &#123;    if (&quot;httpgd&quot; %in% .packages(all.available = TRUE)) &#123;        options(vsc.plot = FALSE)        options(device = function(...) &#123;            httpgd::hgd(silent = TRUE)            .vsc.browser(httpgd::hgd_url(), viewer = &quot;Beside&quot;)        &#125;)    &#125;&#125;\n\npythonmatplotlib绘图\nimport matplotlib.pyplot as pltplt.plot([1, 2, 3, 4], [1, 4, 2, 3])plt.savefig(&#x27;myplot.png&#x27;)\n\n借助matplotlib绘图\nimport matplotlibmatplotlib.use(&quot;Agg&quot;)import matplotlib.pyplot as pltimport igraph as igfig, ax = plt.subplots()ig.plot(g, layout=layout, target=ax)plt.savefig(&quot;test.png&quot;)\n\n(其实大概也有自己的绘图保存方式比如ig.plot(g, &quot;social_network.pdf&quot;))\n引用\nVScode 使用 remote-ssh 的情況下，如何使 plt.show() 正常工作 - 简书\nXming X Server for Windows - Official Website\nmacOS windows x11 - 简书\nmacOS使用XQuartz支持X11实现Linux图形化界面显示 - 知乎\nXQuartz\nXming X Server for Windows - Official Website\n手把手教你免密码连接ssh（适用于win、Linux） - 知乎\n\n","categories":["Tech","Linux"],"tags":["VScode"]},{"title":"xrdp 连接黑屏修复","url":"/2024/10/24/Tech/Linux/xrdp%E4%BF%AE%E5%A4%8D/","content":"引言今天发现 xrdp 的日志太大了直接挤满了硬盘，而删除了之后因为 xrdp 仍在使用无法释放空间，所以需要关闭应用并重启。但是重启之后无法登录 (黑屏) 了，所以只好修复一下。\n查阅后发现是因为在没有注销的情况下进行了重启[1], 因此针对性解决并优化。\n系统版本：Ubuntu 22.04.3 LTS\n效果展示过程安装并启动 dbus-x11最重要的事情是安装 dbus-x11 并在 /etc/xrdp/startwm.sh 中加入相关代码[2].\n## 安装并启动 dbus-x11sudo apt install dbus-x11dbus-launch\n\n修改 startwm.shsudo vim /etc/xrdp/startwm.sh\n\nInside the script, add the following line:\n在脚本内部，添加以下行：\nexport $(dbus-launch)\n\nEnsure that the line is added before the following lines:\n在以下行之前确保添加该行：\ntest -x /etc/X11/Xsession &amp;&amp; exec /etc/X11/Xsessionexec /bin/sh /etc/X11/Xsession\n\nSave the changes and exit the editor.\n保存更改并退出编辑器。\n重启 xrdp 服务生效：\nsudo systemctl restart xrdp\n\n优化之后是优化 xrdp 的体验，减少卡顿[3].\n调整 Xrdp 配置参数：\n编辑 /etc/xrdp/xrdp.ini\ntcp_send_buffer_bytes=4194304tcp_recv_buffer_bytes=6291456\n\ntcp_send_buffer_bytes, tcp_recv_buffer_bytes 两个参数默认被注释了，注释默认值（32768），根据实际情况进行调整。\n调整系统参数：\n临时生效：\nsudo sysctl -w net.core.rmem_max=12582912sudo sysctl -w net.core.wmem_max=8388608\n\n重启后保留：\n将以下内容写入配置文件 /etc/sysctl.conf:\nnet.core.rmem_max = 12582912net.core.wmem_max = 8388608\n\n然后执行：\nsudo sysctl -p\n\n重启 xrdp 服务生效：\nsudo systemctl restart xrdp\n\n结论引用\n完美方案——解决 XRDP 连接黑屏，以及桌面优化！\nRemote Desktop from Windows onto Ubuntu 22.04 takes me to a XRDP login then a blank screen - Ask Ubuntu\nXrdp 体验优化 减少&#x2F;解决画面卡顿\n\n","categories":["Tech","Linux"],"tags":["Linux"]},{"title":"xrdp 音响远程连接","url":"/2024/11/13/Tech/Linux/xrdp%E9%9F%B3%E5%93%8D/","content":"引言结局大失败，bug 太多了，完全没有实现配合 jumpdesktop 这样的软件实现完美远程操作的愿望，放弃…\n效果展示过程自动安装测试过了，自动安装和手动安装遇到的问题是一致的…\n不过我觉得可以推荐先实验一下自动安装，万一成功了呢。\n手动安装安装 PulseAudio第一步提前先把依赖装好避免之后频繁报错。\nsudo apt-get install build-essential meson pkg-config libglib2.0-dev libdbus-1-dev libsndfile1-dev libsystemd-dev libx11-dev libx11-xcb-dev libgtk-3-dev libfftw3-dev libasyncns-dev libtdb-dev libcap-dev libprotobuf-dev libprotobuf-c-dev libpulse-dev libudev-dev libgstreamer1.0-dev libgstreamer-plugins-base1.0-devsudo apt-get install check doxygen libasound2-dev libspeexdsp-dev libsoxr-dev libwebrtc-audio-processing-dev libelogind-dev libavahi-client-dev libsbc-dev libbluetooth-dev libjack-jackd2-dev liblirc-devsudo apt install libwebrtc-audio-processing-devsudo apt install libelogind-dev\n\n安装 elogind\nsudo apt-get install meson ninja-buildgit clone https://github.com/elogind/elogind.gitcd elogindmeson setup builddir -Delogind=disabledsudo ninja -C builddir install\n\n安装 PulseAudio：\n接下来，安装 PulseAudio 音频服务器：\nsudo apt install pulseaudio\n\n安装相关工具（可选）：\n如果你需要额外的 PulseAudio 配置工具或者管理工具，可以安装 pavucontrol，它是一个图形化的 PulseAudio 控制工具，方便你管理音频设置：\nsudo apt install pavucontrol\n\n启动 PulseAudio 服务：PulseAudio 通常会自动启动，如果它没有自动启动，你可以手动启动它：\npulseaudio --start\n\n检查 PulseAudio 状态：可以使用以下命令来检查 PulseAudio 是否在运行：\npulseaudio --check\n\n配置 PulseAudio（可选）：\nPulseAudio 配置文件通常位于 &#x2F;etc&#x2F;pulse&#x2F; 目录下。你可以编辑配置文件来调整 PulseAudio 的设置。主要配置文件有：\n\n&#x2F;etc&#x2F;pulse&#x2F;daemon.conf：控制 PulseAudio 守护进程的行为。\n&#x2F;etc&#x2F;pulse&#x2F;default.pa：设置 PulseAudio 启动时的默认配置。\n\n安装完成后，PulseAudio 会管理你的音频设备，并为应用程序提供音频服务。\n要在系统中安装 pulseaudio-module-xrdp，可以按照以下步骤进行操作。这个模块用于在通过 XRDP 远程连接到 Linux 系统时传输音频。\n安装 pulseaudio-module-xrdp步骤 1:\n安装所需的软件包\n首先，确保你的系统已安装必要的依赖包。使用以下命令来安装：\nsudo apt updatesudo apt install pulseaudio pulseaudio-utils xrdp\n\n步骤 2:\n下载并安装 pulseaudio-module-xrdp\n接下来，从 GitHub 克隆 pulseaudio-module-xrdp 的代码并安装。\ncd /tmpgit clone https://github.com/neutrinolabs/pulseaudio-module-xrdp.gitcd pulseaudio-module-xrdp\n\n首先，你需要运行 autoreconf 命令来生成必要的构建文件。确保你已经安装了 autoconf 和 automake：\nsudo apt-get install autoconf automake\n\n然后，在项目根目录中运行：\nautoreconf --install\n\n这将会生成 configure 脚本和 Makefile 文件。\n配置并编译\n接下来，运行 .&#x2F;configure 来配置编译选项：\n./configure\n\n如果配置成功，它将为你生成一个适用于你系统的 Makefile 文件。\n然后，运行 make 来编译模块：\nmake\n步骤 3: 编译和安装\n在下载的目录中，执行以下命令来编译和安装模块：\nmakesudo make install\n步骤 4: 配置 PulseAudio 和 XRDP\n编辑 pulseaudio 的配置文件，以便允许通过 XRDP 传输音频。打开并编辑 &#x2F;etc&#x2F;pulse&#x2F;default.pa 文件：\nsudo nano &#x2F;etc&#x2F;pulse&#x2F;default.pa\n在文件的末尾添加以下行：\nload-module module-xrdp-sinkload-module module-xrdp-source\n保存并关闭文件。步骤 5: 重启相关服务\n重启 PulseAudio 和 XRDP 服务，以使更改生效。\npulseaudio -ksudo systemctl restart xrdp\n步骤 6: 测试音频\n重新连接到远程桌面，并检查音频是否正常工作。你可以尝试播放声音或使用音量控制来验证音频传输是否正常。\n如果在某些步骤中遇到问题，请根据错误消息进行相应的排查。\n结论引用\n\n\n"},{"title":"利用Ubuntu主机搭建共享打印服务","url":"/2023/04/05/Tech/Linux/%E5%88%A9%E7%94%A8Ubuntu%E4%B8%BB%E6%9C%BA%E6%90%AD%E5%BB%BA%E5%85%B1%E4%BA%AB%E6%89%93%E5%8D%B0%E6%9C%8D%E5%8A%A1/","content":"引言实验室的打印机自带的无线打印功能不太好用, 基本上大家都处于一种时断时续的薛定谔状态, 惠普smart一次又一次的用行动证明了这玩意实在不是很smart, 所以用 linux 搭建一个共享打印机服务或许是个不错的选择.\n这个方法需要:\n\n一台不关机的linux设备(路由器, 主机都行)\n设备有线直连打印机(或拥有稳定的打印机访问)\n设备连接局域网并具有稳定ip地址\n\n效果展示\n过程Ubuntu安装CUPS服务本文以 Ubuntu 22.04 为例, 已使用 HP smart 安装打印机驱动并有线连接打印机.\n## 安装apt install cups aptitudeaptitude install ghostscriptaptitude install foomatic## 启用sudo systemctl start cupssudo systemctl enable cups## sudo nano /etc/cups/cupsd.conf## 修改配置vim /etc/cups/cupsd.conf\n\n在 vim 中用 / 搜索关键词并更改配置:\n\nBrowsing Off或Browsing No –&gt; Browsing On\nListen localhost:631 –&gt; Listen 0.0.0.0:631\nOrder allow,deny –&gt; 在下面一行增加Allow all\n\n更改后重启服务:\nsudo systemctl restart cups\n\n其后进入 ip:631 可以在 Printers 选项卡中得到打印机的服务位置.\n在这次示例中, 为:\nhttp://192.168.1.101:631/printers/HP-LaserJet-MFP-M725\nWindows使用指南Windows 设置 - 添加打印机和扫描仪 - 我需要的打印机不在列表中\n\n\n按名称选择共享打印机(S) - 输入地址 - 直接确认\n\n\n\nMacOS首先, 在 terminal 中输入 sudo cupsctl WebInterface=yes , 然后按提示输入密码.\n然后, 已经安装打印机驱动的情况下, 直接打开http://127.0.0.1:631/admin网页, 输入本机帐号密码, 然后点击 Administration - Printers - Add Printer ，选择 互联网打印协议 (ipp) ，填入打印机地址，选择对映的驱动即可。\n\n\n\n结论利用这个方式, 可以降低其他设备的打印难度, 省去驱动安装的过程, 并享有相对稳定的打印权限.\n引用\n如何使用Ubuntu服务器、CUPS和Bonjour配置打印服务器-A5互联\nubuntu系统搭建cups打印机服务器 – 折腾 – 在网络的世界中一起折腾\n\n","categories":["Tech","Linux"],"tags":["linux","Ubuntu","团队协作"]},{"title":"安装 nvidia 显卡驱动及故障排查","url":"/2024/10/24/Tech/Linux/%E5%AE%89%E8%A3%85nvidia%E6%98%BE%E5%8D%A1%E9%A9%B1%E5%8A%A8/","content":"引言在一台旧一点的服务器 (CentOS 8.5.2111) 上安装 NVIDIA 显卡驱动及 CUDA 工具包。\n如果是 ubuntu 系统，用apt安装，基本上把yum换成apt即可。\n过程一定注意，一定要先查看 PyTorch 和 cuda 的对应关系，避免重装。\nPyTorch 和 cuda 的对应关系在PyTorch 官网查看。\n而 cuda 和 nvidia-driver 的版本对应关系在CUDA 12.6 Update 2 Release Notes查看。\n安装顺序：显卡驱动 → CUDA → CUDA Toolkit → cuDNN → Pytorch\n以这台服务器的显卡型号为 Tesla V100 PCIe 32GB 为例，PyTorch 可以和 cuda 12.4 对应，所以安装 cuda 12.4.1, 对应的 nvidia-driver 是 550.54.15。\n检查显卡型号打开终端并运行以下命令，查看显卡型号：\nlspci | grep -i nvidia\n\n若显卡支持 CUDA 加速，可以看到 NVIDIA 显卡的型号（如 NVIDIA GeForce GTX 1080）。\n安装 NVIDIA 驱动准备环境：\nsudo yum -y install kernel-develsudo yum -y install epel-releasesudo yum -y install gcc\n\n在 CentOS 上，如果找不到 nvidia-driver-latest-dkms，可以尝试以下步骤来手动安装 NVIDIA 驱动和 CUDA。\n手动下载并安装 NVIDIA 驱动前往 NVIDIA 官方网站：\nNVIDIA 驱动下载。\n选择你的显卡型号和操作系统，然后下载对应的驱动程序。\n安装 NVIDIA 驱动：\n\n下载驱动后，将安装包下载到某个目录，然后通过终端进入该目录。\n为驱动程序添加执行权限并运行安装程序：\n\n这时候有两种选择，一种是下载可执行文件 (run), 一种是下载打包好的程序 (deb, rpm), 这里先实验了程序，重启后无效，所以选择下载可执行文件：\n前面说过，以这台服务器的显卡型号为 Tesla V100 PCIe 32GB 为例，对应的 nvidia-driver 是 550.54.15。\nwget https://us.download.nvidia.com/tesla/550.54.15/NVIDIA-Linux-x86_64-550.54.15.runsudo chmod +x NVIDIA-Linux-x86_64-*.runsudo ./NVIDIA-Linux-x86_64-*.run\n\n交互界面选择默认即可。\n程序方法：\nwget https://us.download.nvidia.com/tesla/550.127.05/nvidia-driver-local-repo-rhel8-550.127.05-1.0-1.x86_64.rpmsudo chmod +x ./nvidia-driver-local-repo-rhel8-*.rpmsudo yum install ./nvidia-driver-local-repo-rhel8-*.rpm\n\n但是事实上提示安装成功了，但是重启后无效，所以还是选择下载可执行文件。\n按照提示完成安装，确保在安装时禁用 nouveau 驱动（如有提示），然后重启系统。\nsudo reboot\n\n验证安装：\n重启后，运行以下命令验证驱动是否成功安装：\nnvidia-smi\n\n若显示 NVIDIA 驱动信息，即表明安装成功。\n安装 CUDA添加 CUDA 存储库：\nsudo yum-config-manager --add-repo=https://developer.download.nvidia.com/compute/cuda/repos/rhel8/x86_64/cuda-rhel8.repo\n\n安装 CUDA 工具包：\n在nvidia-smi显示的信息中，右上角有对应的 CUDA 版本，以 CUDA 12.4 为例，运行以下命令：\n手动安装：\n首先在CUDA Toolkit Archive | NVIDIA Developer找到对应的版本，然后下载。\nsudo yum install -y libXi-devel libXmu-devel libXt-devel libXext-devel libX11-devel gcc-c++wget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda_12.4.1_550.54.15_linux.runsudo sh cuda_12.4.1_550.54.15_linux.run# sudo TMPDIR=/dev/sda1/home/tmp sh cuda_12.4.1_550.54.15_linux.run\n\n如果提示下面的错误，可以通过设置 TMPDIR 环境变量，将临时文件存储在空间充足的目录中，例如 &#x2F;home&#x2F;tmp\nExtraction failed.Ensure there is enough space in /tmp and that the installation package is not corruptSignal caught, cleaning up\n\n如果有另一个分区空间足够大，可以将 &#x2F;tmp 挂载到那个分区。例如，如果 &#x2F;home 有足够空间，可以创建一个临时目录并挂载：\n创建新的临时目录：\nsudo mkdir /dev/sda1/home/tmp\n\n将 &#x2F;tmp 挂载到新的目录，并重新运行安装程序：\nsudo mount --bind /dev/sda1/home/tmp /tmp\n\n运行安装完成后，再恢复原有设置：\nsudo umount /tmp\n\n自动安装 (依旧可以跑但是实际跑不完)：\nsudo yum install cuda-12-4 -y\n\n配置环境变量：\n将 CUDA 的路径添加到环境变量中：\nls /usr/local/cuda-*echo &#x27;export PATH=/usr/local/cuda-12.4/bin:$PATH&#x27; &gt;&gt; ~/.bashrcecho &#x27;export LD_LIBRARY_PATH=/usr/local/cuda-12.4/lib64:$LD_LIBRARY_PATH&#x27; &gt;&gt; ~/.bashrcsource ~/.bashrc\n\n验证 CUDA 安装：\n运行以下命令检查 CUDA 安装是否成功：\nnvcc -V\n\n正确显示 CUDA 版本信息说明安装成功。\nubuntu 安装上次发现 cuda 貌似是可以直接带了驱动安装的，所以实验了直接安装 cuda, 结果是失败了，所以还是按照之前的步骤来。\n首先要卸载上个版本的驱动和 cuda。\n# 卸载驱动sudo apt-get purge &#x27;*nvidia*&#x27;# 如果安装了 cuda 的话sudo apt-get purge &#x27;cuda*&#x27;sudo apt-get purge &#x27;libcuda*&#x27;# 删除 cuda 目录sudo rm -rf /usr/local/cuda*# 删除驱动目录sudo rm -rf /etc/systemd/system/multi-user.target.wants/nvidia*# 删除多余的包sudo apt autoremove\n\n然后安装驱动，很不可思议，居然安装失败了，可能是由于 gcc 版本的问题。\n# wget https://us.download.nvidia.com/tesla/550.54.15/nvidia-driver-local-repo-ubuntu2204-550.54.15_1.0-1_amd64.deb# wget https://us.download.nvidia.com/tesla/550.54.15/NVIDIA-Linux-x86_64-550.54.15.run# sudo chmod +x NVIDIA-Linux-x86_64-*.run# sudo ./NVIDIA-Linux-x86_64-*.run# 添加 PPA 源sudo add-apt-repository ppa:graphics-drivers/ppasudo apt update# 安装必要的编译工具sudo apt install build-essential dkms# 安装内核头文件sudo apt install linux-headers-$(uname -r)# 设置正确的编译器export CC=/usr/bin/gcc-12# 搜索驱动apt search nvidia-driver# 安装驱动sudo apt install nvidia-driver-550\n\n然后安装 cuda。\nwget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda_12.4.1_550.54.15_linux.runsudo sh cuda_12.4.1_550.54.15_linux.run\n\n测试：\nnvidia-sminvcc -V\n\n结论不得不说，折腾了很久，在网络文章和官方文档的帮助下，终于成功了。今天的吃一堑就到此为止吧…\n篇外这里特别说明一点，我也不知道为什么反正阿里云的镜像是不能用的，但是清华镜像可以用，所以特别说明如何切换清华镜像。\n比如阿里的镜像源是http://mirrors.aliyun.com/，清华镜像源是https://mirrors.tuna.tsinghua.edu.cn/，只需要把http://mirrors.aliyun.com/换成https://mirrors.tuna.tsinghua.edu.cn/即可，按官网的命令是使用sed。\n既是说，把/etc/yum.repos.d/目录下的CentOS-Base.repo文件中的http://mirror.centos.org都替换成清华镜像源，而我这里已经用了阿里源，所以我应该是把http://mirrors.aliyun.com替换成https://mirrors.tuna.tsinghua.edu.cn。\nsed -e &quot;s|^mirrorlist=|#mirrorlist=|g&quot; \\    -e &quot;s|^#baseurl=http://mirror.centos.org/centos/\\$releasever|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111|g&quot; \\    -e &quot;s|^#baseurl=http://mirror.centos.org/\\$contentdir/\\$releasever|baseurl=https://mirrors.tuna.tsinghua.edu.cn/centos-vault/8.5.2111|g&quot; \\    -i.bak \\    /etc/yum.repos.d/CentOS-*.repo\n\n然后更新缓存：\nsudo yum makecachesudo yum install epel-release\n\n如果不小心已经弄坏了原有的原始仓库文件，可以从阿里云镜像的下载地址下载：\nrepo:\nhttps://mirrors.aliyun.com/repo/Centos-vault-8.5.2111.repo\nepel:\nhttps://mirrors.aliyun.com/repo/epel-archive-8.repo\n引用\n240107-RHEL8+RHEL9 配置安装：NVIDIA 驱动（15 步）+CUDA（4 步）+CUDNN（5 步）+GPU 压力测试_rhel9 安装 n 卡驱动-CSDN 博客\nDownload The Official NVIDIA Drivers | NVIDIA\nCUDA 12.6 Update 2 Release Notes\nCUDA Toolkit Archive | NVIDIA Developer\nCentOS8 修改国内镜像源 - 吕金林 - 博客园\ncentos-vault | 镜像站使用帮助 | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror\nepel | 镜像站使用帮助 | 清华大学开源软件镜像站 | Tsinghua Open Source Mirror\n\n","categories":["Tech","Linux"],"tags":["Linux"]},{"title":"批量测试ip和端口可用性","url":"/2024/03/24/Tech/Linux/%E6%89%B9%E9%87%8Fping/","content":"引言效果展示过程windowsfor /L %D in (1,1,255) do ping 192.168.68.%Dfor /L %D in (1,1,255) do ping -n 10.168.1.%D &gt;&gt;a.txtfor /l %D in (1,1,255) do (ping 192.168.1.%D -n 1 &amp;&amp; echo 192.168.1.%D&gt;&gt;ok.txt || echo 192.168.1.%D &gt;&gt;no.txt)\n\nmacfor D in &#123;1..255&#125;; do ping -c 1 192.168.68.$D; donefor D in &#123;1..25&#125;; do    if ping -c 1 192.168.68.$D | grep -q &quot;64 bytes from&quot;; then        echo &quot;192.168.68.$D is reachable&quot;    fidonefor D in &#123;1..255&#125;; do    (ping -c 1 192.168.68.$D &amp;&amp; echo 192.168.68.$D&gt;&gt;ok.txt || echo 192.168.68.$D &gt;&gt;no.txt) &amp;done\n\nfor D in &#123;1..63355&#125;; do  if nc -z 192.168.1.183 $D; then    echo $D &gt;&gt; ok.txt  else    echo $D &gt;&gt; no.txt  fidone\n\n工具nmap 192.168.1.183## processnmap  192.168.1.0/24 -sn\n\n最全的常见端口及其利用方式 (速查表 比以往还全) - cowpokee - 博客园\n结论引用\n如何同时 Ping 多个 IP 地址，一个小技巧节约 N 小时哦！ - 知乎\n\n","categories":["Tech","Linux"]},{"title":"安装 nvidia-container-toolkit 以支持 docker 使用显卡","url":"/2024/11/01/Tech/Linux/%E5%AE%89%E8%A3%85nvidia-container-toolkit%E4%BB%A5%E6%94%AF%E6%8C%81docker%E4%BD%BF%E7%94%A8%E6%98%BE%E5%8D%A1/","content":"引言如果在 docker 使用 gpu 的时候，出现以下错误：\ndocker: Error response from daemon: could not select device driver &quot;&quot; with capabilities: [[gpu]].\n\n可以参考以下步骤安装 nvidia-container-toolkit 以支持 docker 使用显卡。\n官网地址：\nInstalling the NVIDIA Container Toolkit — NVIDIA Container Toolkit 1.16.2 documentation\n过程Installing with Yum or DnfConfigure the production repository:\ncurl -s -L &lt;https://nvidia.github.io/libnvidia-container/stable/rpm/nvidia-container-toolkit.repo&gt; | \\sudo tee /etc/yum.repos.d/nvidia-container-toolkit.repo\n\nOptionally, configure the repository to use experimental packages:\nsudo yum-config-manager --enable nvidia-container-toolkit-experimental\n\nInstall the NVIDIA Container Toolkit packages:\n# 更新仓库sudo dnf clean allsudo dnf makecache# 安装 NVIDIA Container Toolkitsudo dnf install -y nvidia-container-toolkit\n\nConfigure the container runtime by using the nvidia-ctk command:\nsudo nvidia-ctk runtime configure --runtime=docker\n\nRestart the Docker daemon:\nsudo systemctl restart docker\n\n结论引用\n[docker: Error response from daemon: could not select device driver “” with capabilities: [[gpu]]. AFTER installing nvidia-docker2 - Stack Overflow](https://stackoverflow.com/questions/75118992/docker-error-response-from-daemon-could-not-select-device-driver-with-capab)\n\n","categories":["Tech","Linux"],"tags":["Linux","nvidia"]},{"title":"报错解决_Segmentation fault","url":"/2023/11/01/Tech/Linux/%E6%8A%A5%E9%94%99%E8%A7%A3%E5%86%B3_Segmentation%20fault/","content":"引言效果展示过程结论最后重装了 scipy 解决了。\n引用\n记录一次 Pytorch 使用中遇到 Segmentation fault (core dumped) 的经历 - 知乎\n\n","categories":["Tech","Linux"]},{"title":"代理可用性测试及使用","url":"/2023/05/24/Tech/Linux/%E4%BB%A3%E7%90%86%E5%8F%AF%E7%94%A8%E6%80%A7%E6%B5%8B%E8%AF%95%E5%8F%8A%E4%BD%BF%E7%94%A8/","content":"引言代理（Proxy）是指在网络通信中充当中间人的服务器，它接收客户端发送的请求，然后向服务器发送请求，获取响应后再将响应返回给客户端。代理服务器通常用于隐藏客户端的真实IP地址，提高安全性、访问速度等方面的需求。\n在进行爬虫时，由于一些网站会采取反爬虫机制，可能会限制同一IP地址的访问频率，因此需要使用代理来切换IP地址进行爬取。下面介绍几种代理使用方案及查看代理是否成功的方法。\n过程本文所有代理以 127.0.0.1:7890 为例\n测试代理可用性&#x2F;对部分请求使用代理shell 中测试代理可用性$ curl http://icanhazip.com59.49.101.211$ curl http://icanhazip.com --proxy http://127.0.0.1:7890 37.19.221.152\n\npython 中构建请求头使用代理import requestsURL = &quot;http://icanhazip.com&quot;proxies = &#123;&quot;http&quot;: &quot;http://127.0.0.1:7890&quot;, &quot;https&quot;: &quot;http://127.0.0.1:7890&quot;&#125;response = requests.get(URL, proxies=proxies)if response.status_code == 200:    print(&quot;Your public IP address is:&quot;, response.text.strip())else:    print(&quot;Failed to retrieve public IP address.&quot;)\n\n注意, requests 为第三方库, proxies 格式为 &quot;http&quot;: &quot;http://127.0.0.1:7890&quot; , 而 urllib2.Request 为 python 自带库.\nimport requests## 可选代理IP构建方式proxy = &#x27;127.0.0.1:7890&#x27;proxy_values = &quot;%(ip)s&quot; % &#123;&#x27;ip&#x27;: proxy&#125;proxies = &#123;&quot;http&quot;: proxy_values, &quot;https&quot;: proxy_values&#125;## 也可以使用socks5代理proxies = &#123;&#x27;http&#x27;: &quot;socks5://127.0.0.1:7890&quot;,           &#x27;https&#x27;: &quot;socks5://127.0.0.1:7890&quot;&#125;\n\n全局代理MacOS&#x2F;Linux Bash&#x2F;zshexport https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7890\n\nGNOME## 代理查看gsettings get  org.gnome.system.proxy mode gsettings get org.gnome.system.proxy.http hostgsettings get org.gnome.system.proxy.https portgsettings get org.gnome.system.proxy.socks host## 代理设置### 无gsettings set org.gnome.system.proxy mode &#x27;none&#x27;### 有gsettings set org.gnome.system.proxy.http host 127.0.0.1gsettings set org.gnome.system.proxy.socks port 7890## 查看gsettings list-recursivelygsettings list-recursively | grep proxy\n\npython设置环境变量使用HTTP代理import osos.environ[&quot;http_proxy&quot;] = &quot;http://127.0.0.1:1231&quot;os.environ[&quot;https_proxy&quot;] = &quot;http://127.0.0.1:1231&quot;\n\n通过tsocks使用SOCKS全局代理通过设置环境变量的方式通常只能使用HTTP代理。要使用全局SOCKS代理可以使用tsocks.\n安装tsocks后，编辑 /etc/tsocks.conf ，以使用端口为7890的本地SOCKS5代理为例：\nserver = 127.0.0.1server_port = 7890 server_type = 5\n\n配置完成后在原来的脚本执行命令前添加tsocks即可使用，例如:\ntsocks python3 myscript.py\n\nRSys.setenv(http_proxy=&quot;http://127.0.0.1:7890&quot;)Sys.setenv(https_proxy=&quot;http://127.0.0.1:7890&quot;)Sys.setenv(all_proxy=&quot;socks5://127.0.0.1:7890&quot;)\n\n结论题外话一些好用的查看ip的网站:\n国内https://ip.cn\n\n\n\n您的IP信息\n\n\n\n\n域名解析地址:\n59.49.101.211\n\n\n所在地理位置：\n中国 山西省 太原市 电信\n\n\nhttp://www.cip.cc\n\nhttp://myip.ipip.net\n当前 IP：59.49.101.211  来自于：中国 山西 太原  电信\n\n国外http://icanhazip.com\n37.19.221.152\n\nhttps://ifconfig.me\n\n引用\ncurl命令获取本机外网IP_curl ip_longzhizhui926的博客-CSDN博客\nIP.cn - IP 地址查询 | 地理位置 | 手机归属地  | DNS查询\nIP查询 - 查IP(www.cip.cc)\nhttps://ifconfig.me\nhttp://icanhazip.com\nhttp://myip.ipip.net\n在Python里使用代理的几种方式 - Lambda Infinite\n\n","categories":["Tech","Linux"],"tags":["R 语言","Python","linux","shell","proxy"]},{"title":"挂载硬盘命令","url":"/2024/03/24/Tech/Linux/%E6%8C%82%E8%BD%BD%E7%A1%AC%E7%9B%98%E5%91%BD%E4%BB%A4/","content":"引言效果展示过程挂载硬盘并直接设定到&#x2F;exvolfdisk -l# isk /dev/sda3: 130.97 TiBmkfs -t ext4 /dev/sda3mkdir /mnt/exvolfdisk -l | grep G# /dev/sda3  6397952 1953521663 1947123712 928.5G Linux 文件系统mount /dev/sda3 /mnt/exvoldf -h# cp -a /exvol/* /mnt/exvol/sudo mv /exvol /exvol_oldsudo mkdir /exvolsudo mount /dev/sda3 /exvolsudo blkiddf -hsudo vi /etc/fstab## UUID=&quot;34d6dd4e-9b44-49ee-bf4b-fbc64b2c5fbe&quot; /exvol auto defaults 0 0sudo mount -adf -h\n","categories":["Tech","Linux"]},{"title":"服务器加装硬盘备份迁移","url":"/2025/04/04/Tech/Linux/%E6%9C%8D%E5%8A%A1%E5%99%A8%E5%8A%A0%E8%A3%85%E7%A1%AC%E7%9B%98%E5%A4%87%E4%BB%BD%E8%BF%81%E7%A7%BB/","content":"引言这篇文章可以帮助系统管理员或需要进行服务器数据迁移的用户。下面是一个使用 restic 进行服务器数据备份的 文章大纲和核心内容：\n过程备份在旧服务器上，使用 restic 进行数据备份。\nssh-copy-id user@10.9.65.32 # 复制公钥到新服务器以便免密登录## 安装 resticsudo apt install resticexport RESTIC_REPOSITORY=sftp:tenney@10.9.65.32:/path/to/borg/restic/repoexport RESTIC_PASSWORD=&quot;1919&quot; # 或者使用密码文件/环境变量export RESTIC_CACHE_DIR=/dev/sda1/path/to/cache ## 如默认备份目录不够用可指定备份目录restic init  -r $RESTIC_REPOSITORY --cache-dir=$RESTIC_CACHE_DIR## 备份sudo restic -r $RESTIC_REPOSITORY backup /home /dev/sda1 --verbose  --cache-dir=$RESTIC_CACHE_DIRrestic snapshots -r $RESTIC_REPOSITORY## 状态查看restic snapshots -r $RESTIC_REPOSITORY --cache-dir=$RESTIC_CACHE_DIRrestic -r $RESTIC_REPOSITORY stats --cache-dir=$RESTIC_CACHE_DIR## 备份到本地sudo restic restore latest --target /path/to/restore/location --verbose  --cache-dir=$RESTIC_CACHE_DIR\n\n帐号系统恢复首先获取所有需要备份的帐号的列表。可以使用 ls 或 ll 命令来列出 /home 文件夹的内容来作为账户名列表：\n#!/bin/bash# 获取 /home 目录下的所有文件夹名称（排除 . 和 .. 以及特殊目录）home_dirs=$(ls -1 /home | grep -vE &quot;^\\.$|^\\.\\.$|^lost\\+found$|^dev$|^home$&quot;)# 检查是否找到目录if [ -z &quot;$home_dirs&quot; ]; then    echo &quot;No directories found in /home to create users for!&quot;    exit 1fi# 遍历每个目录名称，创建用户并分配权限for dir in $home_dirs; do    username=&quot;$dir&quot;    echo &quot;Processing user: $username&quot;    # 检查用户是否已存在    if id &quot;$username&quot; &gt;/dev/null 2&gt;&amp;1; then        echo &quot;User $username already exists, skipping creation.&quot;    else        # 创建用户，设置主目录为 /home/$username，shell 为 /bin/bash        sudo useradd -d &quot;/home/$username&quot; -s /bin/bash -m &quot;$username&quot;        if [ $? -eq 0 ]; then            echo &quot;User $username created successfully!&quot;        else            echo &quot;Failed to create user $username!&quot;            continue        fi        # 设置用户密码（这里设置为用户名作为密码，可根据需求修改）        echo &quot;$username:$username&quot; | sudo chpasswd        if [ $? -eq 0 ]; then            echo &quot;Password set for user $username!&quot;        else            echo &quot;Failed to set password for user $username!&quot;        fi    fi    # 检查目录是否存在并分配权限    if [ -d &quot;/home/$username&quot; ]; then        # 修改目录的拥有者为对应用户        sudo chown -R &quot;$username:$username&quot; &quot;/home/$username&quot;        if [ $? -eq 0 ]; then            echo &quot;Ownership of /home/$username set to $username!&quot;        else            echo &quot;Failed to set ownership for /home/$username!&quot;        fi        # 设置目录权限为 700（仅用户可读写执行）        sudo chmod -R 755 &quot;/home/$username&quot;        if [ $? -eq 0 ]; then            echo &quot;Permissions of /home/$username set to 755!&quot;        else            echo &quot;Failed to set permissions for /home/$username!&quot;        fi    else        echo &quot;Directory /home/$username does not exist, skipping permission setup.&quot;    fi    echo &quot;--------------------------------&quot;doneecho &quot;Account creation and permission setup completed!&quot;\n\n总结这样就完成了服务器数据的备份和帐号系统的恢复。使用 restic 进行数据备份是一个高效且安全的方法，可以确保数据在迁移过程中的完整性和安全性。通过脚本自动化帐号创建和权限设置，可以大大减少手动操作的错误和时间消耗。\n","categories":["Tech","Linux"],"tags":["Linux"]},{"title":"安装rust","url":"/2023/11/25/Tech/rust/%E5%AE%89%E8%A3%85rust/","content":"引言看到了一段网上的发言[1]，深有感触。\n约10年前，我刚从当当买了一本C＋＋机器视觉，想精湛一下C＋＋技术。回家时遇到了朋友，他神神叨叨的告诉我：你学啥C＋＋，学蟒蛇啊。我并没有放在心上。大约5年前，我开始学习蟒蛇Python了。每每想起来，我觉得自己的确是那个只会低头走路，不愿抬头看方向的人。\n\n所以我觉得可以整一整。\n效果展示过程对于macOS而言，只需要一句就够了。\ncurl --proto &#39;=https&#39; --tlsv1.2 -sSf https://sh.rustup.rs | sh\n但是我可能因为用的zsh或者别的什么原因，反正$HOME/.cargo/bin并没有被自动添加到可用路径中，因此我还是推荐用brew install rust.\n官方也给出了解释：\n\n在 Rust 开发环境中，所有工具都安装在 ~&#x2F;.cargo&#x2F;bin 目录中，您可以在这里找到包括 rustc、cargo 和 rustup 在内的 Rust 工具链。Rust 开发者通常会将该目录加入 PATH环境变量中。在安装过程中，rustup 会尝试配置 PATH。由于不同平台、命令行 Shell 之间存在差异，rustup 中也可能存在 Bug，因此在终端重启或用户重新登录之前，rustup 对 PATH 的修改可能不会生效，甚至完全无效。如果安装后在终端尝试执行 rustc –version 失败，那么，以上内容就是最可能的原因。\n\n结论引用\nRust 取代Python成为数据科学新宠？\n安装 Rust - Rust 程序设计语言\n\n","categories":["Tech","rust"]},{"title":"Dvorak键盘","url":"/2023/05/23/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/Dvorak%E9%94%AE%E7%9B%98/","content":"引言效果展示过程macOSRime\nios落格输入法\n结论引用\nDvorak（德沃夏克）鍵盤中文初體驗 - 壹讀\nDvorak - 知乎\n胖鸭子的主页 - Dvorak键盘\n什么是Dvorak德沃夏克键盘 iOS 16输入法新功能介绍【详解】\n德沃夏克键盘 - 维基百科\nDvorak布局下一种比较理想的双拼方案 – 张砷镓\nGitHub - igaryhe&#x2F;double-pinyin-dvorak: Double pinyin layout for Dvorak keyboard\nProgrammer Dvorak\nKarabiner-Elements complex_modifications rules\n\n","categories":["Tech","叶子的推荐小软件"]},{"title":"ChatGPT注册指南","url":"/2023/06/07/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/ChatGPT%E6%B3%A8%E5%86%8C%E6%8C%87%E5%8D%97/","content":"工具网页(已关闭):\nhttp://107.175.142.245:8080\n密码:\nyeyezi\n介绍:\n一个美国服务器的远程访问网页, 作用是提供一个稳定的ip, 只有人比较少的稳定ip可以注册chatGTP\n注册指南注册指南(sms-activate接码平台提供):\nhttps://sms-activate.org/cn/info/ChatGPT\n需要注意的事项有:\n\nemail最好不要用中国的, gmail最佳, outlook也行, 实在不行163, 126都行, 但是不要qq\n注册了以后可以用别的ip登录, 除了香港台湾应该都可以, 新加坡日本比较好用\n\n","categories":["Tech","叶子的推荐小软件"]},{"title":"Paste Image - hexo中完美插入本地图片","url":"/2023/05/23/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/Hexo%E5%88%9B%E5%BB%BAtags%E5%92%8Ccategories%E9%A1%B5/","content":"引言效果展示过程创建tags和categories页结论引用\nHexo butterfly Cannot GET &#x2F;tags&#x2F; ||categories&#x2F;出现404\n\n\n","categories":["Tech","叶子的推荐小软件"]},{"title":"​RIME/Squirrel - 完全可控的输入世界","url":"/2023/05/23/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/RIME%E5%AE%8C%E5%85%A8%E5%8F%AF%E6%8E%A7%E7%9A%84%E8%BE%93%E5%85%A5%E4%B8%96%E7%95%8C/","content":"引言小众的需求只能用小众的方法解决，比如我作为一个 Dvorak 键盘 + 双拼使用者，顺便还有不喜欢联网输入的需求，就只能寻求一般人看起来很没用的输入法…\n\nRIME 是一个输入法引擎，全名是 RIME 中州韻輸入法引擎，是一款可以根据用户自己的偏好，进行全面设置的一款跨平台开源输入法引擎，在不同的操作系统有对应的发行版，比如在 Windows 中叫[小狼毫-weasel]，MacOS 平台下叫[鼠鬚管-Squirrel]，Linux 平台下叫[中州韻-ibus]。^[1]^\n\n如引用所叙，RIME 并不是一个输入法，而是一个输入法引擎，\n效果展示过程mac 默认文件修改位置：\n/Library/Input Methods/Squirrel.app/Contents/SharedSupport/\ndefault.yaml\n可以先挪出来然后覆盖回去\n默认输入方案切换键：\nctrl+shift+4\nrime 设置为默认简体将对应输入法的schema.yaml文件中加入reset: 1, 其中0是第一个states, 1是第二个^[6]^.\nswitches:  - name: ascii_mode    reset: 0    states: [中文，西文]  - name: full_shape    states: [半角，全角]  - name: simplification    reset: 1    states: [漢字，汉字]\n\n双语输入优化 Rime 英文输入体验 - Dvel’s Blog\ncurl -fsSL https://raw.githubusercontent.com/rime/plum/master/rime-install | bashcd /Users/tenney/Library/Rimebash ./plum/rime-install BlindingDark/rime-easy-en\n\nlinux 安装RimeWithIBus · rime&#x2F;home Wiki · GitHub\nsudo apt install ibus-rime\n\n输入法代号：ibus-rime\n用户资料夹：~/.config/ibus/rime/\n共享资料夹：/usr/share/rime-data/\n但是事实上要改主题方面，是不能像 mac 那样使用ibus的配置文件夹修改的，而是需要用到tweaker工具。\nGNOME 桌面可以使用扩展 IBus Tweaker。\nIBus Tweaker - GNOME Shell Extensions\n改了之后舒服太多了，不用重启。鄙人的字号是 48 哈哈哈哈。\n结论安全，舒适，折腾，真香。\n引用\n最棒的默认配置：Rime Squirrel 鼠须管输入法配置详解 - 三十年河東 (SSNHD.COM)-博客、分享、秒事\n配置介绍：MacOS 自然码双拼输入法 —— 鼠鬚管\n80m 搜狗字库：GitHub - 15cm&#x2F;rime-sogou-dictionaries: Rime 朙月拼音方案的扩充搜狗词库\nRime&#x2F;小狼豪&#x2F;鼠须管 输入法配置记\nRime 输入法指北 | Jiz4oh’s Life\n2018-11-07-rime 设置为默认简体 - ModerRAS\nUbuntu 上安装使用 ibus-rime（超实用） - keatonlao - 博客园\n\n","categories":["Tech","叶子的推荐小软件"]},{"title":"VS Code 插件推荐","url":"/2023/05/05/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/VS%20Code%E6%8F%92%E4%BB%B6%E6%8E%A8%E8%8D%90/","content":"引言VS Code是微软开发的的一款代码编辑器，既拥有高自由度、又拥有高性能和高颜值，最关键的是，VS Code还是一款免费并且有团队持续快速更新的代码编辑器。而VS Code之所以VS Code安装插件只需要点击图片所示按钮，即可进入插件区，在搜索框中输入插件名点击安装后，等待安装好即可点击重新加载重启VS Code使得插件生效。\n\n最推荐的必备软件Prettier - Code formatter\nPrettier 是一个固执己见的代码格式化程序。它通过解析代码并使用自己的规则重新打印代码来强制实现一致的风格，这些规则考虑了最大行长度，并在必要时包装代码。\n\n各种代码格式化，只关注格式化，并不具有eslint检查语法等能力，只关心格式化文件 (最大长度、混合标签和空格、引用样式等)，包括JavaScript·Flow·TypeScript·CSS·SCSS·Less·JSX·Vue·GraphQL·JSON·Markdown. 他很固执，实在是泰酷了。\nmarkdownlint - Visual Studio Marketplace[markdownlint - Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=DavidAnson.`VS Code&#96;-markdownlint)\n\nMarkdown 标记语言设计为易于阅读、编写和理解。它成功了——它的灵活性既是优点也是缺点。可能有多种样式，因此格式可能不一致。有些构造在所有解析器中都不能很好地工作，应该避免。例如，以下是一些常见&#x2F;麻烦的 Markdown 构造。markdownlint 是 Visual Studio 代码编辑器的扩展，其中包括一个规则库，用于鼓励 Markdown 文件的标准和一致性。它由 Node.js 的 markdownlint 库提供支持（其灵感来自 Ruby 的 markdowlint）。Linting 由 markdownload-cli2 引擎执行，该引擎可以与此扩展结合使用，为脚本和持续集成场景提供命令行支持。markdownload-cli2-action GitHub action 使用相同的引擎，可以与项目工作流集成。\n\n基于美学的markdown语法检查器，具有 40 条规则，助力写出最好看的markdown.\nCodeium - AI Coding Autocomplete and ChatCodeium: AI Coding Autocomplete and Chat for Python, Javascript, Typescript, Java, Go, and more - Visual Studio Marketplace\n\nCodeium 是现代编码超级 power，一个基于尖端人工智能技术的免费代码加速工具包。目前，Codeium 提供 70 多种语言的自动完成、聊天和搜索功能，速度极快，建议质量一流。现代编码工作流程中有许多部分是无聊、乏味或令人沮丧的，从反复使用样板到仔细阅读 StackOverflow。人工智能的最新进展使我们能够消除这些部分，从而无缝地将您的想法转化为代码。通过与 Visual Studio 代码的轻松集成和不到 2 分钟的安装过程，您可以专注于成为最好的软件开发人员，而不是最好的代码猴子。\n\n免费，支持语言多，无区域限制。\nProject Manager - Visual Studio MarketplaceProject Manager - Visual Studio Marketplace\n\n它可以帮助您轻松访问您的项目，无论它们位于何处。不要再错过那些重要的项目了。您可以定义自己的项目（也称为收藏夹），或者选择自动检测 Git、Mercurial 或 SVN 存储库、VS Code文件夹或任何其他文件夹。\n\n将任何文件夹或工作空间另存为项目，并提供快捷打开。\nRemote - SSH - Visual Studio Marketplace[Remote - SSH - Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=ms-`VS Code&#96;-remote.remote-ssh)\n\nRemote-SSH 扩展允许您使用任何带有 SSH 服务器的远程机器作为开发环境。这可以极大地简化各种情况下的开发和故障排除。您可以：在您部署到的同一操作系统上进行开发，或者使用比本地机器更大、更快或更专业的硬件。在不同的远程开发环境之间快速切换，并安全地进行更新，而不用担心影响您的本地计算机。从多台机器或多个位置访问现有的开发环境。调试在其他地方运行的应用程序，例如客户站点或云中。本地机器上不需要源代码就可以获得这些好处，因为扩展直接在远程机器上运行命令和其他扩展。您可以打开远程计算机上的任何文件夹并使用它，就像文件夹在您自己的计算机上一样。\n\n把服务器当本地用，从此告别各 STUDIO.\njsonhero.io tools for VS Code - Visual Studio Marketplace[jsonhero.io tools for VS Code - Visual Studio Marketplace](https://marketplace.visualstudio.com/items?itemName=JSONHero.jsonhero-`VS Code&#96;)\n\n在 jsonhero.io 中快速查看 JSON-一个美丽的 web JSON 查看器\n\n在本地可以轻松查看json分级。\n同样推荐的好用插件\nBetter Comments: 给注释加点色彩。\nCode Runner: 直接运行代码。\nDocker: 管理已安装Docker应用。\n&#96;&#96;VS Code-pandoc: 转换MD文件到各种格式。\nPaste Image: 快捷为MD插入图片，特别合适hexo使用。\nMarkdown Paste: 快捷为MD插入图片。\nPandoc Markdown Preview: 快速预览MD.\nHTML CSS Support: 自动补全样式表。\nEva Theme: 好看的主题，知乎经常推荐。\nMarkdown All in One: Markdown必备。\nopen in browser: 使用默认程序打开任何类型的文件，而不仅仅是 html 文件。\nAuto Rename Tag: 同步修改HTML&#x2F;XML标签。\nImage preview: 鼠标悬停可以预览图片。\n\n在用的软件\nColor Picker: 更好的颜色提取\nHighlight Matching Tag:高亮匹配标签\nImport Cost\n\n团队软件\nEditorConfig\n\n结论VS CODE和插件们相互成就。\n这就是开源的魅力！\n","categories":["Tech","叶子的推荐小软件"],"tags":["VS Code"]},{"title":"为了Markdown语法的美学 - markdownlint","url":"/2023/05/23/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/%E4%B8%BA%E4%BA%86Markdown%E8%AF%AD%E6%B3%95%E7%9A%84%E7%BE%8E%E5%AD%A6%20-%20markdownlint/","content":"为了Markdown语法的美学 - markdownlint引言效果展示过程结论引用\nmarkdownlint-VisualStudioMarketplace\n给你的 Markdown 挑挑刺——语法检查器入门与进阶\n\n\n","categories":["Tech","叶子的推荐小软件"]},{"title":"一种长寿可靠的网页中英分屏翻译方案 - Minja","url":"/2023/05/02/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/%E4%B8%80%E7%A7%8D%E9%95%BF%E5%AF%BF%E5%8F%AF%E9%9D%A0%E7%9A%84%E7%BD%91%E9%A1%B5%E4%B8%AD%E8%8B%B1%E5%88%86%E5%B1%8F%E7%BF%BB%E8%AF%91%E6%96%B9%E6%A1%88%20-%20Minja/","content":"引言效果展示过程结论引用\n一种长寿可靠的网页中英分屏翻译方案 - Minja\n\n","categories":["Tech","叶子的推荐小软件"],"tags":["翻译"]},{"title":"山西医科大学参考文献格式生成方案","url":"/2023/07/31/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E6%A0%BC%E5%BC%8F%E7%94%9F%E6%88%90%E6%96%B9%E6%A1%88_%E5%B1%B1%E8%A5%BF%E5%8C%BB%E7%A7%91%E5%A4%A7%E5%AD%A6/","content":"参考文献著录格式（国标GB／T7714-2015）专著（一）普通图书著录格式：\n[序号] 主要责任者. 普通图书名: 其他书名信息[普通图书标志&#x2F;文献载体标识]. 其他责任者. 版本项. 出版地: 出版者, 出版年: 引文页码. 获取和访问路径.\n简化写法：作者. 书名[M]. 出版地: 出版者, 出版年.\n（二）学位论文著录格式：\n[序号] 主要责任者. 学位论文名[D]. 保存地点: 保存单位, 年份. 获取和访问路径.\n（三）会议文集著录格式：\n[序号] 主要责任者. 会议文集名：会议文集其他信息[C]. 出版地：出版者，出版年. 获取和访问路径.\n析出文献（二）连续出版物中析出的文献（期刊论文等）著录格式：\n[序号] 析出文献主要责任者. 析出文献题名[文献类型标志]. 连续出版物题名: 其他题名信息, 年, 卷(期): 页码[引用日期]. 获取和访问路径.\n参考文献著录格式(山西医科大学本科毕业论文)（一）普通图书\n著作:[序号] 全部作者. 书名 [M] . 出版地: 出版者, 出版年: 页码.\n期刊:[序号] 全部作者. 文献题名 [J] . 刊名, 出版年, 卷号(期号): 起-止页码.\n电子文献:[序号] 全部作者. 电子文献题名 [文献类型&#x2F;载体类型] . 电子文献的出版或可获得地址(电子文献地址用文字表述), 发表或更新日期&#x2F;引用日期(任选).\n学位论文:[序号] 研究生; 导师. 文题. [XX学位论文]. 授予单位所在地: 授予单位, 授予年: 起～止页码.\n\n四步实现自定义 Zotero 参考文献格式\n关于Zotero参考文献格式调整\n[Zotero]一些大学学位论文Zotero样式（更新）\nword processor plugin usage    [Zotero Documentation]\n[Zotero]如何在Word中插入参考文献\nZotero茉莉花插件，一键抓取知网文献\nJasminum - 茉莉花\n参考文献著录格式（国标GB／T7714-2015）\n[Zotero]批量修改条目（文献）语言\n\n–reference-doc&#x3D;&#x2F;Users&#x2F;tenney&#x2F;ResilioSync&#x2F;ResilioSync&#x2F;sync&#x2F;pandoc&#x2F;templ.docx\n","categories":["Tech","叶子的推荐小软件"],"tags":["参考文献","Zotero"]},{"url":"/2023/05/29/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/%E5%B1%B1%E8%A5%BF%E5%8C%BB%E7%A7%91%E5%A4%A7%E5%AD%A6%E6%AF%95%E4%B8%9A%E8%AE%BA%E6%96%87%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E8%91%97%E5%BD%95%E6%A0%BC%E5%BC%8F%E7%9B%B8%E5%85%B3%E7%9A%84CSL%E6%A0%B7%E5%BC%8F/","content":"山西医科大学毕业论文参考文献著录格式相关的CSL样式具体效果Zotero[1] Reichhardt T. It’s sink or swim as a tidal wave of data approaches[J]. Nature, 1999, 399(6736): 517-520.[2] 冯璐, 冷伏海. 共词分析方法理论进展[J]. 中国图书馆学报, 2006(2): 88-92.[6] 冷伏海, 李宏, 王建芳, 惠仲阳, 张秋菊, 陈晓怡, 葛春雷, 刘栋, 叶京, 贾晓琪, 李超, 艾超, 曹华俊. 面向2030年的人与科技发展愿景研究[J]. 中国科学院院刊, 2021, 36(2): 199-207.[3] 铁铮, 姜朝晖. 延期毕业，利弊几何？[N]. 中国教育报, 2016-03-23: 002.[4] 毛俊超. 概率方法在组合数学中的应用[D]. 中国海洋大学, 2007.[5] 高志亮. 论文集前言——数字经济是数字化、数据与数字技术多元动力系统的结果[C], 数据社会与数字经济暨“一带一路”合作国际学术会议论文集. 长安大学智慧油气田研究院、长安大学数据实验与研究中心、广东财经大学数字经济学院、广东财经大学中国数据研究院, 2022: 18-23.\n\n规范模板[3]Reichhardt T. It&#x27;s sink or swim as a tidal wave of data approaches [J] . Nature, 1999, 399(6736): 517-520.[2]冯璐, 冷伏海. 共词分析方法理论进展 [J] . 中国图书馆学报, 2006, (02): 88-92.[9]铁铮. 生物多样性价值几何[N] . 中国教育报, 2005, 5(6): 3.[4]郑开青, ×××. 通讯系统模拟及软件. [XX学位论文]. 北京: 清华大学, 1987: 1-5.[10]赵艳. 影响采摘后芦笋中类黄酮积累的因素研究 [A]. 食品安全监督与法制建设国际研讨会暨第二届中国食品研究生论坛论文集(下) [C], 2005年.\n\n目前功能可自动完成\n期刊:[序号] 全部作者. 文献题名 [J] . 刊名, 出版年, 卷号(期号): 起-止页码.\n报纸文章:[序号]全部作者. 文献题名 [N]．报纸名, 出版年, 月(日): 版次.\n\n其中, 中文期刊要求卷号(期号)与示例不符, 以要求为准.\n可半自动完成\n学位论文:[序号] 研究生; 导师. 文题. [XX学位论文]. 授予单位所在地: 授予单位, 授予年: 起～止页码.\n电子文献:[序号] 全部作者. 电子文献题名 [文献类型&#x2F;载体类型] . 电子文献的出版或可获得地址(电子文献地址用文字表述), 发表或更新日期&#x2F;引用日期(任选).\n\n可自动填入信息, 但不完全符合标准.\n不可实现\n著作&#x2F;技术标准, 未能在CNKI检索到.\n专利, 不可由Zotero Connector(插件)识别.\n\n使用方法软件:\n\nOffice Word (不能WPS)\nZotero\nJasminum - 茉莉花\n\n\n\n下载链接https://wwao.lanzoub.com/iIKtE0xk7ulc\n包含:\n\nsxmu-medical-university.csl\njasminum-v0.2.6.xpi\n\n参考\n[Zotero]如何在Word中插入参考文献\nZotero茉莉花插件，一键抓取知网文献\nJasminum - 茉莉花\n\n"},{"title":"使用 WineZGUI 在 linux 上安装 exe","url":"/2024/10/15/Tech/Linux/linux%E5%AE%89%E8%A3%85exe/","content":"引言效果展示过程sudo dpkg --add-architecture i386sudo apt install zenity wine winetricks libimage-exiftool-perl icoutils gnome-terminal# 安装 flatpaksudo apt install flatpaksudo apt install gnome-software-plugin-flatpakflatpak remote-add --if-not-exists flathub https://dl.flathub.org/repo/flathub.flatpakrepo# 安装 WineZGUIsudo -E flatpak install flathub io.github.fastrizwaan.WineZGUI\n\n结论引用\nWineZGUI\n在 Linux 上使用 WineZGUI 运行 Windows 应用和游戏 | Linux 中国\n\n","categories":["Tech","Linux"],"tags":["Linux"]},{"title":"纯图 ppt 的优势和转换方法","url":"/2024/10/29/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/%E7%BA%AF%E5%9B%BEppt%E7%9A%84%E4%BC%98%E5%8A%BF%E5%92%8C%E8%BD%AC%E6%8D%A2%E6%96%B9%E6%B3%95/","content":"引言纯图 PPT，顾名思义，是将所有内容以图片形式展示的 PPT。这种形式可以保持内容的高度一致性，不会因设备或软件版本的不同而出现错位或排版问题。以下是它的主要优势及转换方法。\n纯图 PPT 的优势\n避免字体兼容性问题无论在什么设备上打开，文字风格、布局都不会变化，避免了因为缺少特定字体导致的内容错乱。\n\n提升观感一致性纯图 PPT 保留了设计原稿的排版和美感，适用于展示设计、品牌形象等对视觉效果要求较高的场合。\n\n防止内容被随意复制转换为图片后，内容不易被直接编辑和复制，适合对知识产权有保护需求的文件。\n\n文件小且兼容性好图片形式的 PPT 通常体积小，加载速度快，对低配置设备和不同版本的软件更友好。\n\n\n转换方法当然选择导出成图片然后一张一张放回去是可以的，但是没有必要，有更好的办法可以选择。\n本文提供的方法是：\n导出为 PDF，再转为 PPT将 PPT 内容转换为 PDF 是实现纯图 PPT 的关键步骤。以下是两种常用的 PDF 导出方法：\n\n使用 WPS 转 PDF\n\n免费导出 PDF：在 WPS 中，点击“文件”→“导出为 PDF”，即可免费将 PPT 直接转换成 PDF 文件。\n会员导出高质量 PDF：在 WPS 会员功能下，选择“输出 PDF”以获得更高的图像分辨率和质量。\n\n\n使用 Office PPT 导出图片并拼接成 PDF\n\n导出图片：在 Microsoft Office 中，选择“文件”→“另存为”，将每页幻灯片单独保存为高分辨率的图片（如 PNG 或 JPEG）。\n拼接成 PDF：使用 PDF 制作软件（如 Adobe Acrobat、Foxit PDF Editor 或在线工具），将导出的图片按页顺序拼接成 PDF 文件。\n\n\n\n将 PDF 转为 PPT转换完成的 PDF 可直接用于展示，或借助一些工具将 PDF 转为 PPT 形式，实现每页仅包含一张图片的纯图效果。\n工具可以使用在线工具如 Stirling PDF 或 https://www.pdf.to 等。\n推荐在线工具地址：\n\nhttps://www.pdf.to\nhttps://stirlingpdf.io/pdf-to-presentation\n\n当然最好在本地搭建一个 Stirling PDF 的服务器，这样更方便。\n注意事项\n之所以有时候会用到多个导出或转换工具，是因为工具原理不一样效果可能不一样，所以如果效果不好可以多试几个工具。\n确保图片的分辨率较高（建议 300 DPI 以上），以免影响展示效果。\n转换完成后，可将 PPT 另存为 PDF 进一步减少体积，并适合跨平台分享。\n\n结论学术 ppt 最重要的部分就是简洁，格式标准，所以力求不要动画效果但内容凝练，非常适合做成纯图 ppt。\n篇外代码方法使用 Python 的 Aspose.Slides 库将 PPT 转换为图片。\n将代码和 PPT 文件放在同一个文件夹下，运行代码即可。\nimport aspose.slides as slidesimport aspose.pydrawing as drawingpres = slides.Presentation(&quot;*.pptx&quot;)for sld in pres.slides:    bmp = sld.get_thumbnail(1, 1)    bmp.save(&quot;Slide_&#123;num&#125;.jpg&quot;.format(num=str(sld.slide_number)), drawing.imaging.ImageFormat.jpeg)\n","categories":["Tech","叶子的推荐小软件"],"tags":["纯图 ppt","office"]},{"title":"文件传输软件推荐","url":"/2023/04/30/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/%E7%BD%91%E9%A1%B5%E6%96%87%E4%BB%B6%E4%BC%A0%E8%BE%93%E8%BD%AF%E4%BB%B6/","content":"引言以前介绍过一款无需下载的局域网文件传输服务 - snapdrop ，用于免登录网页文件传输，但经过使用和反馈发现存在着无法搜索到设备、连接失败的问题，所以这次又带来了几个可用于文件传输的工具推荐。\n网页文件传输文叔叔\n类似于原来的空投，可传送文本，可以钥匙串、网页链接、取件码形式分享, 文件过期时间是24h, 未登录用户每次向他人发送的文件（或文件夹）最大支持 500 个. 无论是否登录最大上传单个文件大小均为 5GB 。超过 50.00MB 的文件最多可以下载 2 次, 下载、预览次数用完后，每 30 分钟系统会自动赠送 1 次（直到充满 2 次）。\njidrop\n\njidrop 除了 snapdrop 可以直接配对局域网设备的功能外，还提供了配对码匹配的功能。从提示可以看出，此功能并非是利用局域网传输，而是使用互联网，因此即使设备处于不同网络可尝试配对连接。\nApp文件传输此类软件用于本地传输均比较稳定，缺点是都需要下载各端的App。优点是使用简单、速度快、安全。\nLANDrop\n支持平台: iOS, Android, macOS, Windows, Linux\nLocalSend\n支持平台: iOS, Android, macOS, Windows, Linux\n速享 - speed_share\n平台：Windows &#x2F; macOS &#x2F; Android &#x2F; Linux\n速享除主流的文件传输功能外，还支持剪贴板同步和网页版分享的功能，高级版用户还支持浏览设备中的所有文件。但本人以MacOS和IOS设备测试网页版传输文件失败，可能在Windows设备上会有更好的表现。\n\n结论文件传输软件可以说是打工人的”钢需”，有需求不断地进行更新换代。最少不能像是因为某W开头的软件的升级而导致文件无法编辑，对吧？\nW姓软件解决方案​Windows+Quicker自动清除微信接收文件的只读标记\nMacOS+fswatch微信文件变成「只读」？我用 ChatGPT 找到了解决方法\n注：本人未使用本方案，而是使用了拖至项目文件夹编辑的方式，原因是将文件留在微信接收文件夹不方便整理且会不断冒出+1+1+1。\n引用\n派评 | 近期值得关注的 App - 少数派\nJiDrop - 跨设备文件互传\n文叔叔 - 传文件，找文叔叔（永不限速）\nLANDrop - Drop any files to any devices on your LAN\nLocalSend\nGitHub - nightmare-space&#x2F;speed_share: Speed Share is a highly available file sharing terminal on LAN(local area network) like airdrop developed by flutter framework.\n\n","categories":["Tech","叶子的推荐小软件"],"tags":["文件传输","file-transfer"]},{"title":"文献翻译阅读应用推荐","url":"/2023/04/21/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/%E6%96%87%E7%8C%AE%E7%BF%BB%E8%AF%91%E9%98%85%E8%AF%BB%E5%BA%94%E7%94%A8%E6%8E%A8%E8%8D%90/","content":"在线翻译服务PDF文件翻译Free Online Translator网址:\nhttps://www.onlinedoctranslator.com/zh-CN/translationform\n无需登录, 保留原格式的PDF文件翻译器，如验证码无法通过大概率是机场质量差，无解决方法。\n使用方法:\n将文件拖入上传区，选择语言后点击转换，完成后自动下载。\n\n\nFree Online Translator - Preserves your document’s layout (PDF, Word, Excel, PowerPoint, OpenOffice, text)\nAI技术ChatPDFhttps://www.chatpdf.com\n本地翻译软件小绿鲸英文文献阅读器——专注提高SCI阅读效率\n一键翻译PDF文献，保留原文格式\n支持下载Word版\n\n知云自带含注释功能的PDF阅读器！多翻译引禁切换，支持中英互译！特有学术引華优化，翻译质量好！选中段落、句子、单词立即翻泽！支持输入或粘贴文宇进入翻译！免费使用，使用门槛低！\n\n知云文献翻译官网-官方指定最新知云文献翻译及Xtranslator-win+mac版下载页面\n","categories":["Tech","叶子的推荐小软件"],"tags":["文献阅读","叶子的神奇小软件"]},{"title":"Markdown 添加参考文献并同时应用于 Word","url":"/2024/01/03/Tech/zotero/Markdown%E6%B7%BB%E5%8A%A0%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E5%B9%B6%E5%90%8C%E6%97%B6%E5%BA%94%E7%94%A8%E4%BA%8EWord/","content":"引言效果展示过程结论引用\n加入参考文献，Markdown 完美转化成 Word - 倔强的小蜗牛\n\n","categories":["Tech","zotero"]},{"title":"zotero 参考文献格式修改 (csl)","url":"/2023/12/22/Tech/zotero/zotero%E5%8F%82%E8%80%83%E6%96%87%E7%8C%AE%E6%A0%BC%E5%BC%8F%E4%BF%AE%E6%94%B9(csl)/","content":"引言效果展示过程结论引用\nZotero 修改或自定义参考文献格式（csl） - 知乎\nVisual CSL Editor\n超实用！zotero 引用文献自定义 CSL 全流程 - 知乎\n几个 Zotero 引文样式 csl（GB&#x2F;T 7714-2015） - 知乎\n\n","categories":["Tech","zotero"]},{"title":"利用 zotero-arxiv-daily 获取最相关每日文献","url":"/2025/08/15/Tech/zotero/%E5%88%A9%E7%94%A8zotero-arxiv-daily%E8%8E%B7%E5%8F%96%E6%9C%80%E7%9B%B8%E5%85%B3%E6%AF%8F%E6%97%A5%E6%96%87%E7%8C%AE/","content":"引言对每一个研究人员来说，获取并阅读最新文献都是必要的，但是很难有人能坚持并有足够的时间去筛选和整理这些信息。但是借助一些方便的工具可以帮我们完成这项重复性劳动。\nzotero-arxiv-daily 是一个基于 arxiv 网站、zotero 文献库和 llm 的自动化工具。其中，arxiv 是一个开放的学术论文预印本库，zotero 是一个强大的文献管理工具 (被用于判断与研究者本人相关性) 。\n简单的说，zotero-arxiv-daily 可以根据用户的 zotero 文献库，自动推荐与用户兴趣相关的最新 arxiv 论文，并将其发送到邮箱中。\n效果展示\n过程我将过程分为三步，一是配置到 github actions 完成自动发送，二是修改部分文件以适配自己的需求，三是使用 keepalive workflow 保活。\n如果就是简简单单能用就行光第一步就足够了。\n基础配置使用这一部分的要点是配置好 github actions, 需要注意的点是获取 zotero 的 apikey 和 llm 的 apikey。\n这里使用的最简单的方法也就是 github actions, 优点是免费文档。如官方文档所述，需要三步，一是 fork 代码仓库，二是配置 secrets，三是配置 workflow。\n需要的 secrets 如下：\n\nARXIV_QUERY: 目标 arxiv 论文的类别。使用 + 连接多个类别。\nZOTERO_ID: zotero 的用户 ID，可以在 zotero 的设置中找到。\nZOTERO_KEY: zotero 的 API key，可以在 zotero 的网页设置 - 安全中生成。\nRECEIVER: 接收文献的邮箱地址。\nSENDER: 发送文献的邮箱地址。\nSENDER_PASSWORD: 发送邮箱的密码&#x2F;认证码，gmail 等是密码，qq 等是邮箱认证码 (可在设置中 SMTP 部分找到，注意只有生成的时候显示一次，自己保留好可以一直用)。\nSMTP_PORT: SMTP 端口号。\nSMTP_SERVER: SMTP 服务器地址。\nUSE_LLM_API: 是否使用 LLM API。\nOPENAI_API_BASE: OpenAI API 基础地址。\nOPENAI_API_KEY: OpenAI API 密钥。\nMODEL_NAME: LLM 模型名称。\n\n官方推荐使用 SiliconFlow 的模型，这是一个开源模型聚合平台，推荐的模式是Qwen/Qwen2.5-7B-Instruct, 因为这个模型的免费性能好而且输入参数是标准的，后面将讲一下不标准的输入应该怎么办。\n如果使用 SiliconFlow 的话这几个参数示例是这样的：\n\nOPENAI_API_BASE: https://api.siliconflow.cn/v1\nOPENAI_API_KEY: OpenAI API 密钥。\nMODEL_NAME: Qwen&#x2F;Qwen2.5-7B-Instruct\n\n温馨提示，一般 OPENAI_API_BASE 后面不带 chat&#x2F;completions, 而是以 v1 结尾，注意不是v1/而是v1。\n但是不知道从什么时候开始我老是登不上 SiliconFlow 的官网，所以我更喜欢魔搭的模型，魔搭的模型是免费的，每天有 2000 次调用限制，\n这是魔搭可以使用的免费模型列表：\nModelScope - 模型列表页\n修改部分文件以适配自己的需求注意，如果使用魔搭，有些模型比如 Qwen&#x2F;Qwen3-235B-A22B 的输入参数是非标准的，所以需要修改代码。\n如果 fork 我修改后的库而不是官方库不用修改直接使用。\nsandy9707&#x2F;zotero-arxiv-daily\n关键在于添加 extra_body 的 enable_thinking 部分和调整 stream 的输入参数。\n参考官方文档：\nmodelscope - API 推理介绍\n### 上文    self.lang = lang    self.extra_body = &#123;                &quot;enable_thinking&quot;: False  # 默认禁用思考功能，可根据需要调整                # &quot;thinking_budget&quot;: 4096  # 可选参数，控制思考的 token 数量        &#125;def generate(self, messages: list[dict]) -&gt; str:        if isinstance(self.llm, OpenAI):            logger.debug(f&quot;Generating content with model: &#123;self.model&#125;&quot;)            try:                # 根据模型名称动态调整请求参数                if self.model == &quot;Qwen/Qwen3-235B-A22B&quot;:                    logger.debug(&quot;Using optimized request scheme for Qwen/Qwen3-235B-A22B&quot;)                    response = self.llm.chat.completions.create(                        messages=messages,                        temperature=0,                        model=self.model,                        stream=False,  # 显式设置为非流式输出                        extra_body=self.extra_body  # 传递 extra_body 参数                    )### 下文\n\n使用 keepalive workflow 保活GitHub Actions 为了防止资源滥用，有一个限制：如果一个代码仓库在 60 天 内没有任何 push (推送) 操作，GitHub 会自动禁用该仓库所有的计划任务 (scheduled workflows)。对于像 zotero-arxiv-daily 这样依赖定时运行（例如每天运行一次）的项目来说，这无疑是太繁复的。\n很多用户可能只是“一次配置，永久使用”，并不会频繁去修改代码。为了解决这个问题，我们可以使用一个现成的、广受欢迎的 Action：gautamkrishnar&#x2F;keepalive-workflow。这个 Action 会在指定的时间（例如每周一次）自动向你的仓库推送一个微小的、无冲突的变更，从而保持仓库的活跃状态，它的唯一目的就是定期对仓库进行一次无意义的写入操作，模拟人工更新，从而重置 60 天的计时器。\n创建新的 Workflow 文件在你的项目仓库中，进入 .github&#x2F;workflows&#x2F; 目录，创建一个新的 YAML 文件，例如 keepalive.yml。\n编辑 Workflow 文件将以下内容粘贴到 keepalive.yml 文件中：\nname: Keep Repo Alive (Manual)on:  workflow_dispatch:  schedule:    - cron: &#x27;0 0 */25 * *&#x27;jobs:  keep-alive:    runs-on: ubuntu-latest    permissions:      contents: write # 必须提供写入权限    steps:      - name: Checkout repository        uses: actions/checkout@v4      - name: Create or update a file to trigger commit        run: |          # 创建一个时间戳文件，每次运行内容都会变化，确保有东西可提交          date &gt; last_updated.txt      - name: Commit and push changes        run: |          # 配置 git 用户          git config --global user.name &#x27;my-bot&#x27;          git config --global user.email &#x27;my-bot@users.noreply.github.com&#x27;          # 添加更改并提交          git add last_updated.txt          # 使用 &quot;git diff-index --quiet HEAD&quot; 检查是否有改动          # 如果没有改动（比如文件内容没变），就不执行 commit 和 push，避免报错          if ! git diff-index --quiet HEAD; then            git commit -m &quot;🚧 keepalive: auto-commit on $(date)&quot;            git push          else            echo &quot;No changes to commit.&quot;          fi\n\n如果按 ai 给的默认方案走会，遇到一个权限问题，然后会让你生成一个 pat token 来给予权限然后使用$调用，但是实际上你只需要在 permissions 中添加 contents: write 即可。\npermissions:      contents: write\n\n结论我对阅读的想法是”好读书不求甚解”, 特别对于研究来说，不必去追求每一步都完全读透，重要的是获取最新的信息和灵感。一是只有论文读的够多，才能读懂，而不是对着一篇精读就能全部读懂。二是论文都是别人的研究，而不是自己的研究，要从中汲取养分而不是生搬硬套。\n因此，我认为利用 zotero-arxiv-daily 这样的工具可以帮助我们提高水平，节省时间和精力。哪怕一天能读一篇摘要呢？\n引用\nGitHub - TideDra&#x2F;zotero-arxiv-daily: Recommend new arxiv papers of your interest daily according to your Zotero libarary.\n\n","categories":["Tech","zotero"],"tags":["zotero","arxiv"]},{"title":"预训练模型集成库 Transformers (Hugging Face)","url":"/2023/12/02/Tech/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/Hugging%20Face/","content":"引言HuggingFace 是一个提供对各种语言模型（包括 ChatGPT-4）访问的平台。\nhttps://huggingface.co\n效果展示过程结论引用\nHugging Face：史上 star 增长最快的开源创业公司 - 知乎\n🤗 Transformers 简介\n\n","categories":["Tech","机器学习"]},{"title":"使用 sklearn 进行机器学习","url":"/2023/11/01/Tech/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E4%BD%BF%E7%94%A8sklearn%E8%BF%9B%E8%A1%8C%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/","content":"引言效果展示过程结论引用\nsklearn.svm.SVC — scikit-learn 1.3.2 documentation\n\n","categories":["Tech","机器学习"]},{"title":"机器学习 xgboost 参数价值和调整方法","url":"/2023/10/31/Tech/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0xgboost%E5%8F%82%E6%95%B0%E4%BB%B7%E5%80%BC%E5%92%8C%E8%B0%83%E6%95%B4%E6%96%B9%E6%B3%95/","content":"引言知其然而不知其所以然的态度做学问迟早要吃大亏的，不如说是前期工作做的越多越好，后期就会越爽越轻松。机器学习方面，虽然大家都是调参小子，但是随便调只为了拟合测试集肯定是不对的，所以我认为好好看看每个参数代表什么是很有必要的。这次主要看的是 xgboost 的参数详情，来自官网[1].\n参数详情部分翻译来源于[2], 详细说明参照官网[3].\n通用参数booster [默认&#x3D;gbtree]描述：选择要使用的提升器类型，可以是 gbtree（树模型）、gblinear（线性模型）或 dart（Dropouts meet Multiple Additive Regression Trees）。\ndevice [默认&#x3D;cpu]描述：XGBoost 运行的设备选择，可设置为以下值：cpu: 使用 CPU。cuda: 使用 GPU（CUDA 设备）。cuda::  是指定要使用的 GPU 的序数（如果有多个设备）。gpu: 默认 GPU 设备选择，从可用且受支持的设备列表中选择。目前只支持 cuda 设备。gpu:: 默认 GPU 设备选择，从可用且受支持的设备列表中选择。目前只支持 cuda 设备。\nverbosity [默认&#x3D;1]描述：打印消息的详细程度。有效值为 0（无输出）、1（警告）、2（信息）、3（调试）。validate_parameters [默认为 false，除了 Python、R 和 CLI 接口]:描述：当设置为 True 时，XGBoost 将验证输入参数，以检查参数是否被正确使用。如果存在未知参数，将发出警告。\nnthread [默认为可用的最大线程数]描述：用于运行 XGBoost 的并行线程数，应考虑线程争用和超线程。\ndisable_default_eval_metric [默认&#x3D;false]描述：禁用默认评估指标。设置为 1 或 true 可禁用默认评估指标。\n树提升器参数eta [默认&#x3D;0.3，别名：learning_rate]描述：用于更新的步长缩减。在每次提升计算之后，算法会直接获得新特征的权重。eta 缩小特征权重，使提升过程更加保守，防止过拟合。\n取值区间：[0,1]\ngamma [默认&#x3D;0，别名：min_split_loss]描述：要进行叶节点进一步划分所需的最小损失减小量。gamma 越大，算法越保守，越不容易过拟合。\n取值区间：[0，∞]\nmax_depth [默认&#x3D;6]描述：树的最大深度。增加此值会使模型更复杂，更容易过拟合。0 表示没有深度限制。\n取值区间：[0，∞]\nmin_child_weight [默认&#x3D;1]描述：子节点所需的最小实例权重之和 (决定最小叶子节点样本权重和)，加权和低于这个值时，就不再分裂产生新的叶子节点。当它的值较大时，可以避免模型学习到局部的特殊样本。但如果这个值过高，会导致欠拟合。\n取值区间：[0，∞]\nmax_delta_step [默认&#x3D;0]描述：允许每个叶节点输出的最大增量。如果设置为 0，表示没有限制；设置为正值有助于使更新步骤更加保守。\n取值区间：[0，∞]\nsubsample [默认&#x3D;1]描述：训练实例的子样本比率。设置为 0.5 表示 XGBoost 会在生长树之前随机采样一半的训练数据，以防止过拟合。\n取值区间：(0,1]\nsampling_method [默认&#x3D;uniform]描述：用于采样训练实例的方法。uniform 表示每个训练实例具有相等的被选中概率；gradient_based 表示选择概率与梯度的绝对值正则化成正比。\n取值区间：[uniform, gradient_based]\ncolsample_bytree, colsample_bylevel, colsample_bynode [默认&#x3D;1]描述：用于列抽样的参数，控制特征的子样本比率。colsample_bytree 用于构建每棵树时对列进行抽样，colsample_bylevel 用于每层进行列抽样，colsample_bynode 用于每个节点进行列抽样。\n取值区间：(0,1]\nlambda [默认&#x3D;1，别名：reg_lambda]描述：L2 正则化权重项。增加此值会使模型更保守。\n取值区间：[0，∞]\nalpha [默认&#x3D;0，别名：reg_alpha]描述：L1 正则化权重项。增加此值会使模型更保守。\n取值区间：[0，∞]\nee_method [默认&#x3D;auto]描述：XGBoost 中使用的树构建算法。可以是 auto、exact、approx、hist 等。\nscale_pos_weight [默认&#x3D;1]描述：用于平衡正负权重的参数，对于不平衡的类别很有用。\nupdater描述：用于定义树更新器的顺序的参数，提供了构建和修改树的模块化方式。\nrefresh_leaf [默认&#x3D;1]描述：刷新更新器的参数，用于控制是否更新树叶节点及其统计信息。\nprocess_type [默认&#x3D;default]描述：用于控制提升过程的类型，可以是 default 或 update。\ngrow_policy [默认&#x3D;depthwise]描述：控制新节点添加到树中的方式，仅支持 hist 或 approx 时使用。\nmax_leaves [默认&#x3D;0]描述：要添加的最大节点数，不用于 exact 树方法。\nmax_bin [默认&#x3D;256]描述：仅用于 hist 或 approx 时，指定连续特征的离散化分桶数量。\nnum_parallel_tree [默认&#x3D;1]描述：在每次迭代期间构建的并行树数量，用于支持增强的随机森林。\nmonotone_constraints描述：用于控制变量单调性的约束。\ninteraction_constraints描述：用于表示允许的交互作用的约束。\nmulti_strategy [默认&#x3D;one_output_per_tree]不知道哪来的参数seed随机数种子，相同的种子可以复现随机结果，用于调参！\nn_estimators在 XGBoost 中，n_estimators 参数指定了要构建的提升树（boosting tree）的数量。具体来说，它表示 boosting 迭代的次数，每次迭代会构建一棵树。这个参数对于控制模型的复杂度和性能非常重要。\n每次迭代，XGBoost 会根据前一轮的模型性能，构建一颗新的树来纠正前一轮的误差。n_estimators 的值决定了模型将拟合多少颗这样的树。增加 n_estimators 的值通常可以提高模型的性能，但需要更多的时间来训练模型。但需要注意，如果 n_estimators 设置得太大，可能会导致过拟合。\n通常，你可以通过交叉验证来选择合适的 n_estimators 值，以平衡模型的性能和训练时间。\n评价指标准确率、精确率、召回率、F1 分数、ROC 曲线和 AUC\n过程结论引用\nXGBoost Documentation — xgboost 2.1.0-dev documentation\n使用 GridSearch 对 xgboost 进行调参（全部流程）_gridsearchcv xgboost-CSDN 博客\nXGBoost Parameters — xgboost 2.1.0-dev documentation\n\n","categories":["Tech","机器学习"],"tags":["Python"]},{"title":"机器学习自动化调参","url":"/2023/10/31/Tech/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%87%AA%E5%8A%A8%E5%8C%96%E8%B0%83%E5%8F%82/","content":"引言效果展示过程autoML[2]安装[3]\nconda install gxx_linux-64 gcc_linux-64 swigconda install auto-sklearn\n\n结论引用\ntpot\nAutoML: Ensemble！自動化集成學習戰力大評比 — — AutoKeras vs. Auto-Sklearn vs. TPOT vs. FLAML | by Alan Wang | Medium\nInstallation — AutoSklearn 0.15.0 documentation\n\n","categories":["Tech","机器学习"],"tags":["Python"]},{"title":"机器学习输入数据应该如何标准化","url":"/2023/10/30/Tech/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0%E8%BE%93%E5%85%A5%E6%95%B0%E6%8D%AE%E5%BA%94%E8%AF%A5%E5%A6%82%E4%BD%95%E6%A0%87%E5%87%86%E5%8C%96/","content":"引言效果展示过程选用指引机器学习数据标准化的六种方法[1]\n\nif data == &#x27;Non-Normal Distribution&#x27;:    try power_transformelif data contains outliers:    try robust_scaleelse:    try minmax_scaleif data == &#x27;Normal Distribution&#x27;:    try scale, normalize\n\n判断是否满足正态分布的方法[2,3,4,5]\n是否归一化在机器学习中，基因表达量通常使用测序数据的读取计数或归一化读取计数作为值。这些值可以通过 RNA 测序（RNA-seq）获得，这是一种使用高通量测序技术来识别和定量转录 RNA 的方法。然后，这些读取计数可以进一步归一化以消除实验偏差和技术偏差。\n例如，常见的归一化方法包括 TPM（每百万转录本）和 FPKM（每千基因每百万映射）或 RPKM（每千基因每百万映射）。这些方法考虑了基因长度和测序深度的影响，使得不同样本之间的基因表达量可以进行比较。\n然后，这些值可以用作机器学习模型的输入特征，例如用于预测疾病状态或疾病亚型。然而，由于基因表达数据通常具有高维度、噪声多和样本少的特点，因此在使用机器学习模型处理基因表达数据时，需要采取适当的特征选择和模型选择策略。此外，还需要进行适当的交叉验证来评估模型的性能。\n在机器学习中，基因表达量通常使用测序数据的读取计数或归一化读取计数作为值。这些值可以通过 RNA 测序（RNA-seq）获得，这是一种使用高通量测序技术来识别和定量转录 RNA 的方法。然后，这些读取计数可以进一步归一化以消除实验偏差和技术偏差。\n例如，常见的归一化方法包括 TPM（每百万转录本）和 FPKM（每千基因每百万映射）或 RPKM（每千基因每百万映射）。这些方法考虑了基因长度和测序深度的影响，使得不同样本之间的基因表达量可以进行比较。\n然后，这些值可以用作机器学习模型的输入特征，例如用于预测疾病状态或疾病亚型。然而，由于基因表达数据通常具有高维度、噪声多和样本少的特点，因此在使用机器学习模型处理基因表达数据时，需要采取适当的特征选择和模型选择策略。此外，还需要进行适当的交叉验证来评估模型的性能。\n结论引用\n机器学习数据标准化的六种方法 - 知乎\nPython 篇 | 正态性检验方法详解 - 知乎\n用 Python 检验数据正态分布的几种方法 - 知乎\nscipy.stats.normaltest — SciPy v0.14.0 Reference Guide\n二元对数正态分布 (bivariate lognormal distribution) 的几个性质_bivariate normal-CSDN 博客\nPython Scipy stats.normaltest() 用法及代码示例 - 纯净天空\n【答疑解惑-II】——不满足正态分布的数据到底能不能用 Gaussian process 的方法呢？ - 知乎\n\n","categories":["Tech","机器学习"],"tags":["python","机器学习"]},{"title":"利用 FFmpeg 批量添加视频水印","url":"/2025/03/09/Tech/%E8%A7%86%E9%A2%91%E5%88%B6%E4%BD%9C%E7%9B%B8%E5%85%B3/%E5%88%A9%E7%94%A8FFmpeg%E6%89%B9%E9%87%8F%E6%B7%BB%E5%8A%A0%E8%A7%86%E9%A2%91%E6%B0%B4%E5%8D%B0/","content":"引言在当今的数字时代，视频已成为信息传播和品牌推广的重要载体。然而，随着视频内容的广泛传播，如何保护版权、提升品牌辨识度成为许多创作者和企业面临的难题。手动为视频添加水印费时费力，而批量处理则能大幅提升效率。本文将带你了解如何利用 FFmpeg 这一强大工具，结合 Python 编程，实现视频的批量水印添加，让你的视频处理更加高效、智能！\n为什么需要批量为视频添加水印？视频批量添加水印的需求源于以下几个常见场景：\n\n版权保护：通过在视频中嵌入专属标识（如名字或 Logo），可以有效防止未经授权的盗用或篡改。\n品牌宣传：水印可以作为品牌符号或口号，在视频传播中不断强化观众对品牌的认知。\n内容管理：为视频添加文字说明、时间戳或版本信息，有助于快速识别内容或用途。\n\n当视频数量较少时，手动添加水印或许还能应付。但面对数十甚至数百个视频时，手动操作不仅耗时，还容易出错。这时，自动化批量处理就显得尤为重要。借助工具，我们可以一次性为所有视频添加水印，省时省力。\nFFmpeg：多媒体处理的“万能工具”FFmpeg 的由来FFmpeg 是一个开源的多媒体处理工具，诞生于 2000 年，由 Fabrice Bellard 发起。其名称“FFmpeg”意为“Fast Forward MPEG”，最初专注于快速处理 MPEG 视频。经过二十多年的发展，它已成为多媒体领域的“瑞士军刀”，广泛应用于视频编辑、格式转换等领域。\nFFmpeg 的功能FFmpeg 功能强大，几乎能满足所有音视频处理需求，包括：\n\n格式转换：将视频从 MP4 转为 AVI，或音频从 MP3 转为 WAV。\n视频编辑：剪辑、合并、调整分辨率等。\n滤镜应用：添加水印、字幕，或调整亮度、对比度。\n流媒体支持：录制和播放实时流媒体。\n\n在本文中，我们将重点利用 FFmpeg 的 drawtext 滤镜功能，为视频添加文字水印。\n使用 FFmpeg 为视频添加水印FFmpeg 通过命令行操作，简单几行命令就能为视频添加水印。以下是基本用法：\nFFmpeg 的安装以 mac 为例，使用 Homebrew 安装 FFmpeg：\nbrew install ffmpeg\n\n而 win 用户则需要下载安装包进行安装。\n添加简单文字水印假设我们有一个视频 input.mp4，想在左上角添加“Watermark”文字，可以使用以下命令：\nffmpeg -i input.mp4 -vf &quot;drawtext=text=&#x27;Watermark&#x27;:fontcolor=white:fontsize=24:x=10:y=10&quot; output.mp4\n\n\n-i input.mp4：输入视频文件。\n-vf &quot;drawtext=...&quot;：应用 drawtext 滤镜。\ntext=&#39;Watermark&#39;：水印文字。\nfontcolor=white：文字颜色。\nfontsize=24：文字大小。\nx=10:y=10：通常用于指定在视频中添加元素（如文本或图像）时的水平和垂直位置，当x=10:y=10时，表示水印在视频的左上角，距离左边缘 10 像素，距离上边缘 10 像素。\n\n运行后，生成的新视频 output.mp4 将带有水印。\n使用文本文件和自定义字体如果水印内容较复杂（如多行文字或特殊字符），我们可以将文字写入文本文件，并指定字体。例如：\nffmpeg -i input.mp4 -vf &quot;drawtext=fontfile=&#x27;/path/to/font.ttf&#x27;:textfile=&#x27;/path/to/text.txt&#x27;:fontcolor=white:fontsize=24:x=10:y=h-th-10&quot; output.mp4\n\n\nfontfile：指定字体文件路径。\ntextfile：指定存储水印文字的文本文件。\ny=h-th-10：其中，h 表示视频帧的高度，th 表示待添加元素的高度。因此，h-th-10 的计算结果为：视频高度减去元素高度再减去 10 像素，即将元素放置在距离视频底部 10 像素的位置。\n\n用 Python 实现 FFmpeg 的批量处理单个视频加水印很简单，但批量处理需要自动化。这时，Python 派上用场。我们可以用 Python 调用 FFmpeg 命令，自动遍历目录中的视频文件并添加水印。\n基本思路\n遍历目录：用 os.walk 找到所有视频文件。\n构造命令：为每个视频生成 FFmpeg 命令。\n执行处理：通过 subprocess 模块运行命令。\n保存结果：将处理后的视频存到指定目录。\n\nPython 脚本的优势手动输入命令适合单次操作，但批量处理时容易出错。Python 脚本可以一次性处理数百个视频，还能灵活调整水印位置、样式等。\n完整 Python 示例代码以下是一个安全的示例代码，去除了敏感路径信息，保留了核心逻辑，供你参考和修改：\nimport osimport subprocess# 定义水印文本文件路径（需替换为实际路径）textfile1 = &quot;/path/to/textfile1.txt&quot;  # 第一行水印文本textfile2 = &quot;/path/to/textfile2.txt&quot;  # 第二行水印文本# 定义字体文件路径（需替换为实际路径）font_path1 = &quot;/path/to/font1.ttf&quot;  # 支持特殊字符的字体font_path2 = &quot;/path/to/font2.ttf&quot;  # 支持中文的字体WATERMARK_POSITION = (10, 10)FONT_SIZE = 24FONT_COLOR = &quot;white&quot;def add_adaptive_watermark_ffmpeg(input_path, output_path, textfile1, textfile2, font_path1, font_path2):    # 构造 FFmpeg 命令    command = [        &quot;ffmpeg&quot;,        &quot;-i&quot;, input_path,        &quot;-vf&quot;,        f&quot;drawtext=fontfile=&#x27;&#123;font_path2&#125;&#x27;:textfile=&#x27;&#123;textfile2&#125;&#x27;:fontcolor=&#123;FONT_COLOR&#125;:fontsize=&#123;FONT_SIZE&#125;:x=&#123;WATERMARK_POSITION[0]&#125;:y=h-th-10, &quot;        f&quot;drawtext=fontfile=&#x27;&#123;font_path1&#125;&#x27;:textfile=&#x27;&#123;textfile1&#125;&#x27;:fontcolor=&#123;FONT_COLOR&#125;:fontsize=&#123;FONT_SIZE&#125;:x=&#123;WATERMARK_POSITION[0]&#125;:y=h-th-40&quot;,        &quot;-codec:a&quot;, &quot;copy&quot;,  # 音频流直接复制，不重新编码        output_path    ]    # 执行命令    try:        subprocess.run(command, check=True)    except subprocess.CalledProcessError as e:        print(f&quot;Error processing &#123;input_path&#125;: &#123;e&#125;&quot;)def process_videos_in_directory(directory, textfile1, textfile2, font_path1, font_path2):    for root, _, files in os.walk(directory):        for filename in files:            if filename.endswith((&quot;.mp4&quot;, &quot;.avi&quot;, &quot;.mov&quot;, &quot;.mkv&quot;)):                input_path = os.path.join(root, filename)                # 构造输出路径（需替换为实际输出目录）                output_path = os.path.join(&quot;/path/to/output/directory&quot;, os.path.relpath(input_path, directory))                output_dir = os.path.dirname(output_path)                if not os.path.exists(output_dir):                    os.makedirs(output_dir)                if os.path.exists(output_path):                    print(f&quot;Output file &#123;output_path&#125; already exists. Skipping...&quot;)                    continue                print(f&quot;Processing &#123;filename&#125;...&quot;)                add_adaptive_watermark_ffmpeg(input_path, output_path, textfile1, textfile2, font_path1, font_path2)                print(f&quot;Watermarked video saved as &#123;output_path&#125;&quot;)# 处理指定目录中的视频（需替换为实际输入目录）process_videos_in_directory(&quot;/path/to/video/directory&quot;, textfile1, textfile2, font_path1, font_path2)\n\n使用说明：\n\n将&#x2F;path&#x2F;to&#x2F;…替换为你的实际文件路径。\ntextfile1.txt 和 textfile2.txt 分别存储两行水印内容。\n确保字体文件支持所需字符（中文或特殊符号）。\n输出视频将保留原目录结构，方便管理。\n\n常见问题及解决方法在批量添加水印时，可能会遇到以下问题：\n中文显示为“口口口”原因：默认字体不支持中文字符，导致显示乱码。解决方法：指定支持中文的字体文件，如“微软雅黑”或“宋体”。在命令中添加 fontfile&#x3D;’&#x2F;path&#x2F;to&#x2F;chinese_font.ttf’即可。\n特殊字符（如®）无法显示原因：字体不支持全 Unicode 字符，商标符号®等无法正常渲染。解决方法：更换支持全 Unicode 的字体，如“Arial Unicode MS”或“Noto Sans”，确保特殊字符正确显示。这些问题在 Python 脚本中也可以通过动态指定字体文件轻松解决。\n结语通过 FFmpeg 和 Python 的结合，你可以轻松实现视频的批量水印添加。这种方法不仅高效，还能灵活应对各种需求。无论是保护版权还是宣传品牌，这套工具都能为你节省大量时间。快动手试试吧，体验自动化带来的便利！\n另外，FFmpeg 功能远不止于此，你可以探索更多滤镜和参数，定制专属的水印样式。祝你的视频创作之路更加顺畅！\n参考\nFFmpeg\n字集 - 免费字体 - 文泉驿\n终于完工！ffmpeg 视频滤镜：添加文本-drawtext_ffmpeg drawtext 添加中文字-CSDN 博客\nFFmpeg Filters Documentation\nFFmpeg Community Discussions\n\n","categories":["视频制作相关"],"tags":["FFmpeg"]},{"title":"Home Assistant 智能家居系统搭建","url":"/2023/06/08/Tech/nas/Home%20Assistant%20%E6%99%BA%E8%83%BD%E5%AE%B6%E5%B1%85%E7%B3%BB%E7%BB%9F%E6%90%AD%E5%BB%BA%E6%8C%87%E5%8D%97%EF%BC%88%E7%B1%B3%E5%AE%B6+Siri%EF%BC%89/","content":"引言效果展示http://192.168.68.79:8123\n\n过程创建高级设置\n硬件渲染\n网络设置 host\n\n存储存f储空间2/docker/homeassiant:/config\n\n端口8123:8123\n环境TZ:Asia/ShanghaiPUID:0PGID:0\n\n下载 HACSdocker exec -it homeassistant bashwget -q -O - https://cdn.jsdelivr.net/gh/al-one/hass-xiaomi-miot/install.sh | HUB_DOMAIN=hub.fastgit.org bash -exitdocker-compose eestart\n\n结论引用\nHome Assistant 智能家居系统搭建指南（米家+Siri）\n智能家居搭建总结（二）：家居智能中控平台\nHome Assistant 安装 HACS\n\n","categories":["Tech","nas"]},{"title":"clash+yacd 的 docker 版安装使用","url":"/2023/07/28/Tech/nas/clash_docker%E5%AE%89%E8%A3%85%E4%BD%BF%E7%94%A8/","content":"引言效果展示过程 (docker)clash# 运行 Clashmkdir ~/clashcp ./config.yaml ~/clash/ # config.yaml 是 Clash 的配置文件docker run --name clash \\    -p 9090:9090 -p 7890:7890 -p 7891:7891 \\    -v ~/clash/config.yaml:/root/.config/clash/config.yaml -d dreamacro/clash\n\n过程 (nas)准备 Clash 配置文件[1]在准备好 Clash 配置文件后，使用任意文本编辑器打开，查找并确认以下设置：（不要带上#及后面的部分）\nport: 7890 #http/https 监听端口socks-port: 7891 #socks5 监听端口allow-lan: true #允许外部连接external-controller: 9090 #UI 监听端口\n\n如果配置文件中不存在对应的项目，请在文件头部进行添加。其中第一，第二及第四项的端口号可以在 1024-65535 之间任意设置但不得重复，第三项必须设置为 true。\n示例配置文件如下：\n保存后将该文件复制到群晖的共享文件夹中，如 &#x2F;docker&#x2F;clash&#x2F;sub.yaml。\n创建 Clash 容器进入 docker 套件并下载映像 dreamacro&#x2F;clash，随后双击映像创建容器，并点击高级设置。\n重启策略容器退出时重启（不考虑在进程启动时就已经停止了…\n挂载点在卷页面中\n\n为 &#x2F;ui 创建文件夹挂载点，\n为 &#x2F;root&#x2F;.config&#x2F;clash&#x2F;config.yaml 创建文件挂载，指向前一步中的配置文件。\n\n在端口设置页面中，为前一步中的 port, socks-port, external-controller 三个端口创建对应的映射端口。如有需要类型可以选择 TCP 和 UDP。\n\n创建 UI 容器在 docker 中下载映像 haishanh&#x2F;yacd 并创建容器，这里只需要为 80 端口创建映射端口即可。\n5080:80\n登录使用在确保以上两个容器都启动运行后，在浏览器中打开 &lt;http://群晖的 ip 地址：步骤 3 中的本地端口&gt;\n（本例中是 http://reizhix:5080，便可以看到如下的登陆界面。\n其中，Hostname 填写群晖的 ip 地址（切勿使用默认的 127.0.0.1），Port 填写步骤 2 中 9090 所对应的映射端口（本例中是 5090），点击 Confirm 即可进入 Clash UI 的主界面。\n此时 Clash 会监听步骤 2 中的 7890 和 7891 端口并向局域网提供服务。由于本教程中没有配置认证，请勿将相关端口映射到外网。\ndocker run -p 5058:80 -d --rm haishanh/yacd\n\n结论引用\n群晖 docker 安装并运行 Clash+UI | reizhi\n\n","categories":["Tech","nas"],"tags":["linux","clash","docker"]},{"title":"transmission 的安装和使用","url":"/2023/09/28/Tech/nas/transmission%E7%9A%84%E5%AE%89%E8%A3%85%E5%92%8C%E4%BD%BF%E7%94%A8/","content":"引言本文安装的是已增强 web 版本\n过程docker 过程资源从官网[1]获得。\n使用魔改版界面：https://github.com/ronggang/transmission-web-control\n可在 transmission 主目录直接git clone https://github.com/ronggang/transmission-web-control获取。\nDATA_FOLDER=&quot;/home/tenney/docker/transmission&quot;docker run -d \\  --name=transmission \\  -e PUID=1000 \\  -e PGID=1000 \\  -e TZ=Etc/UTC \\  -e TRANSMISSION_WEB_HOME= `#optional` \\  -e WHITELIST= `#optional` \\  -e PEERPORT= `#optional` \\  -e HOST_WHITELIST= `#optional` \\  -e TRANSMISSION_WEB_HOME=&quot;/transmission-web-control/src&quot; \\  -p 9091:9091 \\  -p 51413:51413 \\  -p 51413:51413/udp \\  -v $DATA_FOLDER/data:/config \\  -v $DATA_FOLDER/downloads:/downloads \\  -v $DATA_FOLDER/watch:/watch \\  -v $DATA_FOLDER/transmission-web-control:/transmission-web-control \\  --restart unless-stopped \\  lscr.io/linuxserver/transmission:latest\n\n---version: &quot;2.1&quot;services:  transmission:    image: lscr.io/linuxserver/transmission:latest    container_name: transmission    environment:      - PUID=1015      - PGID=1015      - TZ=Etc/UTC      - TRANSMISSION_WEB_HOME= /transmission-web-control/src      - USER= lev      - PASS= yeyezi      - WHITELIST= #optional      - PEERPORT= #optional      - HOST_WHITELIST= #optional    volumes:      - home/tenney/docker/transmisson/data:/config      - home/tenney/docker/transmisson/downloads:/downloads      - home/tenney/docker/transmisson/watch/folder:/watch    ports:      - 9091:9091      - 51413:51413      - 51413:51413/udp    restart: unless-stopped\n\ndocker-compose up\nnas 安装存储存储空间1/FTP/transmission-web-control:/config存储空间1/FTP:/downloads存储空间1/FTP/watch:/watch存储空间1/FTP/transmission-web-control:/transmission-web-control\n\n环境TZ:Asia/ShanghaiPUID:0PGID:0TRANSMISSION_WEB_HOME:/transmission-web-control/src# USER:&lt;!-- lev --&gt;# PASS:# password:&lt;!-- yeyezi --&gt;\n\n引用\nDocker\n[Windows] 绿联云 NAS 搞机笔记（一）安装 transmission|www.52pojie.cn\n[Windows] 绿联云 NAS 搞机笔记（一）安装 transmission\n\n","categories":["Tech","nas"],"tags":["nas"]},{"title":"使用 docker 镶套 ubuntu 系统及 1panel","url":"/2024/04/06/Tech/nas/%E4%BD%BF%E7%94%A8docker%E9%95%B6%E5%A5%97ubuntu%E7%B3%BB%E7%BB%9F%E5%8F%8A1panel/","content":"引言效果展示过程docker run -dt \\    --name 1panel \\    --restart always \\    --network host \\    -v /var/run/docker.sock:/var/run/docker.sock \\    -v /var/lib/docker:/var/lib/docker \\    -v /opt:/opt \\    -e TZ=Asia/Shanghai \\    xeath/1panel-in-docker:latest\n\napt updateapt install byobuapt install openssh-server ncat\n\nPort 220PasswordAuthentication yesPermitRootLogin yes\n\n结论引用\nGitHub - Xeath&#x2F;1panel-in-docker: 将 1Panel 运行在容器中; 1Panel running in Docker\n\n","categories":["Tech","nas"]},{"title":"带有代理的 emby 客户端搭建和使用","url":"/2023/07/28/Tech/nas/%E5%B8%A6%E6%9C%89%E4%BB%A3%E7%90%86%E7%9A%84emby%E5%AE%A2%E6%88%B7%E7%AB%AF%E6%90%AD%E5%BB%BA%E5%92%8C%E4%BD%BF%E7%94%A8/","content":"引言效果展示过程本文默认搭建带有代理的 emby 客户端。\n搭建网络设置 host 而非 bridge.\nNO_PROXY 172.17.0.1,127.0.0.1,localhost ##保持默认ALL_PROXY http://127.0.0.1:7890 ## 更换为自己的http代理HTTP_PROXY http://127.0.0.1:7890 ##更换为自己的http代理\n\n端口8096:8096\n存储存储空间 2/docker/emby:/config存储空间 1/FTP:/data\n\n环境PUID=0PGID=0TZ=Asia/Shanghai\n\ndocker-composeversion: &quot;2.3&quot;services:  emby:    image: emby/embyserver    container_name: embyserver    runtime: nvidia # Expose NVIDIA GPUs    network_mode: host # Enable DLNA and Wake-on-Lan    environment:      - UID=1015 # The UID to run emby as (default: 2)      - GID=1015 # The GID to run emby as (default 2)      - GIDLIST=1015 # A comma-separated list of additional GIDs to run emby as (default: 2)      - NO_PROXY=172.17.0.1,127.0.0.1,localhost      - ALL_PROXY=http://127.0.0.1:7890      - HTTP_PROXY=http://127.0.0.1:7890    volumes:      - /dev/sda1/home/tenney/docker/emby/programdata:/config # Configuration directory      - /dev/sda1/home/tenney/docker/transmisson/downloads:/data      - /dev/sda1/home/tenney/docker/emby/tvshows:/mnt/share1 # Media directory      - /dev/sda1/home/tenney/docker/emby/movies:/mnt/share2 # Media directory    ports:      - 58096:8096 # HTTP port      - 58920:8920 # HTTPS port    devices:      - /dev/dri:/dev/dri # VAAPI/NVDEC/NVENC render nodes      - /dev/vchiq:/dev/vchiq # MMAL/OMX on Raspberry Pi    restart: on-failure\n\ndocker run -d --name emby -e NO_PROXY=172.17.0.1,127.0.0.1,localhost -e ALL_PROXY=http://127.0.0.1:7890 -e HTTP_PROXY=http://127.0.0.1:7890 -p 58096:8096 -v /dev/sda1/home/tenney/docker/emby/config:/config -v /dev/sda1/home/tenney/docker/transmisson/downloads:/media emby/embyserver\n\n结论引用\n绿联 NAS 部署 Emby 影音服务器，打造个人家庭影音系统，实现观影自由！Docker 部署 Emby 教程\n解决 emby 网络问题，给 emby 设置 http 代理_NAS 存储_什么值得买\n【插件】emby 插件之 metat(๐•ᴗ•๐)e：给小姐姐一个全新的家 @代理篇 - invites.fun\nEmby Server for Docker\nInstall Emby Server - X64 | Docker\n\n","categories":["Tech","nas"],"tags":["nas"]},{"title":"河南联通光猫(SK-D748-C)管理密码获取","url":"/2023/07/27/Tech/nas/%E6%B2%B3%E5%8D%97%E8%81%94%E9%80%9A%E5%85%89%E7%8C%AB(SK-D748-C)%E7%AE%A1%E7%90%86%E5%AF%86%E7%A0%81%E8%8E%B7%E5%8F%96/","content":"引言效果展示过程开启talnethttp://192.168.1.1/hidden_version_switch.gch\nmac在无法brew安装telnet的情况下自行安装\ntar zxvf inetutils-1.9.4.tar.gzcd inetutils-1.9.4./configuremakesudo make install\n\ntelnet 192.168.1.1\n\nsendcmd 1 DB set DevAuthInfo 0 User CUAdminsendcmd 1 DB set DevAuthInfo 0 Pass CUAdmin\n\n结论引用\n河南联通光猫破解超级密码+桥接教程 - 一起活动吧\n山东联通SK-D740-C 光猫获取超级密码教程 2023年最新\n【路由器】网络改善小技巧，光猫桥接（附联通光猫的改桥接方法） - 好物清单\n\n","categories":["Tech","nas"]},{"title":"趣闻收集202305","url":"/2023/05/28/%E6%94%B6%E9%9B%86/%E8%B6%A3%E9%97%BB%E6%94%B6%E9%9B%86/%E8%B6%A3%E9%97%BB%E6%94%B6%E9%9B%86202305/","content":"2023-05-28Hexo博客为Hexo博客添加脚注插件 · 大专栏\n","categories":["收集","趣闻收集"],"tags":["趣闻收集"]},{"title":"趣闻收集 202310","url":"/2023/10/07/%E6%94%B6%E9%9B%86/%E8%B6%A3%E9%97%BB%E6%94%B6%E9%9B%86/%E8%B6%A3%E9%97%BB%E6%94%B6%E9%9B%86202310/","content":"Oct 7, 2023\n2023-10-16\n2023-10-16\n","categories":["收集","趣闻收集"],"tags":["趣闻收集"]},{"title":"趣闻收集栏目整理说明","url":"/2023/10/01/%E6%94%B6%E9%9B%86/%E8%B6%A3%E9%97%BB%E6%94%B6%E9%9B%86/%E8%B6%A3%E9%97%BB%E6%94%B6%E9%9B%86%E6%A0%8F%E7%9B%AE%E6%95%B4%E7%90%86/","content":"已将大多数”看到的有趣的东西”放至github资料库Knowledge-Vault.\n网址为:https://sandy9707.github.io/Knowledge-Vault/\n","categories":["收集","趣闻收集"],"tags":["趣闻收集"]},{"title":"神奇小软件 2022","url":"/2023/12/02/%E6%94%B6%E9%9B%86/%E7%A5%9E%E5%A5%87%E5%B0%8F%E8%BD%AF%E4%BB%B6/%E7%A5%9E%E5%A5%87%E5%B0%8F%E8%BD%AF%E4%BB%B62022/","content":"2022少数派 - 高效工作，品质生活\napril文叔叔\n六月SnippetsLab\n七月https://wantwords.nethttps://wqbook.wqxuetang.comhttps://www.ijiaodui.com/home\n八月稻壳阅读器 - 百度文库浏览器\n九月十月nuoshellMultitouch for Mac\n十一月RSwitchhidden barmatrixfreefilesync\n十二月tablemicrophone\n","categories":["收集","神奇小软件"]},{"title":"红包封面小礼物和 2023 年年终总结","url":"/2024/02/01/%E6%9D%82%E8%B0%88/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/2023%E5%B9%B4%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/","content":"引言2023 一如既往的过去，2024 毫无二致的过来。但对我来说，2023 是一个非常重要的节点，因为：我，鄙人，区区在下，结婚了。另外就是，建立了公众号，发了篇论文，升级了学业。可喜可贺，可喜可贺。\n新年了，给大家送点小礼物，红包封面 600 份，谢谢大家的陪伴。\n想要红包封面的到这里就可以结束了，下面是本人的一些心里话，有兴趣的可以听我絮叨絮叨。\n杂谈 - 公众号起源和现状这个公众号的建立初衷很简单，那就是把我可能说好几次的内容说成一次。教程，体验，杂谈，分享，等等，只要我觉得”有意思”的东西，都可能出现在这个小小的公众号中。在此由衷感谢我的一位 l 姓师兄和一位 c 姓同门，没有他们的提点我愚笨如我都想不起这个想法。\n我一向很崇尚信息的共享，信息可以说是成本最低的人类升级素材了，堪称是一本万利。只需要书写一次便能共享无数次。而且，只要我写的东西帮过了一个人，那从第二个开始是白赚。\n人类最伟大的发明就是文字，文字带给了人类文明传承下去的可能。我爱文字，正如我爱我的母亲。因此，我也喜欢书写文字，更期待着我的文字能给他人带来的微小的改变。文字承载着我的思考，我的思想，我的理想。\n不知不觉间，也有了近 200 名关注者，还是谢谢大家，谢谢团队的推广。\n如果有一直关注并阅读我的文字的朋友，首先谢谢您，我何德何能能有您这样好的读者朋友。但是，你也许能看出来，我在后半年发的文章是越来越少的。一是忙着发论文，没时间学习新东西，存货有限，二是我写的东西已经有越来越多不止是属于我自己的了，在这种情况下，不仅是我写的东西，连我的想法和相关作品也没办法轻易拿出来分享。\n总而言之，本人依然坚持并享受着文字创作，以后也请多多支持。\n年终总结 - 今年看过的影视作品顺序按本人看的顺序排行，较早的在前。\n电影今年最喜欢的电影应该是双重躯体，新假面骑士，师父，汉密尔顿，机械姬。\n特别是汉密尔顿，实在属于惊喜，我太喜欢 Satisfied 和 My shot 了。\n然后是新假面骑士，燃起了一点点我对特摄的热爱，甚至把假面骑士：亚马逊和假面骑士：空我下到了本地。虽然打斗真不怎么样，但是变身就是帅啊！Hen Shin!\n至于师父，虽然徐式电影一向不讨行家喜欢，但是我就挺喜欢这个范的，帅是一辈子的事嘛。\n最后是双重躯体和机械姬，这种科幻皮的人性探讨最有趣了。\n\n双重躯体.Dual.2022\n喜剧之王.King.of.Comedy.1999\n济公.The.Mad.Monk.1993\n布达佩斯大饭店.The.Grand.Budapest.Hotel.2014\n速度与激情.10.Fast.X.2023\n奥本海默.Oppenheimer.2023\n红辣椒.Paprika.2006\n百元之恋.100.Yen.Love.2014\n神秘博士与戴立克.Dr.Who.and.the.Daleks.1965\n神秘博士：戴立克入侵地球.Doctor.Who:.The.Dalek.Invasion.of.Earth.1964\n杰瑞和玛姬生活阔绰.Jerry.&amp;.Marge.Go.Large.2022\n化身博士.Dr..Jekyll.And.Mr..Hyde.2008\n超人.Superman.1978\n超人.2.Superman.II.1980\n未来罪行.Crimes.of.the.Future.2022\n新假面骑士.Shin.Kamen.Rider.2023\n怪物史瑞克.4.Shrek.Forever.After.2010\n师父.The.Final.Master.2015\n福音战士新剧场版：Q.Evangelion:.3.0.You.Can.(Not).Redo.2009\n福音战士新剧场版：破.Evangelion:.3.0+1.0.Thrice.Upon.a.Time.2012\n汉密尔顿.Hamilton.2020\n摇滚莫扎特.Mozart.L.Opera.Rock.2010\n白蛇.2：青蛇劫起.Green.Snake.2021\n姜子牙.Legend.of.Deification.2020\n机械姬.Ex.Machina.2015\nX.战警：第一战.X-Men.First.Class.2011\n\n剧集请务必观看瑞克和莫蒂，谢谢大家。\n\n命运石之门.Steins.Gate.S01.2011\n冥王.PLUTO.S01.2023\n火凤燎原.The.Ravages.of.Time.S01.2023\n女子监狱.Orange.Is.the.New.Black.2013\n为美好的世界献上爆炎！.|.Kono.Subarashii.Sekai.ni.Bakuen.o.S01.2023\n瑞克和莫蒂.Rick.and.Morty.S07.2023\n\n书籍今年是真没看书啊 (不过买书真买了不少)，希望寒假至少把上野千鹤子的几本和传习录给看看…\n\n呐喊 - 鲁迅\n超新星纪元 - 刘慈欣\n弟兄 - 鲁迅\n\n漫画说几个值得记下来的吧：\n\nThe Pervert - 雷米 博伊德尔\n自由 - 大鳥雄介\n天国大魔镜 - 石黑正數\n胰臟壞掉後，生活不像從前那麼艱難了 - 永田卡比\n影宅 - ソウマトウ\n\n杂谈 - 短视频我讨厌短视频，短视频对时间的利用率简直只能用悲剧来形容，信息熵简直是负的。我对短视频的恶意无限大。\n我们准备一个视频需要什么？一个大纲，一个讲稿，一些精巧的构思。而短视频需要的是一个”创意”, 一个 bgm, 没了。\n不排除有一些很优秀的作品，但是那样的作品换成长视频或文稿依然极其优秀。\n在我最喜欢的网文小说赛博英雄传里，有一种类似香烟的东西叫垃圾信息，内容是搞笑多媒体内容集锦，看的时候会开心，看完之后什么都不会记得。我将这种快乐定义为流于表面的情感，因为他什么也不会留下，你甚至不会 (或不应) 和别人分享。\n总而言之，我的观点是至少在一些领域，比如科普，短视频是不合适的。因为信息量太低，展示的要点太突出，太容易产生偏颇 (观点的偏移), 再加上强大的传播能力，对某些事物的污名化能力远远大于正经科普和辟谣。\n基于同样的理由，我同样讨厌 ppt，6 页 a4 纸显然比 30 张 ppt 更能表达演讲者的立意。ppt 是用来说服的，而不是用来表达的。\n基于以上的意见和感受，我将继续保持并持之以恒的投入长文本创作中。\n感想既然您看到了这里，我觉得我可以说一些更加无聊更加自私的事了。\n从最初的最初我就想写一点东西来介绍一下自己，没想到一直拖到了现在，机会难得，我想谈一谈我本人以及我对一些事情的看法。\n我自诩是一个女权主义者，人本主义者 (也可以称之为人类中心主义者), 工业党，技术主义者。\n和我相熟的人都知道，我是一个很强调”道德感”的人，虽然不一定会次次做到，我也会走草坪上的”路”，我也会为方便长开水龙头，但我依旧相信哪怕偶尔做一下就比不做强。\n因为我觉得这是”好”的。\n首先定义一下好和坏，好就是对我好的，坏就是对我不好的。做了会令我开心的事自然就是好事，令我不开心的事自然就是坏事。我的记忆力不算很好，但是如果我做了不开心的事，之后的每一天我的心情都可能因为这个事而恶劣一点点，我不喜欢。\n但是当尺度放到团体，乃至社会，乃至人类，每次尺度的变动都会是标准变动，因为人的本质是屁股。人天然只会对和自己相似的东西产生共情，比如不能和人类共情的人我们一般称为反社会人格，因此我认为比起选择自己的行为准则，选择自己的站位更为重要。\n但我依旧相信，小学课本的那一套就是最美好的东西，诚信，友善，自由，这些就应该是伊吕波的伊。\n我依旧相信人人都是未觉醒的强者。\n我依旧愿意相信最美好的事物。\n亲爱的读者朋友们，你们对人为什么活着有自己的想法吗？\n我认为，人活着是为了追求美，追求感动。\n我想把感动带给别人，这样就会是双倍的感动。我喜欢把快乐分享给别人，这样就会有双倍的快乐。世间最美的东西就是真理和大道，探寻大道是如此有趣的事情，如有同道则吾道长不孤。\n我相信一定会有一个时刻，让你觉得”啊，我就是为了这一刻而活的。”, 我就是喜欢度过那样的时刻。\n刚出炉的面包在口中融化的口感，不经意间脑海回响的旋律，大雨后泥土的芬芳，爱人的手，星星。\n我爱这些奇迹，正是生活中那些微小的奇迹一路带我走到了这里，让我活成现在的自己。我能以自己的意志喜欢着现在的自己，是多么幸运又伟大的事情，是那么多微小的奇迹累计而成的事情。我很感激世界，所以我想让世界对所有人都更温柔一点。谢谢你，世界上所有有爱的人。\n关于学业，鄙人比较愚笨，基本上上学就没有顺过，但是竟然一步一步也走到了现在。真的非常非常感谢师长，前辈和后辈，家人，每一个支持我的人。\n既然身处其位，更加不能怠懈了。为了信任我的人们，2024, 加油！\n新年快乐!!!\n愿望愿：世界和平，家人和睦。除此之外，能为医学作出一些微不足道的进步便再好不过。\n给自个儿的关键词2021 年的我是”想出去看看”, 2022 的我是”以愤怒为燃料”, 2023 的我是”很好保持住”。\n拾贝\n喜爱孤独者，非神即兽。–亚里士多德; 《政治学》1253a28-30;while a man who is incapable of entering into partnership, or who is so self-sufficing that he has no need to do so, is no part of a state, so that he must be either a lower animal or a god.\n\n","categories":["杂谈","年终总结"],"tags":["年终总结"]},{"title":"2024 年年终总结","url":"/2024/12/29/%E6%9D%82%E8%B0%88/%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/2024%E5%B9%B4%E5%B9%B4%E7%BB%88%E6%80%BB%E7%BB%93/","content":"引言春去冬来，又是一年。\n给自个儿的关键词2021 年的我是”想出去看看”, 2022 的我是”以愤怒为燃料”, 2023 的我是”很好保持住”。\n"},{"title":"趣闻收集 202304","url":"/2023/04/28/%E6%94%B6%E9%9B%86/%E8%B6%A3%E9%97%BB%E6%94%B6%E9%9B%86/%E8%B6%A3%E9%97%BB%E6%94%B6%E9%9B%86202304/","content":"2023-04-28老夫写程序就是一个词：敏捷\n我只要你的真心，和阳精\n","categories":["收集","趣闻收集"],"tags":["趣闻收集"]},{"title":"走进修仙 2024 同人活动","url":"/2024/11/02/%E6%9D%82%E8%B0%88/%E5%90%8C%E4%BA%BA%E6%96%87/%E8%B5%B0%E8%BF%9B%E4%BF%AE%E4%BB%992024%E5%90%8C%E4%BA%BA%E6%B4%BB%E5%8A%A8/","content":"自\n","categories":["杂谈","同人文"],"tags":["走进修仙"]},{"title":"公众号历史消息查询","url":"/2023/04/05/%E6%9D%82%E8%B0%88/%E8%85%BE%E8%AE%AF%E5%B0%8F%E6%8A%80%E5%B7%A7/%E5%85%AC%E4%BC%97%E5%8F%B7%E5%8E%86%E5%8F%B2%E6%B6%88%E6%81%AF%E6%9F%A5%E8%AF%A2/","content":"引言效果展示过程使用以下网址进入历史消息:\nhttps://mp.weixin.qq.com/mp/profile_ext?action=home&amp;__biz=&#123;自己百度搜怎么获取公众号好biz值&#125;==#wechat_redirect\n示例:\nhttps://mp.weixin.qq.com/mp/profile_ext?action=home&amp;__biz=MzIyOTM2OTE2Ng====#wechat_redirect\n获取公众号biz值:\n结论引用\n公众号新版不能跳转到历史消息啦？ | 微信开放社区\n如何获取微信公众号标识（biz值）-小宇博客\n\n","categories":["杂谈","腾讯小技巧"],"tags":["公众号"]},{"title":"量子计算介绍和使用实录 (一)","url":"/2025/09/09/Tech/quantum/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8%E5%AE%9E%E5%BD%95%20(%E4%B8%80)/","content":"引言自爱因斯坦与波尔之争以来，“量子力学”几乎成为无人不晓的名词，许多概念已经深入人心，科幻作品里更是充斥着或科学、或不科学的“量子”词汇：薛定谔的猫、量子纠缠、量子叠加、量子自杀、量子芯片、“量子护盾”、“量子长矛”…似乎只要在任何词前面加上“量子”二字，立刻就能身价倍增，也平添几分神秘与趣味。\n那么我们不妨继续提几个问题：\n\n研究量子计算有什么用？\n什么是量子计算？\n量子计算的优势到底是什么？\n量子计算目前的应用场景？\n量子计算算法的构建逻辑和运行基础\n量子计算的简单算法构建和测试\n\n量子计算有什么用？对于问题 1, 答案是：因为很 cooooooooool!!!!!!\n\n“一个新生的婴儿有什么用呢？” —-法拉第\n\n当然，如果有人非要刨根问底，可以去啃大部头[1]增长见识。\n什么是量子计算要解答这个问题，首先要回答什么是量子？\n量子来自拉丁语 quantum，意思是“多少”“最小单位”。在物理学里，它指某种物理量最小、不可再分的单位。在数学中可以做到”日取其半，万世不竭”, 但是在现实中，我们会受到普朗克尺度的约束，普朗克常数、光速和引力常数决定了我们能测量的空间时间能力最小单位。\n而量子力学就是研究量子等级的物理现象的学科，比如电子、光子等微观粒子的行为。在研究量子力学的过程中，科学家们发现了一些与经典物理学截然不同的现象，比如叠加态、波粒二象性、不确定性、量子纠缠等。\n再其次，量子计算是利用量子力学的原理来进行计算的一种新型计算方式。与传统计算机使用比特（0 和 1）作为信息的基本单位不同，量子计算机使用量子比特（qubit），它可以同时处于 0 和 1 的叠加状态。这种叠加状态使得量子计算机能够在某些特定任务上表现出极大的并行处理能力。具体为什么这样的并行处理能力会带来优势，后面会讲到。\n量子计算的优势到底是什么量子计算的优势主要来自量子力学的两个核心特性：叠加（Superposition）、纠缠（Entanglement）[1,2,3]。\n叠加普通计算机处理比特（0 或 1），而量子计算机处理的是量子比特（qubit），它可以同时处在“0”和“1”的叠加态。这意味着好比你去餐厅点菜，经典比特只能点鱼或肉二选一；量子比特却能“一边点鱼一边点肉”，直到你真的要吃的时候才“坍缩”成结果。这意味着量子计算机可以在同一时间“并行”探索指数级的可能性。\n在量子信息科学中，量子比特（qubit）是其信息载体，对应经典信息里的 0 和 1，量子比特两个可能的状态一般表示为$|0\\rangle$ 和 $|1\\rangle$。\n在二维复向量空间中，$|0\\rangle$ 和 $|1\\rangle$ 作为单位向量构成了一组标准正交基 (后面会讲矩阵的几何表达)。量子比特的状态可以用一个叠加态表示，例如：\n$$|\\varphi\\rangle &#x3D; a|0\\rangle + b|1\\rangle$$\n其中 $a^{2}+b^{2}&#x3D;1$。测量结果为 $|0\\rangle$ 态的概率是 $a^{2}$，得到 $|1\\rangle$ 态的概率是 $b^{2}$。\n这说明一个量子比特能够处于既不是 $|0\\rangle$ 又不是 $|1\\rangle$ 的状态，而是处于两者线性组合的所谓中间状态之上。\n经典信息可表示为：\n0110010110…\n而量子信息可表示为：\n$$|\\varphi\\rangle_{1}|\\varphi\\rangle_{2}|\\varphi\\rangle_{3}|\\varphi\\rangle_{4}|\\varphi\\rangle_{5}\\ldots$$\nn 个量子比特组成的系统，在不被测量时，能够同时表示 $2^n$ 种可能的状态。这意味着，量子计算机可以在一个计算周期内，同时对 $2^n$ 个状态进行运算。相比之下，经典计算机需要 $2^n$ 个独立的计算周期来逐一处理这些状态。这种内在的并行性是量子计算实现巨大效率提升的根本原因，使其能够同时处理数百万个运算，大大提高了计算效率。\n纠缠纠缠是量子位将其状态与其他量子位相关联的能力。\n当多个量子比特发生纠缠，它们的状态会紧密联系——一个变化，另一个立即呼应，不管距离多远。在计算上，这让量子比特之间能够“协作”，大幅提升运算效率。\n利用量子纠缠，量子计算机可以在分布式系统中高效地传输和处理信息，这是经典计算机无法实现的。量子纠缠为量子计算提供了独特的优势。\n综上所述，量子计算通过叠加和纠缠这两个核心特性，实现了在某些复杂计算任务上的指数级加速，展现出传统计算机无法比拟的潜力。\n其他特性测量当测量量子态时，波函数会坍缩，您可以将状态测量为 0 或 1。在这种已知或确定的状态下，量子位将充当经典位。\n退相干退相干是量子位中量子态的损失。辐射等环境因素会导致量子位的量子态崩溃。构建量子计算机的一项重大工程挑战是设计各种试图延迟状态退相干的功能，例如构建保护量子位免受外部场影响的特殊结构。\n量子计算目前的应用场景\n人工智能研究的突破依赖于更强大的计算机和更高效的算法，基于量子并行原理的量子计算机提供了一种与经典超算完全不同的计算方式，能否用量子计算机来加速人工智能算法是一个很自然的问题。但是量子计算机并非对各种问题自动拥有量子加速，加速的可能性依赖于针对特定问题精巧的量子算法设计。量子计算机研究的一个核心方向是在重要应用领域找到具有指数加速可能的算法。指数加速不同于经典超算中的常数倍加速，它的特点是，加速的倍数随着问题的规模（例如输入比特的数目）以指数函数形式迅速增长。指数加速赋予了量子计算机一种无与伦比的超能力，但这种超能力并非在各应用领域普遍存在。事实上，迄今发现的具有指数加速可能的量子算法只有寥寥几个，每个具有指数加速能力的量子算法的发现，都是量子计算机研究的重要突破，往往开拓量子计算机的一个重要应用领域。[4]\n\n量子计算可以颠覆许多行业。Amazon 在下面给出了一些使用场景示例[3]：\nML机器学习（ML）是分析大量数据以帮助计算机做出更好的预测和决策的过程。量子计算研究研究了信息处理的物理极限，并在基础物理学领域开辟了新天地。这项研究促进了多个科学和工业领域（例如化学、优化和分子模拟）的进步。它也是一个日益受关注的领域，金融服务业可以通过它来预测市场动向，制造业也可以通过它来改善运营。\n优化量子计算可以改善研发、供应链优化和生产。例如，您可以通过优化复杂流程中的路径规划等元素，应用量子计算来降低制造流程相关成本并缩短周期时间。另一个应用是贷款组合的量子优化，以便贷方可以释放资本、降低利率并改进其产品。\n模拟精确模拟系统所需的计算量随着药物分子和材料的复杂性呈指数增长。即使使用近似方法，当前的超级计算机也无法达到这些模拟所需的精度水平。量子计算有可能解决化学中面临的一些极具挑战性的计算问题，使科学界能够进行当今难以处理的化学模拟。例如，Pasqal 构建了他们的 QUBEC 计算软件来运行化学模拟。QUBEC 将运行量子计算任务所需的繁重工作自动化，涵盖计算基础设施的自动配置、运行预处理和后处理经典计算以及执行错误缓解任务等。\n分子模拟与量子化学量子算法，特别是变分量子本征求解器（VQE）和量子相位估计算法（QPEA），可以更精确地计算分子的基态能量和化学反应过程中的能量势垒。这对于预测分子的稳定性和反应活性至关重要，能帮助科学家筛选出更有潜力的候选药物。\n蛋白质折叠与结构预测蛋白质的结构决定其功能，而预测其三维结构是药物设计中的一个核心挑战。蛋白质折叠是一个典型的 NP-难问题，其构象空间巨大。量子退火和量子优化算法可以有效地探索这个庞大的搜索空间，寻找能量最低的构象，从而更准确地预测蛋白质结构。\n药物分子对接（Drug Docking）药物分子需要精确地“对接”到靶标蛋白质的特定位点才能发挥作用。这也可以被看作是一个复杂的优化问题。量子优化算法，如量子近似优化算法（QAOA），可以用来寻找分子与靶标蛋白的最佳结合构象和结合能，从而加速筛选出与靶点亲和力更强的药物。\n结论本文中，我们介绍了量子计算的基本概念、核心特性及其在各个领域的潜在应用。量子计算通过利用叠加和纠缠等量子力学现象，展现出在处理复杂计算任务时的独特优势。尽管目前量子计算仍处于早期发展阶段，但其在机器学习、优化和分子模拟等领域的应用前景令人期待。随着技术的不断进步，量子计算有望在未来彻底改变我们解决问题的方式，推动科学和工业的发展。下一节将介绍量子计算的算法构建逻辑和运行基础。\n引用\n量子计算与编程入门 — 量子计算与编程入门 1.0.0 documentation\n什么是量子计算？- 量子计算简介 - AWS\n什么是量子计算原理_量子计算原理有哪些优势 - 亚马逊云科技\n清华量子信息中心段路明研究组发现具有指数加速的量子机器学习算法 - 清华大学\n\n","categories":["Tech","quantum"],"tags":["quantum","量子计算","量子力学"]},{"title":"量子计算介绍和使用实录 (二)","url":"/2025/09/11/Tech/quantum/%E9%87%8F%E5%AD%90%E8%AE%A1%E7%AE%97%E4%BB%8B%E7%BB%8D%E5%92%8C%E4%BD%BF%E7%94%A8%E5%AE%9E%E5%BD%95%20(%E4%BA%8C)/","content":"引言上一节中，我们介绍了量子计算的基本概念、核心特性及其在各个领域的潜在应用。本节将介绍量子计算的算法构建逻辑和运行基础。\n\n量子计算算法的构建逻辑和运行基础\n量子计算的简单算法构建和测试\n\n效果展示过程结论引用\nPyQPanda — pyQPanda  文档\n线性代数学习笔记（九）——矩阵运算（一）_矩阵运算 k(n)&#x3D;||n-1n||-CSDN 博客\n如何理解矩阵相乘的几何意义或现实意义？\nQPanda3: Quantum Cloud Service\n\n","categories":["Tech","quantum"],"tags":["quantum","量子计算","量子力学"]},{"title":"评：宇宙探索编辑部 (Journey to the West)","url":"/2023/06/11/%E6%9D%82%E8%B0%88/%E5%8F%B6%E5%AD%90%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%BD%B1%E8%AF%84/%E8%AF%84%E5%AE%87%E5%AE%99%E6%8E%A2%E7%B4%A2%E7%BC%96%E8%BE%91%E9%83%A8/","content":"评：宇宙探索编辑部 (Journey to the West)\n7.5 分\n\n浪漫是做不到但很美好的事情，但男人的浪漫就是仅仅是白痴，是逃避。\n\n挺不错的电影，有着完整的剧情，严谨的台词，恰当的演技，各处埋伏的伏笔也得到了回收。无疑是一部”电影”了。\n电影的主角叫唐志军，是一位痴迷于追逐外星人的杂志编辑，杂志名叫”宇宙探索”. 在上世纪那个贫穷而充满想象力的年代，人们对世界充满了未知和向往，气功，UFO, 鸡血，无数在今天看来堪称滑稽的东西大行其道。自然，唐老师也乘风而上，一时风头无二，名利双收。可惜好景不长，随着技术的进步，伪神被拉下御座，神秘的衣再不能阻挡来自地面的窥探。所谓的发现外星人一次次的被证明是炒作抑或是失误，已经无人相信超自然的存在。\n但是唐志军停不下来，自己的多年坚持，失去女儿的压力，加上对事实的渴望，他已经没有停下来的资格。\n于是他孤注一掷般的展开了最后一次冒险，相信了谁都不信的硅胶外星人，掏出了所有的积蓄，远离了所有信任他的人，一味的向前，不顾一切的向前。\n故事里他成功了，成功的目睹了一次第三类接触，完成了多年的心愿。但之后呢？当他在念献给女儿的诗时，他是否会后悔呢？也许人类的一大步对个人并没有那么大的价值，他奉献的一生也许本可由上亿人的多几十年完成，但他的家庭却只能由他补全。太虚无了，太可悲了。而且，如果他没成功呢？\n片子的前期非常真实，小人物的境遇，可笑的坚持，一丝不苟的说着不着边际的话，让唐老师多出一些滑稽，而影片多了些喜剧色彩。而从遇到驴开始，唐老师就给了我一种堂吉诃德的荒诞感，比”老堂”幸运的是，老唐的世界真的有巨人，所以他得以完成他的英雄之旅。\n总之，宇宙探索编辑部这部片子内容完整，又不乏风趣 (喜剧担当那日苏), 算是一部不错的，公路片？纪录片？\n\n","categories":["杂谈","叶子的个人影评"],"tags":["科幻","电影","Science Fiction","Movies"]},{"title":"神奇小软件 2022","url":"/2023/12/02/%E6%94%B6%E9%9B%86/%E7%A5%9E%E5%A5%87%E5%B0%8F%E8%BD%AF%E4%BB%B6/%E7%A5%9E%E5%A5%87%E5%B0%8F%E8%BD%AF%E4%BB%B62023/","content":"2023januarypyTransitorcookiecloudn.eko\nFebHazel\nmarsnapdropOmniDiskSweeper\nJunefoobar2000\nDecHugging Face\n","categories":["收集","神奇小软件"]},{"title":"新假面骑士","url":"/2023/10/29/%E6%9D%82%E8%B0%88/%E5%8F%B6%E5%AD%90%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%BD%B1%E8%AF%84/%E8%AF%84%E6%96%B0%E5%81%87%E9%9D%A2%E9%AA%91%E5%A3%AB/","content":"影评其实我挺喜欢的…我已经决定多看几季了…\n原来看 amazon 的时候感觉还是太子贡向了就没继续看，但是随着年龄的增长，我..好像能喜欢一些更子贡的东西了…\n说起 amazon, 仁叔瞎眼变身那真的好帅啊，真的帅爆炸了。反正我可以为了这一段去看一季的。\nAmazon!!     第二季仁叔最后一次变身《假面骑士 Amazons》_哔哩哔哩_bilibili\n引用\n\n\n","categories":["杂谈","叶子的个人影评"],"tags":["新假面骑士","特摄"]},{"title":"显示器显示“输出调整为1600*900 60Hz”解决办法","url":"/2023/08/26/%E6%9D%82%E8%B0%88/%E7%94%B5%E8%84%91%E5%B0%8F%E6%8A%80%E5%B7%A7/%E6%98%BE%E7%A4%BA%E5%99%A8%E6%98%BE%E7%A4%BA%E2%80%9C%E8%BE%93%E5%87%BA%E8%B0%83%E6%95%B4%E4%B8%BA1600*900%2060Hz%E2%80%9D%E8%A7%A3%E5%86%B3%E5%8A%9E%E6%B3%95/","content":"终极答案重启一下\n引言效果展示结论重启可以解决90%的问题, 重装可以解决99%的问题.\n重买可以解决100%的问题(大概).\n篇外事实上老式键盘鼠标不能用也是一样的重启解决, 因为这玩意不支持热插拔…\n过程(以前吃过的亏)win因特尔显卡设置\n\n选择显示器\n显示设置\n引用\n\n\n","categories":["杂谈","电脑小技巧"]},{"title":"学习相关","url":"/2023/08/26/Tech/%E5%8F%B6%E5%AD%90%E7%9A%84%E6%8E%A8%E8%8D%90%E5%B0%8F%E8%BD%AF%E4%BB%B6/%E5%8F%B6%E5%AD%90%E7%9A%84%E7%A5%9E%E5%A5%87%E5%B0%8F%E7%BD%91%E7%AB%99/%E5%AD%A6%E4%B9%A0%E7%9B%B8%E5%85%B3/","content":"引言论文ResearchGateResearchGate居然可以搜到各大学校vpn都搜不到的论文, 太强了…\n大学英语六级真题在线六级真题(2012-2023年6月) | 英语真题在线\n\n英语真题在线主要是一个免费在线服务，无需登录就可以下载所有考研英语、四六级、专八、专四真题电子档、在线查答案、播放音频听力、在线浏览真题等。 通过增强的功能（高级版）收取非常少的功能服务费用于支持我们的日常运营。\n\n效果展示过程结论引用\n六级真题(2012-2023年6月) | 英语真题在线\n\n","categories":["Tech","叶子的推荐小软件","叶子的神奇小网站"],"tags":["叶子的神奇小软件"]},{"title":"挚爱影视","url":"/2023/06/17/%E6%9D%82%E8%B0%88/%E5%8F%B6%E5%AD%90%E7%9A%84%E4%B8%AA%E4%BA%BA%E5%BD%B1%E8%AF%84/%E6%8C%9A%E7%88%B1/","content":"由于同步记录仅从 2019 年起，因为榜单不全。\n电影\n美丽人生 9.7\n雄狮少年 9.5\n巴霍巴利王 9.3\n护垫侠 9.0\n\n音乐剧\n汉密尔顿.Hamilton.2020\n\n剧\n瑞克和莫蒂.Rick.and.Morty\n非自然死亡\n老友记\n\n番\nRick and Morty\n异兽魔都\n我的三体\n鬼灭之刃\nbeastars\n\n漫画\n龙珠 - 鸟山明\n刃牙 - 板垣惠介\n噬谎者 - 迫稔雄\n炎拳 - 藤本树\nBEASTARS-板垣巴留\n螺丝侠 - 吉富昭仁\njojo-荒木吕飞彦   3756214\n鬼灭之刃\n\n歌曲\n群青 - yoasobi\n\n小说网文\n赛博英雄传\n空想之拳\n剑来\n\n小说文学\n呐喊 - 鲁迅\n\n外国文学\n百年孤独\n\n","categories":["杂谈","叶子的个人影评"]}]